---
title: SVD奇异值分解及应用
date: 2019-07-27 19:57:51
tags: [机器学习,矩阵分析]
categories: 
- 机器学习
---

## 特点

* 优点：简化数据，去除噪声，提高算法结果
* 缺点：数据的转换可能难以解释
* 适用于数值型数据

<!--more-->

## 原理

$M_{m\times n} = U_{m\times n}D_{n\times n}V_{n\times n}^T\approx U_{m\times k}D_{k\times k}V_{k\times n}^T$

对于矩阵$U$可表示为：

$U = (u_1,u_2,...,u_n)$

对于$V$：

$V =(v_1,v_2,...,v_n)$

则有：

$M=d_{1} u_{1} v_{1}^{T}+d_{2} u_{2} v_{2}^{T}+\cdots+d_{n} u_{n} v_{n}^{T}=\sum_{i=1}^{n} d_{i} u_{i} v_{i}^{T}=\sum_{i=1}^{n} A_{i}$

$M_n \approx M_{k}=\sum_{i=1}^{k} A_{i}$

## 应用

### 图像压缩

存储一张 1000×622 大小的图片，实际上就是存储一个 1000×622 的矩阵，共 622000 个元素。这个矩阵用 SVD 可以分解为 622 个矩阵之和，如果我们选取其中的前 100 个之和作为对图像数据的近似，那么只需要存储 100 个奇异值 $d_i$，100 个 $u_i$ 向量和 100 个 $v_i$ 向量，共100×(1+1000+622)=162300 个 元素，大约只有原始的 26% 大小。

