---
title: ml4sys笔记
toc: true
date: 2022-03-23 19:08:33
tags:
categories:
---

<!--more-->

* A Learning-based Approach Towards Automated Tuning of SSD Configurations

提出了LearnedSSD框架。对于新的工作负载，LearnedSSD将提取其特征，并使用相似性比较网络将其与ConfDB(实现中使用leveldb)中的记录进行比较。如果LearnedSSD在其ConfDB中识别出类似的工作负载，它将直接推荐相应的SSD配置，这样我们就可以利用之前学到的经验。否则，LearnedSSD将为工作负载学习新的SSD配置，并将它们添加到其ConfDB中以供将来参考。

开发了一种基于块I/O跟踪的基于学习的聚类方法。选择块I/O跟踪来了解存储工作负载的特征。跟踪特征包括I/O时间戳、I/O大小、设备号、块地址和操作类型。使用主成分分析将数据点转换为二维。之后使用k-means对这些数据点进行聚类。 在对一个新工作负载的所有数据点进行聚类后，我们将计算被检查数据点的中心与现有集群中心之间的距离。如果距离低于一个阈值，属于现有的工作负载集群。如果LearnedSSD无法识别类似群集，LearnedSSD将为新工作负载创建一个新群集。

然后这里就又一个问题，如何生成新配置？

LearnedSSD一次调整一个或两个相关参数，然后保留满足约束的参数。对于其他参数，LearnedSSD将在搜索空间中来回调整其值。一旦我们确定了一种配置的参数，LearnedSSD将使用GPR模型来确定具有最佳预测性能等级（4）的配置。如果其性能等级优于搜索根，LearnedSSD将此配置设置为新的搜索根，并继续下一次搜索迭代。SGD程序（3）的主要挑战是平衡学习精度和开发开销。由于无法保证初始配置集将覆盖整个搜索空间，LearnedSSD必须逐步扩展其搜索空间，以确保能够识别最佳配置。然而，这可能会导致搜索空间爆炸。为了解决这个问题，我们引入了一个启发式利用因子，即正在利用的配置与现有学习配置之间的最小曼哈顿距离[77]。我们还为配置探索中的搜索迭代次数设置了一个阈值（LearnedSSD中默认为20次迭代）。 

预测已探索配置的等级。LearnedSSD使用GPR[59]预测新配置的等级（4）。这主要有三个原因。首先，GPR可以提供与深度神经网络几乎相同的性能，尤其是在搜索最优配置和提出建议的建模方面。其次，它在探索新知识和学习知识之间提供了极好的权衡[44,67]。第三，默认情况下，GPR以较低的计算开销提供置信区间[9]。在LearnedSSD中，我们通过指定其均值函数和协方差函数来建立一个新的GPR模型。由于在LearnedSSD中学习之前，性能指标的平均值未知，因此平均值函数配置为可训练。我们使用协方差函数来表示模型的两个相邻点之间相关性 ，采用径向基函数（RBF）核[75]和有理二次核[76]作为回归协方差。我们还添加了一个用于随机噪声模拟的白核[47] 



* Lynx: A Learning Linux Prefetching Mechanism For SSD Performance Model

为了执行顺序预取，需要回答两个主要问题：何时预取，以及预取多少数据。传统的Linux预读机制通过将PoM和PoH关联起来来回答第一个问题。在缺页的情况下启动同步预读操作，在命中的情况下启动异步预读操作。对于第二个问题，预读会在32个连续页面的窗口大小内从存储设备预取数据。当特定文件的未命中率增加时，预读窗口会缩小，因为预取被评估为低效。然后，要预取的数据量是动态的。 
