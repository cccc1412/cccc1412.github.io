{"pages":[],"posts":[{"title":"B+树","text":"b+树 B+树简介结构如图： 分为两种类型的节点：内部节点和叶子节点 内部节点中包含key和指向孩子节点的指针，指针数 = key个数+1 叶子节点中包含key和指向数据的指针，指针数 = key个数 节点中的key是有序存放的 根节点至少有一个key，指向两个孩子节点 其他节点至少半满，阶数就是最大孩子节点的个数，key_num&gt;=ceil((order-1)/2) 相邻叶子节点间有指针连接，便于区间查询 B+树是向上生长的，就是插入节点后，之后叶子节点拆分后，才开始向上拆分节点，直到根。 插入123456找到要插入的节点如果节点未满，加入记录（利用插入排序或者二分保证有序）否则，分裂节点 分配新节点的空间，把原来节点的一半移动到新节点//此时当前节点还是叶子节点 更新父亲节点，把新节点的最小值（或最大值）和地址插入到父亲节点 如果父亲节点满，分裂父亲节点，第m/2个key加入到父亲节点的父亲节点，并更新孩子指针。重复该步，直到key个数不满或者分裂到根，树高+1。 删除123456//有相应的key的情况找到要删除的节点删除key后，key个数大于等于 ceil((m-1)/2)，删除结束如果兄弟节点key大于 ceil(m-1)/2，借用兄弟节点的key，更新父亲节点如果兄弟节点没有多余的key，则合并成一个新的节点，并删除父亲节点中的key检查内部节点key个数是否大于等于 ceil((m-1)/2),根据兄弟节点是否有剩余合并或者借key 序列化反序列化内存中的B+树如何保存到磁盘，指针维护的父子节点关系如何转化？ 用文件偏移量代替指针。数据库实现中，B+树存储在一个文件中，访问孩子节点也是通过文件偏移量实现。 序列化实现序列化节点，写入前，先保存当前文件偏移量，这是的偏移量就是这个节点的偏移量，用做返回值。 然后正常写入节点的信息如键值数，键值。 如果当前节点有孩子节点，空出一块区域，大小根据孩子个数计算。这块区域等序列化孩子节点完成后，用孩子节点的偏移量填充。回去填充前需要记录当前偏移量，填充完成后再恢复回去，这样文件才能接着往下写。 该过程就是深搜的过程，往下搜的时候写node本身的数据，偏移量先空出来，递归返回后把偏移量填上。 1234567891011121314151617181920212223long BPTree::serializeNode(Node * cur_node,int fd){ long cur_offset = lseek(fd, 0, SEEK_CUR); write(fd,(char*)&amp;cur_node-&gt;key_num,sizeof(int)); write(fd,(char*)&amp;cur_node-&gt;is_leaf,sizeof(bool)); for(int i = 0;i&lt;cur_node-&gt;key_num;i++){ write(fd,&amp;cur_node-&gt;key[i],sizeof(int)); } if(cur_node-&gt;child_node[0]!=NULL){ long offset_record_start = lseek(fd, 0, SEEK_CUR); lseek(fd,(cur_node-&gt;key_num+1)*sizeof(long),SEEK_CUR); std::vector&lt;long&gt;child_offset(cur_node-&gt;key_num+1); for(int i = 0;i&lt;=cur_node-&gt;key_num;i++){ child_offset[i] = serializeNode(cur_node-&gt;child_node[i],fd); } long recover_point = lseek(fd, 0, SEEK_CUR); lseek(fd,offset_record_start,SEEK_SET); for(int i = 0;i&lt;=cur_node-&gt;key_num;i++){ write(fd,(char*)&amp;child_offset[i],sizeof(long)); } lseek(fd,recover_point,SEEK_SET); } return cur_offset;} 反序列化反序列化就是根据序列化时的文件格式，找到孩子节点在文件中存储的位置，实例化到内存。 123456789101112131415161718192021222324Node *BPTree::deserializeNode(int fd,Node *parent_Node){ int key_num; bool is_leaf; read(fd,&amp;key_num,sizeof(int)); read(fd,&amp;is_leaf,sizeof(bool)); Node *node = new Node(); node-&gt;key_num = key_num; node-&gt;is_leaf = is_leaf; for(int i = 0;i&lt;key_num;i++){ read(fd,&amp;node-&gt;key[i],sizeof(int)); } if(!is_leaf){ long offset; for(int i = 0;i&lt;=key_num;i++){ long childOffset; read(fd,&amp;childOffset,sizeof(long)); long cur_offset = lseek(fd, 0, SEEK_CUR); lseek(fd,childOffset,SEEK_SET); node-&gt;child_node[i] = deserializeNode(fd,node); lseek(fd,cur_offset,SEEK_SET);//为了读下个child_offset } } return node;} B+树并发控制机制https://zhuanlan.zhihu.com/p/50112182 https://zhenghe.gitbook.io/open-courses/cmu-15-445-645-database-systems/relational-data-model https://www.cs.usfca.edu/~galles/visualization/BPlusTree.html Redis是一个单线程引擎 VoltDB是多线程引擎 并发协议，强制所有访问数据结构的线程使用这种协议,关注逻辑正确和物理正确 lock和latcheslock是高级层面的概念，保护了数据库中的逻辑内容（tuple,table） latch是低级层面的概念，关心的是保护数据结构或对象的物理完整性，保护数据库中的关键部分，保护内部数据结构免受其他线程同一时刻读写所带来的问题。 latch只有两种模式，读、写 读模式允许多条线程在同一时间读取同一个对象。 写模式是独占的，只有一个进程能操作对象。 实现方式： std:mutex m; m.lock(); m.unlock(); linux是用futex实现的，futex指fast userspace mutex,是在userspace也就是进程的地址空间里占用一点内存地址，通过这个内存来尝试进行一次cas操作，来获取这个latch,如果没有获取到，就会退一步使用速度更慢的mutex。(mutex是OS层面的) 自旋锁 spin latch,这种做法很快，因为现代CPU里，有一条指令，这条指令可以在一个内存地址上进行CAS操作，c++ 中有std::atomic可以实现，也有atomic_flag 实际就是atomic。 b+树的并发协议两个问题： 多个进程试图修改一个节点的内容 一个进程在遍历树，而另一个进程在分割或合并节点。 basic idea: 给parent加latch 给child加latch 如果parent是安全的，则释放latch 安全节点：在更新的时候不会分裂或者合并 插入的时候不满 删除的时候大于half-full a better latching algorithm Insert/Delete: 使用与 Search 相同的方式在查询路径上获取、释放read latch，在 leaf node 上获取 write latch 如果 leaf node 不安全，可能会引起其它节点的变动，则使用 Latch Crabbing 的策略再执行一遍 该方法乐观地假设整个操作只会引起 leaf node 的变化，若假设错误，则使用 Latch Crabbing 的原始方案。 Horizontal Scan之后再看","link":"/2020/12/09/B-%E6%A0%91/"},{"title":"BAOVERLAY: A Block-Accessible Overlay File System for Fast and Efficient Container Storage","text":"BAOVerlay设计BAOVerlay将overlay文件看做一系列块，通过块，baoverlay实现了非阻塞的写实拷贝机制，每次要写入时，并不是完整的文件从下层到上层进行拷贝，而是需要更新的块从下层到上层异步复制。最后，baoverlay实现了一种新的文件格式B-Cow，用来紧凑存储overlay文件用来节省存储空间。分配存储空间被推迟，知道实际实际更新了overlay文件的块。 实现块访问在POSIX兼容的文件系统中，文件或目录与inode数据结构关联，inode存储了文件的元信息，例如文件的所有权、访问模式和磁盘中的数据位置，该文件的操作。overlay文件系统为每个 overlay2的open函数会创建一个关联到overlay文件的 inode，并填充所需要的信息。其中一个主要的步骤就是找出关联的underlaying文件属于哪一层，从而根据backing fs的inode 的fetch操作，然后将其放入overlay inode的一个字段中。","link":"/2022/05/11/BAOVERLAY-A-Block-Accessible-Overlay-File-Systemfor-Fast-and-Efficient-Container-Storage/"},{"title":"BP神经网络算法 matlab实现","text":"根据西瓜书5.3编写。 搭建$4 \\times 10\\times3$的全连接神经网络。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263clear all;clc;data = load('Iris-train.txt');testD = load('Iris-test.txt')x2 = testD(:,1:end-1);y2 = testD(:,end);x = data(:,1:end-1);temp = data(:,end);y = zeros(3,75);for i = 1:75 y(temp(i)+1,i) =1;end%sigmoid functionf = @(x) 1/(1+exp(-x))delta = 0.1;V= randn(4,10);W = randn(10,3);gamma = randn(10,1);theta = randn(3,1);hTrain = []; hTest = [];flag = 1;while 1 accTrain = 0; for k = 1:75 % for all samples b = arrayfun(f,V'*x(k,:)'-gamma);%隐含层的激活值 (10*1) y_bar = arrayfun(f,W'*b-theta);%输出层 (3*1) %输出层梯度 g = y_bar.*(1-y_bar).*(y(:,k)-y_bar); %(3*1) %隐含层梯度 e = b.*(1-b).*(W*g);%(10*1) %权重和偏置更新 W = W + delta*b*g'; %10*3 theta = theta - delta*g;%3*1 V = V + delta*x(k,:)'*e';%4*10 gamma = gamma - delta*e; [maxL,label] = max(y_bar); accTrain = accTrain + (label==(temp(k)+1)); end %计算测试集准确率 b = arrayfun(f,V'*x2'-repmat(gamma,1,75));%隐含层的激活值 (10*75) y_bar = arrayfun(f,W'*b-repmat(theta,1,75));%输出层 (3*75) [maxL,label] = max(y_bar); hTrain = [hTrain accTrain/75]; hTest = [hTest sum(label == (y2+1)')/75]; plot(hTrain,'blue') hold on plot(hTest,'red') if flag == 1 legend('训练集acc','测试集acc'); flag = 0; end if sum(label == (y2+1)')/75&gt;0.98 break end pause(0.000001);end","link":"/2019/10/27/BP%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E7%AE%97%E6%B3%95-matlab%E5%AE%9E%E7%8E%B0/"},{"title":"C++/C语言学习","text":"Effective c++item1 把c++看成语言的集合C++可以看成由几个模块组成： C：C++是以C为基础的，指针、数组、数据类型等都是来自于C OOC（Object-Oriented C++）：类、继承、多态、虚函数等 Template：泛型模块 STL 这样区分的目的是：不同的模块有不同的编程策略 C模块中，一般用值传递 OOC，常量引用传递 STL，也是使用值传递 item2 用const、enum、inline代替#define尽量以编译器代替预处理器 方便在编译出错的时候找到错误位置，因为编译器对变量报错是根据符号表来的，宏至少简单的文本替换，出错的时候不容易定位。 用const用来声明数值常量、常量指针、类中的常量需要加上static，从而保证不会产生多个拷贝 enum hack：enum的行为像#define，比如不能获得地址，不会引来非必要的内存分配 使用inline代替宏：对于简单的语句封装成函数不划算，但是用宏可能会带来一些不可预料的错误，尽量写templet inline函数。 item3 多用constconst的使用范围 可以在class外部修饰global或namesspace作用域中的常量 可以修饰被声明为static的对象 也可以修饰class内部的static和non-static成员变量 指针自身，指针所指也可以是const const的语法规则 const int* ptr被指的是常量，也就是指向的内存不能修改 int* const ptr指针本身是常量，指针指向的位置不能修改 const int* ptr和int const* ptr，意义相同 STL迭代器的const 对于STL的迭代器，如果希望迭代器所指的东西不可变动，需要使用的是const_iterator,如std::vector&lt;int&gt;::const_iterator const_itr = vec.begin() 如果迭代器本身不可变动，即不可指向别的地方，直接用const修饰即可 const在声明函数使用const可以修饰函数的返回值、函数参数、函数自身 const Rational operator* (const Rational&amp; lhs, const Rational&amp; rhs); const成员函数指明该函数不会修改类的任何成员数据的值 bitwise constness和logical constness123456789class BigArray { vector&lt;int&gt; v; int accessCounter;public: int getItem(int index) const { accessCounter++; return v[index]; }}; 这个是编译不过的。我们希望的是getItem不会修改核心成员，而不考虑非核心成员，是logical constness。 编译器只认bitwise constness，为了解决这个问题，用mutable修饰accessCounter：mutable int accessCounter;。 const和non-const成员函数的重复问题为了避免代码重复，使用non-const函数调用const函数。 关于const约束的变量 从变量的名称开始，顺时针移动到下一个指针或者类型，直到表达式结束 或者是从右到左的语法解码，后面的修饰前面的 *读作pointer to int const *p：p是一个指针，指向一个const int，也就是说p本身指向的位置是可以修改的，但是指向的内存不能修改 int * const p：p是一个const指针，指向int，就是说这个指针指向的位置不能修改，但是允许修改存储在地址的值 const int* cont p：p是一个const 指针，指向一个const int。p既不能修改指向的位置，也不能修改里面的值 item 4确定对象被使用之前已经被初始化永远在对象使用之前初始化对于基本数据类型，手工完成。对于类，写构造函数，使得对象的每一个成员都被初始化。 主要：赋值和初始化不同 赋值与初始化语法虚函数http://www.noobyard.com/article/p-yfcqfueo-su.html 为什么要有虚函数：为了实现动态绑定，即在运行时决定调用哪个函数。举个例子：person为基类，派生出student 和 teacher子类，现在学校大门口有一个队列，存放了一系列person指针，每次pop，通过ptr调用函数“出校”，区别是学生需要扫码，而教师不需要，但是编译器在编译程序的时候并不知道要调用哪个出校函数，这取决与运行时队列pop出来的到底是student还是teacher，也就是动态绑定的含义，通过对象的虚表指针调用，因此也可以理解为：虚函数是将函数绑定到特定类的一种手段。 static关键字https://zhuanlan.zhihu.com/p/37439983 static出现在两种场景：面向对象和面向过程 面向对象 静态成员变量 静态成员函数 面向过程 静态全局变量 静态局部变量 静态函数 静态成员变量为什么要用static成员变量？每个对象有用相同的某项属性，就用static，比如student类，包含static int num 学生总人数，这是每个学生实例公用的。 static成员变量分配在数据段 跟全局对象相比：静态成员变量的命名空间在类中，不会与全局命名空间的命名产生冲突。static可以加入访问控制，比如private。 静态成员函数为什么用static成员函数？类似的，static成员函数为类服务，而不是为对象服务，因此static成员函数也没有this指针，因此也仅可以访问静态成员函数和静态成员变量 静态成员函数不能访问非静态成员函数和变量 反过来非静态成员函数可以任意访问静态成员函数和变量 静态全局变量静态局部变量静态函数static函数仅在声明他的函数中可见，不能被其他文件使用 为什么用？不同文件中可以定义相同名字的函数，不会发生冲突。 RAIImodern C++完美转发std::forwardRAII和智能指针RAIIRAII是c++特有的资源管理方式。把依赖栈和析构函数，对所有资源进行管理（包括堆内存，下面有一个例子）。栈上的指针在释放的时候会调用析构函数，在析构函数里释放堆内存。 例子： create_shape在堆上new了对象，返回对象的指针，如何让这块内存不会泄露？ 把这个函数的返回值（对象的指针），包裹到一个局部对象中，该局部对象的析构函数中delete掉这个指针。 12345678910111213141516171819202122class shape_wrapper {public: explicit shape_wrapper( shape* ptr = nullptr) : ptr_(ptr) {} ~shape_wrapper() { delete ptr_; } shape* get() const { return ptr_; }private: shape* ptr_;};void foo(){ … shape_wrapper ptr_wrapper( create_shape(…));//这里的shape_wrapper是一个局部栈对象，退出foo函数时会自动析构wrapper对象，而wrapper的析构函数会delete传入的shape指针。 …} 经典RAII的例子： 12345678std::mutex mtx;void some_func(){ std::lock_guard&lt;std::mutex&gt; guard(mtx); // 做需要同步的工作} 而不写成： 1234567891011std::mutex mtx;void some_func(){ mtx.lock(); // 做需要同步的工作…… // 如果发生异常或提前返回， // 下面这句不会自动执行。 mtx.unlock();} 智能指针实现从刚刚shape_wrapper类改造成模板类，就是一个简单的智能指针： 1234567891011121314template &lt;typename T&gt;class smart_ptr {public: explicit smart_ptr(T* ptr = nullptr) : ptr_(ptr) {} ~smart_ptr() { delete ptr_; } T* get() const { return ptr_; }private: T* ptr_;}; 但是这样跟指针的行为还有点差异，比如不能用*解引用，不能用-&gt;访问成员，不能用在bool表达式里，因此添加： 123456789template &lt;typename T&gt;class smart_ptr {public: … T&amp; operator*() const { return *ptr_; } T* operator-&gt;() const { return ptr_; } operator bool() const { return ptr_; }} 然后对于拷贝构造呢？smart_ptr&lt;shape&gt; ptr2(ptr1)应该怎么表现？ 转移指针所有权，这就是auto_ptr的实现了，现在已经废除，因为这样设计的smart_ptr一旦进行了赋值或拷贝，就不在拥有这个对象了。 12345678910111213141516171819202122232425262728template &lt;typename T&gt;class smart_ptr { … smart_ptr(smart_ptr&amp; other) //拷贝构造 { ptr_ = other.release(); } smart_ptr&amp; operator=(smart_ptr&amp; rhs) //赋值 { smart_ptr(rhs).swap(*this); //首先rhs把自己维护的指针交给给临时对象smart_ptr(rhs)，然后这个临时对象维护的指针和this对象维护的指针交换一下，this对象就拿到rhs维护的指针了，临时对象smart_ptr拿到this之前维护的指针，它会随着临时对象smart_ptr销毁而被delete。 return *this; } … T* release() { T* ptr = ptr_; ptr_ = nullptr; return ptr; } void swap(smart_ptr&amp; rhs) { using std::swap; swap(ptr_, rhs.ptr_); } …}; 再改下，就是unique_ptr： 123456789101112131415template &lt;typename T&gt;class smart_ptr { … smart_ptr(smart_ptr&amp;&amp; other) //改成移动构造函数 { ptr_ = other.release(); } smart_ptr&amp; operator=(smart_ptr rhs) { rhs.swap(*this); return *this; } …}; 现在添加引用计数，形成shared_ptr: 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173#include &lt;utility&gt; // std::swapclass shared_count {public: shared_count() noexcept : count_(1) {} void add_count() noexcept { ++count_; } long reduce_count() noexcept { return --count_; } long get_count() const noexcept { return count_; }private: long count_;};template &lt;typename T&gt;class smart_ptr {public: template &lt;typename U&gt; friend class smart_ptr; explicit smart_ptr(T* ptr = nullptr) : ptr_(ptr) { if (ptr) { shared_count_ = new shared_count(); } } ~smart_ptr() { if (ptr_ &amp;&amp; !shared_count_ -&gt;reduce_count()) { delete ptr_; delete shared_count_; } } smart_ptr(const smart_ptr&amp; other) { ptr_ = other.ptr_; if (ptr_) { other.shared_count_ -&gt;add_count(); shared_count_ = other.shared_count_; } } template &lt;typename U&gt; smart_ptr(const smart_ptr&lt;U&gt;&amp; other) noexcept { ptr_ = other.ptr_; if (ptr_) { other.shared_count_-&gt;add_count(); shared_count_ = other.shared_count_; } } template &lt;typename U&gt; smart_ptr(smart_ptr&lt;U&gt;&amp;&amp; other) noexcept { ptr_ = other.ptr_; if (ptr_) { shared_count_ = other.shared_count_; other.ptr_ = nullptr; } } template &lt;typename U&gt; smart_ptr(const smart_ptr&lt;U&gt;&amp; other, T* ptr) noexcept { ptr_ = ptr; if (ptr_) { other.shared_count_ -&gt;add_count(); shared_count_ = other.shared_count_; } } smart_ptr&amp; operator=(smart_ptr rhs) noexcept { rhs.swap(*this); return *this; } T* get() const noexcept { return ptr_; } long use_count() const noexcept { if (ptr_) { return shared_count_ -&gt;get_count(); } else { return 0; } } void swap(smart_ptr&amp; rhs) noexcept { using std::swap; swap(ptr_, rhs.ptr_); swap(shared_count_, rhs.shared_count_); } T&amp; operator*() const noexcept { return *ptr_; } T* operator-&gt;() const noexcept { return ptr_; } operator bool() const noexcept { return ptr_; }private: T* ptr_; shared_count* shared_count_;};template &lt;typename T&gt;void swap(smart_ptr&lt;T&gt;&amp; lhs, smart_ptr&lt;T&gt;&amp; rhs) noexcept{ lhs.swap(rhs);}template &lt;typename T, typename U&gt;smart_ptr&lt;T&gt; static_pointer_cast( const smart_ptr&lt;U&gt;&amp; other) noexcept{ T* ptr = static_cast&lt;T*&gt;(other.get()); return smart_ptr&lt;T&gt;(other, ptr);}template &lt;typename T, typename U&gt;smart_ptr&lt;T&gt; reinterpret_pointer_cast( const smart_ptr&lt;U&gt;&amp; other) noexcept{ T* ptr = reinterpret_cast&lt;T*&gt;(other.get()); return smart_ptr&lt;T&gt;(other, ptr);}template &lt;typename T, typename U&gt;smart_ptr&lt;T&gt; const_pointer_cast( const smart_ptr&lt;U&gt;&amp; other) noexcept{ T* ptr = const_cast&lt;T*&gt;(other.get()); return smart_ptr&lt;T&gt;(other, ptr);}template &lt;typename T, typename U&gt;smart_ptr&lt;T&gt; dynamic_pointer_cast( const smart_ptr&lt;U&gt;&amp; other) noexcept{ T* ptr = dynamic_cast&lt;T*&gt;(other.get()); return smart_ptr&lt;T&gt;(other, ptr);} 问题 shared_ptr怎么实现的 见上 shared_ptr是否线程安全 分场景，同一个shared_ptr被多个线程写，不是线程安全的。多线程读是安全的，根据同一个智能指针创建新的智能指针（增加引用计数）也是安全的。（不懂） atomicc++11引入atomic模板，可以应用到任何类型上，但实现不一样 对于整型量和指针等简单类型，通常结果是无锁的原子对象； 而对于另外一些类型，比如 64 位机器上大小不是 1、2、4、8（有些平台 / 编译器也支持对更大的数据进行无锁原子操作）的类型，编译器会自动为这些原子对象的操作加上锁。 编译器提供了一个原子对象的成员函数 is_lock_free，可以检查这个原子对象上的操作是否是无锁的。 问题 atomic怎么实现的 std::functionstd::function是一个可调用对象的包装器 可调用对象可以是：函数指针、一个有operator成员函数的类对象、可以被转换成函数指针的类对象、类成员函数指针。 比如： 123456789101112// 普通函数int add(int a, int b){return a+b;} // lambda表达式auto mod = [](int a, int b){ return a % b;}// 函数对象类struct divide{ int operator()(int denominator, int divisor){ return denominator/divisor; }}; 虽然他们类型不同，但是调用形式是相同的，调用形式就是参数和返回值，也就是function初始化时候的模板参数，于是就可以这样写： 123std::function&lt;int(int ,int)&gt; a = add; std::function&lt;int(int ,int)&gt; b = mod ; std::function&lt;int(int ,int)&gt; c = divide(); 用来取代函数指针，特别适合作为回调函数使用。 std::bind把可调用实体的某些传入参数，绑定到已有的变量，返回一个std::function 12345678910111213struct Foo { void print_sum(int n1, int n2) { std::cout &lt;&lt; n1+n2 &lt;&lt; '\\n'; } int data = 10;};int main() { Foo foo; auto f = std::bind(&amp;Foo::print_sum, &amp;foo, 95, std::placeholders::_1); f(5); // 100} 通过std::bind和std::function配合使用，所有的可调用对象均有了统一的操作方法。 auto和decltypeauto 的推导用在初始化时候，但目前的c++标准不允许类成员变量使用auto。 auto总是推导出值类型，不可能是引用。 auto可以加上const、volatile、*、&amp; 这样的类型修饰符，得到新的类型。 STL参考 const static","link":"/2021/11/24/C-C%E8%AF%AD%E8%A8%80%E5%AD%A6%E4%B9%A0/"},{"title":"C++和C混合编译externC","text":".c文件和.cpp文件在混合编译时遇到了undefined reference to XX的问题。 出现undefined reference to 的原因同一个函数名，C++和C编译后的符号不同，造成链接器找不到XX函数的定义了。 程序目录如下： test.cpp中需要用到my_malloc.c中的函数，如果在test.cpp中不用extern “C”修饰my_malloc.h，test.o的符号表如下： 可以看到，使用C++规则进行编译后，符号表中的函数名添加了前缀和后缀，这跟C++的重载实现(符号名中加入形参信息)和调用约定（如fastcall，stdcall）有关。 这也说明了为什么不能根据返回值类型的不同实现函数的重载，因为符号表中函数名的生产规则没考虑返回值，即使返回类型不同也会出现重定义。 解决使用extern “C”包裹my_malloc.h后重新编译test.cpp ：gcc -c test.cpp 1234567//file test.cpp#include &lt;stdio.h&gt;#include &lt;stdlib.h&gt;extern \"C\"{#include \"my_malloc.h\"}... 得到test.o的符号表如下： 这样就跟my_malloc.o中的符号保持了一致，链接可以正常完成： 参考https://zhuanlan.zhihu.com/p/123269132","link":"/2021/11/04/C-%E5%92%8CC%E6%B7%B7%E5%90%88%E7%BC%96%E8%AF%91externC/"},{"title":"C++ STL容器实现","text":"queuequeue其实有两种实现，一种底层是list，一种底层是deque listlist的实现是一个双向循环链表 deque是维护了一个map数组，map数组里存了指向几个连续空间的指针，连续空间存放用户数据。同时deque维护了两个迭代器，start和finish。 一个生产者一个消费者deque是线程安全的吗？ 比如某个时刻push_back造成map需要重新分配，start迭代器的node需要更新到新的map，还没更新时候，发生了pop_front，需要start的node需要后移，这时push_back的node移动生效，就把pop_front的操作覆盖了。 对于list的情况呢？ 由于是双向循环链表的情况，一个线程插入，一个线程删除。添加时，新增的末尾节点要指向第一个节点，还没赋值这个指针的时候，另一个线程进行了头部的删除，头节点已经修改。 为什么ringbuffer就是单生产者单消费者线程安全的了？","link":"/2022/03/30/C-STL%E5%AE%B9%E5%99%A8%E5%AE%9E%E7%8E%B0/"},{"title":"CSAPP Lab3-Attack","text":"本文是CASPP Attack实验的学习笔记。 缓冲区溢出原理函数的调用过程写一个测试程序，在main中调用fun()。 layout asm查看反汇编 mov $0x2,%edi，将2放入edi寄存器用作函数传参 call指令相当于push IP然后jump [addr] 使用ni(next instruction)、si指令调试，进入fun函数，看看函数调用做了什么： push %rbp：将rbp寄存器压栈，这时候的rbp指向的是main函数的rbp mov %rsp,%rbp，将rsp寄存器的值赋值给rbp寄存器 mov -0x4(%rbp),%eax，将返回值写入eax寄存器 pop %rbp，弹栈，栈顶元素赋值给rbp寄存器 retq，相当于pop IP，弹栈，栈顶元素赋值给ip寄存器。 因此，函数调用过程： 调用方把要传的参数写入寄存器或者压栈，然后call 把下一条指令地址压栈，也就是函数的返回地址压栈，然后jump 进入被调方，被调用方先把old rbp压栈，也就是把调用方的rbp寄存器压栈，然后将rsp寄存器的值赋值给rbp寄存器，注意每次pop和push指令都会修改rsp的值，也就是将当前栈顶作为被调用函数栈帧结构的栈底 其实后面应该还会有sub指令修改rsp寄存器，可能是这里程序太简单编译器优化掉了，main函数的反汇编里倒是有体现（第四行）。 被调用方返回时，pop把old rbp恢复，指向main函数的栈底，其实还应该有个mov %rbp %rsp，把rbp的值赋值给rsp，也就是恢复main函数的栈顶为被调用者的栈底。 这个时候rsp指向函数的返回地址，ret从栈顶取出返回地址给rip寄存器。 用到的一些gdb指令 layout src、layout asm、layout regs查看源码，反汇编，寄存器 ni,si汇编指令的调试 x/nfu &lt;addr&gt;：打印内存，n是打印单元个数，f是打印格式，u是单元类型 ROP链攻击原理返回导向编程（Return-Oriented Programming）是一种攻击技术，利用栈溢出的方式控制程序的指令执行流程。 gadgets：以ret结尾的代码片段或函数 rop攻击：在代码空间中寻找以ret结尾的代码片段，组合形成一条攻击链，实现攻击，这些ret结尾的代码片段就叫gadgets。 将一个个gadgets的地址以字符串的形式存放在缓冲区中，当程序执行ret指令时会造成一连串的gadget被执行。 如图，程序在执行ret指令时，从栈中将gadget1的地址弹出，放到rip中，程序转而去执行gadget1的代码，然后执行ret，再从栈中将gadget2的地址弹出放到rip寄存器中，执行gadget2的代码，然后再ret。。。 实验文件实验目录如下： ctarget: 实验一二的可执行程序 rtarget: 实验三四的可执行程序 cookie.txt: An 8-digit hex code that you will use as a unique identifier in your attacks. farm.c: The source code of your target’s “gadget farm,” which you will use in generating return-oriented programming attacks. hex2raw: A utility to generate attack strings. 使用objdump -d exefile &gt; exefile.asm生成汇编代码 rtarget通过反汇编代码，看到代码中有getbuf函数， 该函数首先将rsp指针向下移动，然后将rsp的值传给了rdi寄存器，rdi寄存器是用来函数调用中传递的第一个参数，也就是Gets函数的参数。可以猜到，Gets函数从用户输入中读取数据，然后放在了某个缓冲区中，因此rdi寄存器传递的参数就是这个缓冲器的起始地址，就是getbuf栈帧结构中的某个数组，这个数组的首地址刚好是rsp指针指向的地方。 touch2如下： 123456789101112131415void touch2(unsigned val){ vlevel = 2; /* Part of validation protocol */ if (val == cookie) { printf(\"Touch2!: You called touch2(0x%.8x)\\n\", val); validate(2); } else { printf(\"Misfire: You called touch2(0x%.8x)\\n\", val); fail(2); } exit(0);} 任务目的：让test函数执行完getbuf后去执行touch2，touch2函数有一个参数，我们需要再执行touch2之前把val设置为cookie，cookie的值再cookie.txt中。 解题一些问题参考资料 ROP攻击例子：http://lindada.com.cn/2020/04/19/ROP/","link":"/2021/11/14/CSAPP-Lab3-Attack/"},{"title":"DPDK & f-stack","text":"DPDK &amp; f-stack C10M问题http://www.youtube.com/watch?v=73XNtI0w7jA#! Errata Security 公司的 CEO Robert Graham，他在 Shmoocon 2013 大会上很巧妙地解释了这个问题， UNIX 的设计初衷其实为电话网络的控制系统而设计的，而不是一般的服务器操作系统，所以，它仅仅是一个数据负责数据传送的系统，没有所谓的控制层面和数据层面的说法，不适合处理大规模的网络数据包。 最后他得出的结论是： OS 的内核不是解决 C10M 问题的办法，恰恰相反 OS 的内核正式导致 C10M 问题的关键所在。 基于OS内核的数据传输的弊端1、中断处理。当网络中大量数据包到来时，会产生频繁的硬件中断请求。 2、内存拷贝。数据从网卡通过 DMA 等方式传到内核开辟的缓冲区，然后从内核空间拷贝到用户态空间，占到了数据包整个处理流程的 57.1%。 3、上下文切换。硬件中断和软中断，锁竞争（内核资源），系统调用 4、局部性失效。一个数据包的处理可能跨多个 CPU 核心，容易造成 CPU 缓存失效，造成局部性失效。如果是 NUMA 架构，更会造成跨 NUMA 访问内存。 5、内存管理。传统服务器内存页为 4K，为了提高内存的访问速度，避免 cache miss，可以增加 cache 中映射表的条目，但这又会影响 CPU 的检索效率。 DPDK DPDK 能够绕过内核协议栈，本质上是得益于 UIO 技术，通过 UIO 能够拦截中断，并重设中断回调行为，从而绕过内核协议栈后续的处理流程。 UIO 设备的实现机制其实是对用户空间暴露文件接口，比如当注册一个 UIO 设备 uioX，就会出现文件 /dev/uioX，对该文件的读写就是对设备内存的读写。 F-stackDPDK 本身并不包含 TCP/IP 协议栈，F-Stack 好比胶水，粘合了 DPDK 和 FreeBSD TCP/IP 协议栈，纯 C 语言编写，通过外加头文件、宏控制、以及hook相关实现进行的移植，对FreeBSD协议栈源代码的修改不到100行(基于libuinet)。 无共享架构 每个进程CPU、网卡队列绑定，具有无竞争、零拷贝、线性扩展、NUMA友好等特点。 解决了局部性失效的问题。 使用DPDK的轮询模式，排除中断处理造成的性能影响。 使用DPDK作为网络I/O模块，将数据包从网卡直接接收到用户态，减少内核态到用户态的内存拷贝。 请求平均分配到每个核上，通过设置DPDK的rss hash函数保证相同ip、port的请求落到同一个核上。 各进程拥有独立的协议栈、PCB表等资源，消除了协议处理过程中的各种资源竞争。 进程之间不共享内存，通过无锁环形队列（rte_ring)传递通信，如ARP包等。 参考资料[]: https://cloud.tencent.com/developer/beta/article/1005218 “官方全用户态网络开发套件 F-Stack 架构分析”","link":"/2023/05/08/DPDK-f-stack/"},{"title":"DQN算法","text":"DQN记录。 Q-learning首先要学习DQN算法要先学习Q-learning算法，DQN是在Q-learning得基础上结合了深度的方式。 Q-learning算法的核心是维护一张表叫做Q表，该表中保存了面对所有状态采取不同决策的效用值，假设有m种状态，n种操作，那么该表就是m*n的，假设能学习到一张完美的表，那么每帧都选用当前状态可采取操作的效用值最大的操作，那么在游戏中的存活时间就可以无限大。 所以关键是如何学习到这张表： 参考：https://www.zhihu.com/question/26408259的首赞答案。 伪代码如下： 123456789101112131415初始化 Q = {}; //Q表while Q 未收敛： //Q表还能更新 初始化S，开始新一轮游戏 while 游戏状态S未结束： 使用策略π，获得动作a=π(S) 使用动作a进行游戏，游戏的新状态S',与奖励R(S,a) Q[S,A] ← (1-α)*Q[S,A] + α*(R(S,a) + γ* max Q[S',a])更新 S ← S'//更新状态 DQN可以看出，Q-learning的弊端在于要保存所有状态所有动作的效用值，但对于很多问题状态空间太大了，所以就有人引出了DQN算法，改进的地方是使用神经网络来拟合这张表。 s是状态，a是采取的动作，theta是网络的参数，r是reward。 （s,a,r,s_）是经验池，经验池保存了每个时间步得到的（s,a,r,s_）样本，因为要采用离线的学习方式，随机的从以前的状态中学习（可能是为了防止局部最优）。 经验池中包含了：当前状态、采取的行动、带来的奖励（真实的奖励，而不是预测的）、采取行动后的下一个状态。每次模拟，都会往经验池中新增新的样本。 Q是预测到的奖励，那么为了拟合Q表，就是希望预测到的奖励能够等于真实的奖励。网络的输入是状态，输出是不同动作在该状态下对应的Q值 于是有了mse(r-Q),原公式还有改进，加入了折扣因子gamma,用来同时兼顾记忆中的利益，gamma越大，则原先经验的影响越大。 要理一下，假设有3个动作，那么网络的输出有3个神经元，但是计算loss的时候并没有用到3个神经元，而是选取a_j对应的神经元的值，对应的label是：经验池中面对当前状态，采取a_j后的真实收益 与 采取a_j动作后到达的下一个状态的预测可能最大收益的加权综合，是在表明，到达新位置后，新位置能够给出的最大效用值，也就是以往的经验。Gamma越大越注重经验，越小，越注重眼前的利益，也就是r。 关于GYMenv.unwrapped.get_action_meanings()可以获取动作的含义。 参考https://blog.csdn.net/qq_30615903/article/details/80744083","link":"/2019/11/27/DQN%E7%AE%97%E6%B3%95/"},{"title":"Efficient IO with io_uring","text":"本文旨在介绍最新的Linux IO接口，io_uring，并将其与现有的进行比较。我们将讨论它存在的原因、内部工作原理以及用户接口。本文不会详细介绍具体的命令，这些在man手册中。相反，本文将介绍io_uring以及其工作原理。 Introduction在Linux中有很多基于文件的IO方式。最古老的是read和write系统调用。后来有了pread和pwrite的版本，可以传入偏移量参数。在后来又有了preadv和pwritev，这是基于前者的向量版本，进一步扩展了API以及可修改的标志位。这几个系统调用有一个共同点，他们都是同步接口。这就意味这这些调用在数据准备就绪时才能返回。在一些场景下，需要异步接口，POSIX有aio_read和aio_write来满足，但是这两个的实现和性能一般。 Linux的原生异步IO接口，简称aio，有许多局限性： 最大的限制是只支持O_DIRECT。由于这个限制，native aio在大部分场景下都不适用，对于buffered IO，aio接口以同步的方式运行。 即使满足了异步的所有约束，有时候还不是异步的。IO提交可能会以多种方式阻塞，如果需要元数据来执行IO，提交将会阻塞。对于存储设备，只有固定数量的请求slots可用，如果这些slots当前被占用，提交将会被阻塞直到有一个可用。 API本身设计不好。每次IO提交需要拷贝64+8字节，每次完成拷贝32字节，共104字节的内存拷贝。对IO来说，希望的是零拷贝。 这意味着Linux缺乏一个能满足异步IO的接口，在内核可以更高效实现这一点的情况下，应用程序没有理由要创建私有IO线程池来获得良好的异步IO。 Improving the status quo一开始的工作集中在改进aio接口上，在被放弃之前，这项工作取得了相当大的进展。出发点是，改善原有接口比提供新的接口简单，工作量小。 现有aio接口由三个系统调用组成： io_setuo：设置aio上下文的系统调用。 io_submit：提交io。 io_getevents：用于获取或等待io完成的系统调用。 由于这些系统调用需要改变行为，要添加新的系统调用来传递这些信息，最终使得代码复杂度和可维护性都不是很好，API的理解和使用也变得更复杂。 所以有必要从零开始设计一个全新的东西。 新的接口设计目标 易用，不易误用。 可扩展，新的接口不只是用于块IO，对于网络或非块存储也能用。 功能丰富。要涵盖应用程序所需要的大部分功能（比如IO线程池），减少应用程序开发的工作量。 效率高。存储IO大多是基于块的，因此一个IO大小至少为512b或4kb，协议请求甚至没有携带数据负载，新接口要求对每个请求的开销都高效。 可伸缩性。虽然效率和低延迟很重要，但是在峰值也要尽可能提供最佳的新能。 io_uringaio为了处理IO尽量了多个单独内存拷贝，也就是存在内存副本，损害了效率和可扩展性，这是要避免的。 由于要尽量避免复制，内核和应用程序必须友好的共享定义IO本身和完成事件的结构，要实现这一点，需要让共享数据的coordination也驻留在应用程序和内核之间的共享内存。要实现这一点，就要考虑这内核和应用程序的同步管理方式。 应用程序不能在不用系统调用的情况下与内核共享锁，系统调用肯定会降低与内核通信的速率，这违背了设计目标中的效率需求。满足我们需求的一种数据结构是ringbuffer，单生产者单消费者的场景。通过共享环形缓冲区，我们可以消除应用程序和内核之间共享锁的需要，而且巧妙的避开了memory和ordering和barriers。 异步接口有两个基本操作：提交请求的行为和完成请求的事件。对于提交IO，应用程序时生产者，内核是消费者。对于完成事件刚好相反，内核生产，用户消费。因此我们需要一对环buffer来在应用程序和内核之间提供有效的通信通道。这个ringbuffer的通信通道就是io_uring的核心，也就是后面的提交队列（SQ）和完成队列（CQ），这是新接口的基础。 data structure有了通信通道，下面要定义用于描述请求和完成事件的数据结构。 cqe完成队列事件 Completion Queue Event 对于完成队列事件，简称cqe： 12345struct io_uring_cqe { __u64 user_data; __s32 res; __u32 flags; }; user_data用户数据字段取自初始提交请求，可以包含应用程序识别请求所需要的任何信息。一个常见的用例是将其作为原始请求的指针，内核不会触及这个字段，只是在提交和完成过程中简单搬运。 res保存请求的结果，将其视为系统调用的返回值。对于正常的读写操作，类似于读或写的返回值。对于成功的操作，他将包含传输的字节数，如果发生故障，返回负数。 sqe请求队列条目 Submission Queue Entry 请求队列(sqe)定义： 123456789101112131415161718192021struct io_uring_sqe { __u8 opcode; __u8 flags; __u16 ioprio; __s32 fd; __u64 off; __u64 addr; __u32 len; union { __kernel_rwf_t rw_flags; __u32 fsync_flags; __u16 poll_events; __u32 sync_range_flags; __u32 msg_flags; }; __u64 user_data; union { __u16 buf_index; __u64 __pad2[3]; }; }; opcode：操作码，用于描述特定请求的操作码，比如矢量读取IORING_OP_READV flag： ioprio是对此请求的优先级，对于正常的读写操作，遵循ioprio_set中的定义， fd是与请求关联的文件描述符 off保存操作应该发生传递偏移量 addr：如果操纵码描述了传输数据的操作，addr包含操作应执行IO的地址。如果操作码时某种向量化读写操作，那么将指向struct iovec数组的指针，跟preadv类似。对于非矢量IO传输，addr直接包含地址。 len是非矢量IO传输的字节计数，或者是addr描述的矢量数，用于矢量IO传输。 … communication channel介绍ring如何工作的。尽管提交和完成是对称的，但是两者之间的索引是不同的。 CQE被组织成一个数组，该数组的内存可以被内核和应用程序可读可写。然而CQE是内核产生的，因此实际上只能由内核修改。 每当内核想cq ring发布新事件时，都会更新tail，当应用程序消费entry时，更新头部。因此，如果head和tail不同，应用程序就知道有多个事件可以消费。head和tail时32位int，可以自然溢出，这样就不用管理ring已满的标志。ring的大小必须是2的n次幂。 要查找一个事件的索引，应用程序必须使用环的大小掩码来屏蔽当前尾部的索引。 123456789101112131415161718unsigned head; head = cqring→head; read_barrier(); if (head != cqring→tail) { struct io_uring_cqe *cqe; unsigned index; index = head &amp; (cqring→mask); cqe = &amp;cqring→cqes[index]; /* process completed cqe here */ ... /* we've now consumed this entry */ head++; } cqring→head = head; write_barrier(); 虽然CQ环直接索引CQ的共享数组，但提交端在他们之间有一个间接数组。因此提交端环形缓冲区是该数组的索引，而该数组又包含进入SQE的索引。原因是，一些应用程序可能回在内部数据结构中嵌入请求单元，使他们能灵活的这样做，同时保留在一个操作中提交多个SQE的能力。 sqe的使用和cqe基本是相反的操作： 1234567891011121314151617struct io_uring_sqe *sqe; unsigned tail, index; tail = sqring→tail; index = tail &amp; (*sqring→ring_mask); sqe = &amp;sqring→sqes[index]; /* this call fills in the sqe entries for this IO */ init_io(sqe); /* fill the sqe index into the SQ ring array */ sqring→array[index] = index; tail++; write_barrier(); sqring→tail = tail; write_barrier(); 一旦内核使用了sqe 参考资料","link":"/2022/03/22/Efficient-IO-with-io-uring/"},{"title":"KML论文阅读","text":"KML: Using Machine Learning to Improve Storage Systems https://github.com/sbu-fsl/kernel-ml motivation这篇论文把机器学习框架移植到了内核，为什么要移植到内核？操作系统中包括许多启发式的算法，但是这些启发式的算法并不能很好的适用多变的工作负载，OS不得不向用户公开许多可调参数，让用户决定参数设置。 KML的提出是为了： 1、取代启发式算法，动态适应不断变化的工作负载。 2、使用ML进行系统参数设定，不再需要由用户确定。 该论文证明了ML可以比现有的启发式算法更好的调优存储系统的参数。 OS中的启发式决策场景预读大小比如在NFS中，预读太少会浪费潜在的吞吐量，预读太大会污染缓存，读入无用数据，可以用ml设置参数。 预测KV存储中的索引结构缓存相关IO调度KML的设计提供了两种不同的操作模式： 内核空间进行训练和推理（性能和准确性，采样速率高时使用） 用户空间训练，内核空间进行推理（开发框架使用的便利性） KML代码库由用户和内核空间共享 KML通过探针来收集OS中目标组件的数据。 异步ML计算不会对IO路径产生负面影响。 神经网络的计算是一个DAG（有向无环图），推理意味着从源点（输入）开始遍历DAG，直到终点（网络输出）。 u-MLib.a和k-MLib.ko时从相同的KML源码中编译得来的。 同时做了一个KML的包裹层，使得KML在用户和内核api是统一的（类似于syscall和glibc吧）。 问题：为什么不在用户空间推理，然后只修改内核参数 资源开销3.4节介绍 减少计算开销浮点计算问题内核一般禁用浮点单元（FPU），这是为了减小上下文切换的开销，而ML中的矩阵原酸一般基于浮点运算。 三种解决方法： 量化：减少计算和内存开销，单数会降低准确度 定点表示：使用整数寄存器做浮点计算，所有浮点操作都是模拟的，效率很高，但是会有数值不稳定的现象（不太懂） 在内核中启用FPU：使用kernel_fpu_begin开启FP寄存器的使用。 降低内存开销内存开销有三个： 模型数据：结构，权重 训练和推理过程中KML内部的内存分配 训练和推理的数据收集：使用一个无锁循环缓冲区收集输入数据，然后用一个异步线程对收集到的数据进行训练，注意合理设置ringbuffer的大小，使得异步训练线程能及时处理。 资源受限情况没看懂，大概就是留了一些内存分配的api。 数据处理和异步训练normalization需要大量的FP计算，在为存储系统中设计KML时，一个主要原则时避免IO在数据路径上的内联计算。因此KML将训练、推理、数据归一化放到不同的异步线程中，线程间的通信使用ringbuffer或者其他KML组件（如数据收集组件）。目前只支持一个异步训练线程，不支持并行训练。 用户空间训练KML的用户空间和内核空间库由相同的API访问，并从相同的代码库中编译，因此将训练好的ML模型移植到内核空间进行推断很容易。 跟踪内存管理子系统，使用Re-Animator从存储组件中收集数据。 KML提供了30个API，分为五类：内存管理、线程、日志、原子操作、文件操作。 安全稳定性除了模型初始化和ML模型保存外，不涉及IO，KML对存储组件的稳定性方面的影响仅限于内存分配和并发。 用户模式和内核模式分配内存时都用到了锁机制，因此可能会出现意外的延迟或者死锁，为了解决这些问题，KML只在异步训练线程中分配内存，在使用ringbuffer使用了额外的保留内存（防止溢出吗）。 两个应用实例预读在动态工作负载下预测最佳的预读值。 预读是将磁盘上的存储数据预取到操作系统缓存，根据局部性原理预计这些数据将在近期使用，问题是要决定提前读多少：读太少就需要更多次的磁盘读，读太多会带来无用数据的缓存污染。这里的第一个应用就是ML调参，决定预读值的大小。 数据采集数据集生成：作者使用了4个不同的RocksDB的基准测试程序，每个测试都有20个不同的预读大小（8~1024）,这样就有了不同工作负载下不同预读值大小的性能（ops/sec），以这些为数据集预测其他工作负载的最佳预读值。 原始特征采集：使用LTTng来采集系统特征。利用hook function捕获page cache的行为，采集了三个原始特征：开始执行的时间差，inode 号（用来过滤RocksDB的文件访问）、文件的页偏移。 数据预处理和归一化以一秒为间隔对输入数据进行汇总，处理后的特征： 每秒发生的事务数量 页面偏移量的滑动平均值 页面偏移量的滑动标注差 连续事务的平均绝对页面偏移量的差值 输入到nn之前，先进行z-score归一化。 模型结构就一个3层的fcnn或这决策树模型（决策树要快，而且可解释性强一点） 实验结果k fold的交叉验证，准确率为95.5% 验证特征对分类性能的贡献： 随机化interest features的顺序，然后计算k fold的交叉验证 皮尔逊相关分析 最后发现特征的重要程度从高到低为：平均绝对页面偏移量的差，事务数，页面偏移量的滑动平均值。 NFS rsize网络读块大小最优值确定 最后处理完的特征为： 每秒的事务数 每对nfs4_read和nfs_readpage_done的时间差 连续nfs4_read的请求平均时间差 连续nfs_readpage_done的平均时间差 未来改进点 引入基于反馈的控制算法来解决不稳定行为 安全方面考虑，模型加载需要数字前面和认证 代码前置知识IO栈kernel中的文件读写 filp_open() filp_close(), vfs_read() vfs_write()，set_fs()，get_fs()等，这些函数在linux/fs.h和asm/uaccess.h头文件中声明。 iptableshttps://cloud.tencent.com/developer/article/1619659 ebpfC风格的面向对象http://unicornx.github.io/2016/01/06/20160106-c-oob/ 12345678910111213struct foo { int a; int b; int c; struct foo_operations ops;};struct foo_operations { void (*op_a) (struct foo *, loff_t, int); void (*op_b) (struct foo *, char __user *, size_t, loff_t *); void (*op_c) (struct foo *, const char __user *, size_t, loff_t *); ......}; 源码阅读readahead针对readahead问题，在readahead.c文件中实现了内核模块。 module_init(kml_readahead_init)指明了模块的入口点。 kml_readahead_init创建了两个内核线程，然后设置跟踪点。 1234567891011121314151617181920static int __init kml_readahead_init(void) { ... kml_readahead_update_thread = kthread_run(&amp;readahead_update, NULL, \"kml_readahead_update\"); kml_perf_monitoring_thread = kthread_run(&amp;perf_monitoring, NULL, \"kml_perf_monitoring\"); ... set_trace_readahead_add_to_page_cache_fptr( (void *)&amp;readahead_add_to_page_cache);//函数指针 set_trace_readahead_mm_filemap_fsl_read_fptr( (void *)&amp;readahead_mm_filemap_fsl_read); set_trace_readahead_fsl_writeback_dirty_page_fptr( (void *)&amp;readahead_fsl_writeback_dirty_page); set_trace_readahead_get_tuning_device_fptr( (void *)&amp;readahead_get_tuning_device); set_trace_readahead_get_disk_ra_val_fptr((void *)&amp;readahead_get_disk_ra_val); //(void *)&amp; a,取a的地址，然后转化为无类型指针。 ... return 0;} 12345678910111213141516171819202122232425262728293031323334353637383940void readahead_add_to_page_cache(struct page *page) { unsigned long index = 0, i_ino = 0; u64 time_passed; u64 data_process_start, data_process_end; dev_t blk_dev_no = 0; double data[3]; if (page != NULL) { index = page-&gt;index; if (page-&gt;mapping != NULL &amp;&amp; page-&gt;mapping-&gt;host != NULL) { i_ino = page-&gt;mapping-&gt;host-&gt;i_ino; blk_dev_no = page-&gt;mapping-&gt;host-&gt;i_sb ? page-&gt;mapping-&gt;host-&gt;i_sb-&gt;s_dev : page-&gt;mapping-&gt;host-&gt;i_rdev; if (blk_dev_no != tunning_device_number) { return; } } } time_passed = kml_get_current_time(); time_passed = kml_get_time_diff(time_passed, start_time); if (module_exiting) return; kernel_fpu_begin(); data[0] = time_passed; data[1] = i_ino; data[2] = index; data_process_start = kml_get_current_time(); if (readahead_data_processing(data, (readahead_net *)readahead, disk_base_readahead_val, true, false, i_ino)) { } data_process_end = kml_get_current_time(); data_process_total += kml_get_time_diff(data_process_end, data_process_start); kml_atomic_add(&amp;data_process_count, 1); kernel_fpu_end();} 问题为什么不用mmap https://blog.acolyer.org/2016/04/26/the-linux-scheduler-a-decade-of-wasted-cores/","link":"/2022/01/13/KML%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/"},{"title":"KMP字符串匹配","text":"KMP学习记录 next数组next[j] = k 代表 p[j] 之前的模式串子串中，有长度为k 的相同前缀和后缀，p0 p1, …, pk-1 = pj-k pj-k+1, …, pj-1 已知next [0, …, j]，求next [j + 1] 对于P的前j+1个序列字符： 若p[k] == p[j]，则next[j + 1 ] = next [j] + 1 = k + 1；若p[k ] ≠ p[j]，如果此时p[ next[k] ] == p[j]，则next[ j + 1 ] = next[k] + 1，否则继续递归前缀索引k = next[k]，而后重复此过程。 如果p[k] == p[j]，就是再原有最长前后缀的基础上多了一位 如果p[k] ≠ p[j]，就找更小的前缀，使得前缀的前缀能和后缀+1位匹配上，由于前缀的后缀是能和后缀匹配上的，所以要找的是前缀的最长公共前后缀","link":"/2020/03/09/KMP%E5%AD%97%E7%AC%A6%E4%B8%B2%E5%8C%B9%E9%85%8D/"},{"title":"Linux下的epoll和I/O复用","text":"学libco过程中遇到了epoll和I/O复用相关概念。 网络编程流程 阻塞IO和非阻塞IO每个连接都会对应一个读缓冲区和写缓冲区 阻塞在哪？ 阻塞在网络线程，比如调用了read/recv，下面的就不能运行，程序就卡在那里 阻塞和非阻塞的差异？ IO函数在数据到达时是否立刻返回，立刻返回的是非阻塞 阻塞和非阻塞由什么决定？ fd决定，默认fd是阻塞。 fcntl可以设置fd为非阻塞 阻塞IO 数据准备阶段是看readbuffer是否有数据，数据到达后把数据拷贝到用户空间，也就是应用程序中，这个是数据拷贝阶段。 非阻塞IO 假设当前readbuffer没有数据，调用read/recv会立马返回，继续执行read后面的逻辑 阻塞非阻塞 同步和异步阻塞和非阻塞强调的是线程的状态。 同步和异步强调的是执行顺序，同步可以确定程序执行的顺序调用，调用返回之前下一行代码不会调用。异步调用不明确执行顺序。 I/O多路复用 用一个线程检测多个IO事件，复用的是网络线程 早期，为了实现一个服务器支持多个客户端的连接，使用fork/thread一个进程/线程的方式去接受并处理请求。这是阻塞IO+多线程，优点处理及时，但是线程利用率低，线程数有限。 一个连接到来后，遍历所有的已注册的文件描述符，找到需要处理的文件描述符，也就是select和poll。 IO多路复用作用在数据准备阶段 由于遍历引起的巨大开销O(n)，在原有的基础上进一步优化，有了epoll的方法。 epoll epoll是linux内核的可扩展I/O事件通知机制。 使用一个文件描述符管理多个描述符。 epoll epoll 全程 event poll 事件轮询 epoll实际是从操作系统订阅消息。 epoll将进程关注的文件描述符存入一颗红黑树，在这棵红黑树中，key是socket的编号，值是socket关注的消息。当内核发生了一个事件的时候，比如socket编号1000可以读取，这个时候就从红黑树查找进程是否关注了这个事件。 为什么用红黑树：内核可以快速判断某个消息是否需要发送给使用epoll的线程。 当关注的事件发生时，epoll会将这个fd放到一个就绪队列中，当用户调用epoll_wait的时候，就会从队列中返回一个消息。epoll_wait不一定立刻返回，可以设置timeout，如果设置成0就立刻返回，epoll就是非阻塞的。 程序接口1int epoll_create(int size); 在内核中创建epoll实例，并返回一个epoll文件描述符。size是要监听的文件描述符数量，大于size的话内核会自动扩容。 1int epoll_ctl(int epfd, int op, int fd, struct epoll_event *event);//ctl就是control 向epfd对应的内核epoll实例添加、修改或删除对fd事件event的监听。 op 为 EPOLL_CTL_ADD：往事件表中注册fd上的事件 EPOLL_CTL_MOD：修改fd上的注册事件 EPOLL_CTL_DEL ：删除fd上的注册事件 如果 event 的 events 属性设置了 EPOLLET flag，那么监听该事件的方式是边缘触发。 1int epoll_wait(int epfd, struct epoll_event *events, int maxevents, int timeout); 当 timeout 为 0 时，epoll_wait 立即返回。 timeout 为 -1 时，epoll_wait 会阻塞直到已注册的事件变为就绪。 当 timeout 为一正整数时，epoll 会阻塞直到计时 timeout 毫秒或已注册的事件变为就绪。（因为内核调度延迟，阻塞会略微超过 timeout 毫秒）。 epoll的实现重要数据结构12345struct eventpoll { struct rb_root rbr; //红黑树,管理epoll监听的事件 struct list_head rdlist;//保存epoll_wait 返回满足条件的时间 ...}; 123456789101112struct epoll_event { __uint32_t events; /* Epoll events */ epoll_data_t data; /* User data variable */};events可以是以下几个宏的集合：EPOLLIN ：表示对应的文件描述符可以读（包括对端SOCKET正常关闭）；EPOLLOUT：表示对应的文件描述符可以写；EPOLLPRI：表示对应的文件描述符有紧急的数据可读（这里应该表示有带外数据到来）；EPOLLERR：表示对应的文件描述符发生错误；EPOLLHUP：表示对应的文件描述符被挂断；EPOLLET： 将EPOLL设为边缘触发(Edge Triggered)模式，这是相对于水平触发(Level Triggered)来说的。EPOLLONESHOT：只监听一次事件，当监听完这次事件之后，如果还需要继续监听这个socket的话，需要再次把这个socket加入到EPOLL队列里 描述监控事件，events对应文件描述符事件 epoll_data_t是一个联合体，同一时间只能使用一个字段 123456typedef union epoll_data { void *ptr; int fd; __uint32_t u32; __uint64_t u64;} epoll_data_t; 事件发生时，用户设置的data字段将会返回给使用者 原理图 mmapmmap将用户空间的一块地址和内核空间的一块地址同时映射到相同的一块物理内存地址，这块物理内存对内核和用户均可见，内核可以直接看到epoll监听的句柄。 红黑树 二叉搜索树 存储epoll监听的套接字fd。存储到mmap出来的内存。添加或者删除一个套接字（epoll_ctl）时，都在红黑树上去处理。 通过epoll_ctl 添加进来的fd都会放在红黑树的节点内。 同时与网卡驱动建立回调关系，如果网卡驱动检测到节点有事件，节点会被拷贝到就绪队列 双向链表先看epoll_wait做了什么： 调用ep_poll，当双向链表中无就绪fd，挂起当前进程，直到链表不为空。 当文件fd状态改变，不可读/不可写变为可读/可写，对应fd上的回调函数ep_poll_callback会被调用 ep_poll_callback将相应fd对应的epitem加入链表，导致链表不为空，进程被唤醒，epoll_wait继续执行。 ep_event_transfer函数将rdlist中的epitem拷贝到txlist,rdlist清空 ep_send_event，扫描txlist中的每个epitem，调用关联fd对应的poll方法，从而获得fd上较新的events，封装在epoll_event从epoll_wait返回。 epoll使用123456789101112131415161718192021222324int listenfd = socket;bind(listenfd,addr);listen(listenfd);int efd = epoll_create(0);//创建根节点epoll_ctl(efd,epoll_ctl_add,listenfd,&amp;ev);//把fd放到红黑树while (true) { epoll_event ev[size];//需要在用户态分配内存 int nevent = epoll_wait(efd,ev,size,timeout);//作用在数据准备阶段 for(int i = 0; i &lt; nevent; i++) { epoll_event *e = ev[i]; if(e-&gt;fd == listenfd) { int clientfd = accept(listenfd); epoll_ctl(efd,epoll_ctl,clientfd.&amp;env); } else { if (读事件) { read(); logic; send(); } if (写事件) send(); if (错误事件) close(); } }} epoll的ET与LT ET：边沿触发 LT:水平触发 LT水平EPOLLIN的触发条件是 *读缓冲区非空 * EPOLLOUT的触发条件是 *写缓冲区非满 * ET边沿EPOLLIN的触发条件：对端有数据写入才会触发，所以触发一次要不断读数据直到所有的数据都读完，否则只能登下次对端写入了。所以epoll必须要求异步socket。 EPOLLOUT的触发：连接时触发一次，表示可写。 ​ 或者某次write，写满了发送缓冲区，对端读了一些数据，又重新可写了 ​ 也就是说EPOLLOUT发生在不写到可写转化的时刻。 ​ 如果想人为的强制触发，使用epoll_ctl重新设置event就可以，会马上触发一次EPOLLOUT事件。 reactor 组成：非阻塞IO+IO多路复用 特征：基于事件循环，以事件驱动或者事件回调来实现业务逻辑 Reactor： 即非阻塞同步网络模型，可以理解为，向内核去注册一个感兴趣的事件，事件来了去通知你，你去处理 Proactor： 即异步网络模型，可以理解为，向内核去注册一个感兴趣的事件及其处理handler，事件来了，内核去处理，完成之后告诉你 reactor要求主线程（I/O处理单元）只负责监听文件描述符上是否有事件发生，有的话就通知工作线程（逻辑单元），读写数据，接受新的连接，处理客户请求均在工作线程中完成。 使用同步I/O模型实现的reactor模式的工作流程为： 主线程向epoll内核事件表中注册socket上的读就绪事件 主线程调用epoll_wait等待socket上有数据可读 当socket上有数据到达，epoll_wait通知主线程，主线程将socket可读事件放入请求队列 睡眠在请求队列上的某个工作线程被唤醒。这个工作线程从socket上读取数据，并处理客户请求，然后往epoll内核事件表中注册该socket上的写就绪事件。 主线程调用epoll_wait等待socket可写。 socket可写时，epoll_wait通知主线程，主线程将socket的可写事件放入请求队列 睡眠在请求队列上的某个工作线程被唤醒，向客户发送服务器的处理结果。 参考https://www.cnblogs.com/shine-yr/p/5214705.html","link":"/2021/01/11/Linux%E4%B8%8B%E7%9A%84epoll%E5%92%8CI-O%E5%A4%8D%E7%94%A8/"},{"title":"Linux内核之内存管理","text":"虚存管理：inux进程可以划分为多个不同的内存区域：代码段、数据段、BSS段、堆、栈。Linux内核把这些区域抽象成vm_area_struct的对象进行管理。 前置知识区分逻辑地址、线性地址、物理地址 分段和分页都是由CPU提供的。 虚拟地址包括了逻辑地址和线性地址，程序员用的其实是逻辑地址，分页机制可以绕开，单分段机制绕不开 12int test;int *ptr = &amp;test;//ptr放的是逻辑地址的偏移量，段基址放在寄存器里 疑问： 既然指针变量存的是偏移量，那为什么写程序的时候不用考虑段寄存器？ Linux和windows使用的是平坦内存模型，x64直接忽略了段描述符中的段基址和段界限，cpu直接支持flat模式。（fs,gs例外） 分段和分页都是由CPU提供的，intel开发手册，查看卷3，第三章保护模式下的内存管理。 gdtr寄存器的特殊之处：不能使用mov指令访问gdtr寄存器，必须使用sgdt（访问）和lgdt（写入load）指令访问，这两个指令是特权指令，ring0才能访问。 逻辑地址就是应用程序员能看到的地址，就是机器语言中引用一个操作数或者是指定的地址 逻辑地址又叫虚拟地址 逻辑地址：段选择符+段内偏移量 CPU中有一个MMU，MMU中有一个分段单元的逻辑电路把逻辑地址转换成线性地址。 Linux有限度的使用了分段机制，有限制就是说所有的段基址都为0，所以在linux系统下，逻辑地址（虚拟地址）就等于线性地址 段基址就是根据段选择符查到的段描述符里的base字段 所有进程使用了相同的段寄存器，也就是不同的进程共享了同样的一组线性地址。 这样设计Linux可以移植到大多数处理器平台，比如一些不支持分段的体系结构。 内核的虚拟地址到物理地址只差了一个偏移，而用户空间的虚拟地址到物理地址则用了多久页表进行映射 为什么要分段？比如8086，8088，16位的CPU要访问20位的内存总线 为什么分页？比如要支持虚拟内存，内存不够要换页 内存管理 内核使用node、zone、page三级结构描述物理内存 页 页是内核管理内存的基本单位。MMU内存管理单元以页位单位管理系统中的页表。 123456789101112struct page { page_flags_t flags; //页状态，页是不是脏的，有没有锁定在内存中等等 atomic_t _count;//页被引用了多少次，没有引用的时候就可以在新的分配中使用它 atomic_t _mapcount; unsigned long private; struct address_space *mapping; pgoff_t index;//包含页的最近最少使用的双向链表的指针。 struct list_head lru;#if defined(WANT_PAGE_VIRTUAL) void *virtual;//如果进行了内存映射，就是虚拟地址。对存在高端内存的系统来说有意义。#endif /* WANT_PAGE_VIRTUAL */}; 页表转换谁执行page walk？CPU 页表由谁创建？操作系统，但是CPU规定了页表长什么样，即页表规范 谁会设置或修改页表？CPU会，OS也会 Intel CPU提供了多种页表结构： 二级页表：32位非PAE模式 三级页表：PAE模式 四级页表：IA-32e，即64位模式 32位页表 重点还是64位下的： 其实只有48位，前面16位是符号位扩展。 用户空间是0000，内核空间是FFFF。 page map level-4 table在linux里叫pgd page-directory pointer table在linux里叫pud page directory在linux里叫pmd 如果PS = 1，后面就是offset，为0表示还有下一级页表 P位代表是否存在（被换到磁盘），RW位就是读写权限 区内核的虚拟地址空间分为三个类型的区，这三个区又线性映射到物理内存上。 ZONE_DMA：这里的页只能执行DMA操作（0~16MB） ZONE_NORMAL：正常映射的页（16~896MB） ZONE_HIGHEM：高端内存(动态映射) 什么是高端内存内核态下虚拟地址和物理地址是一个线性关系，就是所谓的内核线性地址空间，两者存在一个固定的offset，物理地址 = 逻辑地址 – 0xC0000000 x86-32位系统下，linux按照3：1来划分虚拟内存，3GB是用户空间，1GB是内核空间。 也就是说内核只能用1GB的地址空间来映射物理地址空间，如果内存大于1G的情况下，线性地址就不够用了。因此内核引入了一个高端内存的概念，小于896M的 叫低端内存，剩下的128M的线性空间用来灵活映射大于896M的物理地址空间，这128M就是我们说的高端内存区。 对于64位系统，地址空间足够用，就不用高端内存区了。 比如ARM-64的内核地址空间布局： 页管理struct page * alloc_pages(gfp_t gfp_mask,unsigned order)分配$2^(order)$个连续的物理页，并返回指向第一个页的指针。 void * page_address(struct page *page)返回给定物理页的逻辑地址 unsigned long __get_free_pages(gfp_t gfp_mask, unsigned int order)也是分配物理页，当时返回的是分配的第一个页的逻辑地址。 还有获取填充为0的页，释放页等等 kmalloc()、kfree（）和vmalloc()这两个是对应的，用于获得以字节为单位的一块内核内存，释放由kmalloc分配出来的内存块。 kmaclloc确保分配出来的内存页在物理地址上是连续的，虚拟地址自然也是连续的。 分配的内存在虚拟地址上是连续的，而在物理内存上不一定连续，也是用户空间分配函数的工作方式。 他分配非连续的物理内存块，再修改页表，把内存映射到逻辑地址空间的连续区域中。 大多数情况下，只有硬件设备才需要连续的物理内存，因为硬件设备位于MMU之外，尽管如此，内核还是尽量使用kmalloc，因为这样可以提高性能，vmalloc需要对获得的页建立页表项一个个映射，还可能会导致TBL抖动。 slab分配器slab描述符1234567struct slab { struct list_head list;//slab高速缓存描述符的三个双向循环链表中的一个。 unsigned long colouroff;//slab中第一个对象的偏移。 void *s_mem;//slab中第一个对象的地址。 unsigned int inuse;//当前正在使用的slab中的对象个数。 kmem_bufctl_t free;//slab中下一个空闲对象的下标}; 高速缓存描述符1234567891011121314struct kmem_cache_s { struct array_cache *array[NR_CPUS];//每个CPU都有一个slab空闲对象缓存 unsigned int batchcount;//要转移进本地高速缓存或从本地高速缓存中转移出的大批对象的数量。 unsigned int limit;//本地高速缓存中空闲对象的最大数目。这个参数可调。 struct kmem_list3 lists; /* NUMA: kmem_3list_t *nodelists[MAX_NUMNODES] */ unsigned int objsize;//高速缓存中包含的对象的大小。 ... unsigned int gfporder;//一个单独slab中包含的连续页框数目的对数。 ... size_t colour; //slab使用的颜色个数。用于slab着色。 unsigned int colour_off; //slab中的基本对齐偏移。 ...}; 虚存管理进程的地址空间内存描述符 内存描述符mm_struct是进程描述符中的一个字段，包含了进程地址空间有光的全部信息 1234567891011121314struct mm_struct { struct vm_area_struct * mmap;//指向线性区对象的链表头 struct rb_root mm_rb;//指向红黑树的根 //这是内存区域的两种不同的组织结构，实际包含的内容是一样的，根据不同的需求选用不同的结构。 ... pgd_t * pgd;//指向页全局目录，根据多级页表的设计最终找到物理页面 atomic_t mm_count;//引用计数 struct list_head mmlist; ... unsigned long start_code, end_code, start_data, end_data;//代码段和数据段的地址 unsigned long start_brk, brk, start_stack;//堆和栈的地址 unsigned long arg_start, arg_end, env_start, env_end;//参数和环境变量 ...} mm_struct是否共享决定了是进程还是线程。 mm_struct是对整个用户空间的描述 虚拟内存区域VMA VMA 一个进程有多个不同的段，段用vm_area_struct进行描述，通过mmap创建。另外，堆和栈也是有自己的vma的。 使用pmap或cat /proc/pid/maps看到的就是进程的不同的区。如果有动态链接的情况，进程的地址空间也会包含链接库的代码段、数据段、bss段。 12345678struct vm_area_struct { struct mm_struct; //指向关联的mm unsigned long vm_start,vm_end;//段的首位地址 ... unsigned long vm_flags;//不同标志组合成不同的权限，从而决定不同的段的属性 ... unsigned long vm_pgoff;//在映射文件中的偏移量，以页为单位，处理页错误时候使用。} ELF和Linux进程虚拟地址空间的映射关系 ELF文件中有一个程序头，程序头描述了ELF文件该被如何转载到进程的虚拟地址空间。 ELF引入了一个叫Segment的概念，一个Segment包含一个或者多个属性类似的Section，比如.init和.text是两个属性类似的Section，这两个段被看作是一个Segment，在装载的时候对应了一个VMA，这样减少了页面的内部碎片。 Segment是从装载的角度对Section进行了划分，链接的时候，属性类似的段放在一个空间，这个属性是说权限，比如可读可执行。 在ELF文件中，描述Section的叫做段表，表示Segment的叫程序头，程序头才描述了ELF文件该被操作系统如何映射到进程的虚拟地址空间。 使用readelf -l读取程序头，比如： 不一定是每个Segment都要被映射到虚拟地址空间的，类型位LOAD的才需要，别的是装载时起辅助作用。 实际上程序头里写的各段转载虚拟地址并不一定跟linux装载后完全对应，linux装载时有一些特殊的处理，另外对于PIE地址无关编译的情况，程序头里代码段虚拟地址总是从0开始，实际情况下是随机的，各段共用了一个随机偏移量。 参考linux2.6.11源码 《Linux内核设计与实现》第十二章、十五章 《程序员的自我修养》 《深入理解LINUX内核》第二章 pie编译选项","link":"/2021/08/02/Linux%E5%86%85%E6%A0%B8%E4%B9%8B%E5%86%85%E5%AD%98%E7%AE%A1%E7%90%86/"},{"title":"Linux内核之内核数据结构","text":"Linux内核中用到的一些数据结构 kfifo内核中循环队列的实现 对于两个线程一个入队一个出队的并发操作，循环队列不加锁就可以保证线程安全。 1234567struct kfifo { unsigned char *buffer; /* the buffer holding the data */ unsigned int size; /* the size of the allocated buffer */ unsigned int in; /* data is added at offset (in % size) */ unsigned int out; /* data is extracted from off. (out % size) */ spinlock_t *lock; /* protects concurrent modifications */}; 循环队列初始化12345678910111213141516171819202122232425struct kfifo *kfifo_alloc(unsigned int size, int gfp_mask, spinlock_t *lock){ unsigned char *buffer; struct kfifo *ret; /* * round up to the next power of 2, since our 'let the indices * wrap' tachnique works only in this case. */ if (size &amp; (size - 1)) { //判断size是否是二的幂 BUG_ON(size &gt; 0x80000000); size = roundup_pow_of_two(size); } buffer = kmalloc(size, gfp_mask); if (!buffer) return ERR_PTR(-ENOMEM); ret = kfifo_init(buffer, size, gfp_mask, lock); if (IS_ERR(ret)) kfree(buffer); return ret;} 注意到一点是，size需要为2的n次幂，否则就向上取整进行扩展。这样是为了将模运算转化为与运算，提高效率 kfifo-&gt;in % kfifo-&gt;size 转化为 kfifo-&gt;in &amp; (kfifo-&gt;size – 1)，因为size-1一定是01111…这种形式的，取模就是一个保留低位舍弃高位的过程，刚好是01111..这样的二进制数取与的过程。 另外判断一个数不是二的幂用了size &amp; (size - 1)，例如100000&amp;011111 = 0，也就是只有二的幂，与自己-1的数取与会得到0。 入队123456789101112131415161718unsigned int __kfifo_put(struct kfifo *fifo, unsigned char *buffer, unsigned int len)//buffer是要加入队列的数据，len是buffer的长度{ unsigned int l; len = min(len, fifo-&gt;size - fifo-&gt;in + fifo-&gt;out);//需要长度和空闲长度的最小值 /* first put the data starting from fifo-&gt;in to buffer end */ l = min(len, fifo-&gt;size - (fifo-&gt;in &amp; (fifo-&gt;size - 1)));//需要长度和末端长度的最小值 memcpy(fifo-&gt;buffer + (fifo-&gt;in &amp; (fifo-&gt;size - 1)), buffer, l);//一部分放到末端 /* then put the rest (if any) at the beginning of the buffer */ memcpy(fifo-&gt;buffer, buffer + l, len - l);//一部分放到起端 fifo-&gt;in += len;//in和out始终是线性增大的，但溢出的时候，重新从0开始增长 return len;} 根据buffer的长度，分成了两部分进行入队 （在图上，in指针也不一定在out的右边，比如in一直写，是可能在out左边的，这也是出队时候可能会分成两部分memcpy的原因。但是数值上始终满足in&gt;out，in-out&lt;size） 出队123456789101112131415161718unsigned int __kfifo_get(struct kfifo *fifo, unsigned char *buffer, unsigned int len){ unsigned int l; len = min(len, fifo-&gt;in - fifo-&gt;out); /* first get the data from fifo-&gt;out until the end of the buffer */ l = min(len, fifo-&gt;size - (fifo-&gt;out &amp; (fifo-&gt;size - 1))); memcpy(buffer, fifo-&gt;buffer + (fifo-&gt;out &amp; (fifo-&gt;size - 1)), l);//to,from /* then get the rest (if any) from the beginning of the buffer */ memcpy(buffer + l, fifo-&gt;buffer, len - l); fifo-&gt;out += len; return len;} 跟入队类似。 kfifo使用in和out两个指针来描述写入和读取游标，对于写入操作，只更新in指针，而读取操作，只更新out指针为了避免读者看到写者预计写入，但实际没有写入数据的空间，写者必须保证以下的写入顺序： 1.往[kfifo-&gt;in, kfifo-&gt;in + len]空间写入数据2.更新kfifo-&gt;in指针为 kfifo-&gt;in + len 在操作1完成时，读者是还没有看到写入的信息的，因为kfifo-&gt;in没有变化，认为读者还没有开始写操作，只有更新kfifo-&gt;in之后，读者才能看到。 那么如何保证1必须在2之前完成，秘密就是使用内存屏障：smp_mb()，smp_rmb(), smp_wmb()，来保证对方观察到的内存操作顺序。 关于内存屏障：https://blog.csdn.net/weixin_30446197/article/details/96602025?utm_medium=distribute.pc_relevant.none-task-blog-2~default~baidujs_title~default-1.pc_relevant_antiscanv2&amp;spm=1001.2101.3001.4242.2&amp;utm_relevant_index=4 memcpy后修改out，修改out之前其实是要加内存屏障的，因为可能memcpy还没完成，out已经被修改了。 参考资料https://www.cnblogs.com/blogs-of-lxl/p/10570885.html","link":"/2021/08/27/Linux%E5%86%85%E6%A0%B8%E4%B9%8B%E5%86%85%E6%A0%B8%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/"},{"title":"Linux内核之块IO层","text":"Linux IO体系VFS层屏蔽了不同文件系统的差异，想上层提供统一的文件读写访问接口 FS层具体的文件系统层","link":"/2022/02/21/Linux%E5%86%85%E6%A0%B8%E4%B9%8B%E5%9D%97IO%E5%B1%82/"},{"title":"Linux内核之文件系统","text":"对于read 和 write。 在 VFS 层调用的是 vfs_read 和 vfs_write 并且调用 file_operation。 在 ext4 层调用的是 ext4_file_read_iter 和 ext4_file_write_iter。 接下来就是分缓存 I/O 和直接 I/O。直接 I/O 读写的流程是一样的，调用 ext4_direct_IO，再往下就调用块设备层了。缓存 I/O 读写的流程不一样。对于读，从块设备读取到缓存中，然后从缓存中拷贝到用户态。对于写，从用户态拷贝到缓存，设置缓存页为脏，然后启动一个线程写入块设备。","link":"/2022/05/05/Linux%E5%86%85%E6%A0%B8%E4%B9%8B%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F/"},{"title":"Linux内核之进程管理","text":"Linux内核之进程管理 进程描述符 进程描述符 task_struct 就是PCB，其结构定义在&lt;include/linux/sched.h&gt;中，包含内核管理一个进程需要的信息 内核中有一个双向循环链表，所有进程也是用双向链表连接的。 123struct list_head { struct list_head *next, *prev;}; 在linux 2.6.11的代码中，list_head是task_struct中的一个字段。 注意到的一点是，这里的双向链表和以前认识里的带data域的双向链表不同，这种结构实际上是一种侵入式链表，数据是附加到链表的，这样设计的双向链表是通用的，就不用考虑节点的数据类型了。 但是这样如何根据链表的指针获取外层的结构体？ Linux实现了一个特殊的宏 1234#define list_entry(ptr, type, member) container_of(ptr, type, member) //ptr是成员变量指针，type是结构体的类型，member是ptr的变量名#define list_entry(ptr, type, member) / ((type *)((char *)(ptr)-(unsigned long)(&amp;((type *)0)-&gt;member))) 这个宏可以通过结构体某个成员的指针获取整个结构体的指针。 (unsigned long)(&amp;((type *)0)-&gt;member)：得到的就是ptr指向的mebmer相对于结构体基址的偏移量，与ptr结构体成员指针相减就得到了结构体的基址。 这是因为在C语言中，一个给定结构中的变量偏移在编译时就被ABI固定下来了。 进程描述符通过slab分配器进行分配，在内核栈底或栈顶创建一个thread_info的结构，这个结构中有指向进程描述符的指针 thread_info结构定义在&lt;asm/thread_info.h&gt;下 1234567891011struct thread_info { struct task_struct *task; /* mtain task structure */ struct exec_domain *exec_domain; /* execution domain */ __u32 flags; /* low level flags */ __u32 status; /* thread synchronous flags */ __u32 cpu; /* current CPU */ int preempt_count; mm_segment_t addr_limit; struct restart_block restart_block;}; 进程创建Unix用两个函数实现进程的创建：fork()和exec() fork()拷贝当前进程创建一个子进程，子进程和父进程只有pid,ppid和一些统计量不同，其他是一样的。 然后用exec()读取可执行文件并载入地址空间开始执行。 写时拷贝的优化fork使用写时拷贝实现。fork的时候内核不赋值整个进程的地址空间，而是父子进程暂时共享同一份拷贝。子进程需要写入的时候，数据才会被复制，对于fork后立刻exec的情况下，就不需要复制了。 因此fork的实际开销： 复制父进程的页表 给子进程创建task_struct进程描述符 fork的实现 实际就是复制父进程的页表，并给子进程创建唯一的进程描述符 linux通过调用clone实现fork，vfork，__clone pthread_create会调用__clone()，最后会通过不同的flags去调用clone()，flags设置为共享进程的地址空间，共享文件系统信息，共享打开的文件，共享信号处理程序。 fork调用clone时，四个标志都不设置创建的是进程。反正创建的是线程。 linux中线程的实现从2.6.11内核的角度来说，并没有线程的概念。linux把所有线程都当成进程来对待，也没有特别的调度算法和数据结构来表示线程。 linux内核把线程看作与其他进程共享某些资源的进程，所以linux里的线程还是进程，也有自己的task_struct。 linux中的线程是种轻量级进程实现LWP。 123456struct task_struct { ... pid_t pid;//pid对进程和线程都是独一无二的 pid_t tgid;//linux中线程实现的核心成员，表示线程组id ...} 当用pthread_create创建一个线程时，会创建一个新的task_struct，这个进程描述符有独一无二的pid，但是这个线程的tgid等于原始进程的pid，这个进程创建的所有线程的tgid都是原始进程的pid，领头进程的进程号。 命令ps和getpid()查到的pid是task_struct中的tgid成员，LWP号才是真正的pid。 12345struct tast_struct { ... struct mm_struct *mm, *active_mm;//内存区描述符，对于线程是共享的 ...} 多线程出现后，CPU的调度是以线程为单位进行调度，资源分配还是以进程为单位。 线程模型线程分用户级线程与内核级线程（根据运行环境和调度者的身份）。（区别内核线程，内核线程是没有用户空间的完全工作与内核的线程。） 用户线程运行在用户空间，由线程库调度，内核根本不知道这些线程的存在。 内核线程相当与用户线程运行的容器，一个进程可以拥有M个内核线程和N个用户线程，M&lt;=N 线程实现形式的不同，决定了不同的M和N。 对于M:N=M:1的实现，也就是M个用户空间线程对应一个内核线程，这种就是完全在用户空间实现的线程，这种实现不占用内核资源，速度相当快，创建和调度也不用内核干预，tcb在用户空间，缺点就是对于多CPU系统，一个进程的不同线程也无法运行在不同的CPU上。协程就是用户级线程，这样设计避免了频繁的上下文切换。 对于M:N = 1:1的实现，一个用户空间线程被对应为一个内核线程，tcb在内核空间，linux的tcb还是task_struct，这种是内核级的线程，NPTL项目pthread就是这种实现方式。pthread_create会调用clone系统调用，由操作系统创建内核级线程，也就是轻量级进程。 现代线程都是1：1的，每个线程有两个栈，一个用户空间的一个内核的。 进程线程区别创建进程的话，调用的系统调用是 fork，在 copy_process 函数里面，会将五大结构 files_struct、fs_struct、sighand_struct、signal_struct、mm_struct 都复制一遍，从此父进程和子进程各用各的数据结构。 而创建线程的话，调用的是系统调用 clone，在 copy_process 函数里面， 五大结构仅仅是引用计数加一，也即线程共享进程的数据结构。 进程切换 进程切换的关键操作：切换地址空间、切换内核堆栈、切换内核控制流程以及必要寄存器的现场保护与还原。 进程调度 调度需要关注什么时候进行切换和选择哪个进程来运行，这其实是个数学问题，给定一组参数，比如线程的优先级，使用的时间，然后返回下一个要运行的线程是谁。 内核2.6以前使用的是O(n)调度法，2.6版本替换为了O(1)调度法（2003年）。 O(1)调度法对每个优先级用两个链表管理运行的进程，一个是ready-to-run的就绪链表，一个是耗尽时间片的链表。 后来，Linux放弃了预定义的时间片的概念，引入了完全公平调度（CFS）到Linux 2.6.23内核中（2007年），直到现在也一直作为Linux的调度器。 CFS以模块方式组织，也就是实现了多个调度类，不同类型的进程选择不同的调度算法。比如，rt class调度试试进程，fair class才是CFS的实现，idle class处理没有任务运行的情况。 多核调度 多核调度的重点是load balance，其余的看成是单核调度的复刻 多核调度需要额外考虑的问题： 一个核的两个超线程不需要平衡：一个核有两个超线程，他们共享相同的执行部件，那么再平衡是没有意义的 跨核调度：如果轻易的跨核调度可能引发大量的cache失效，因为L1 L2cache是不共享的 线程NUMA系统的一个Node迁移到另一个 考虑CPU的休眠和降频的方式降低功耗，比如两个进程是在一个核上，另一个核休眠，或者分配到两个核上一起降频 CFS定期以软中断的形式周期执行load balance的代码，将任务从最繁忙的核中提取出来转移到空闲的核中来实现平衡，负载均衡的决策以来与缓存和NUMA的位置。CFS将core按层次结构划分为每个硬件级别的调度域（sched_domain），load balance在每个sched_domain执行。一个sched_domain中的cpu核又被划分为不同的调度组（sched_group），不同的组之间可以进行线程的迁移。 CFS负载均衡内核线程https://mp.weixin.qq.com/s/GO0z646XZko_pUvmMSa9RQ 问题 一个多线程的进程fork出来的进程是多线程的吗？答案不是，fork出来的进程只有一个线程，就是调用fork的那个线程。 CFS的公平的含义是什么？ 参考资料Linux下调用pthread库创建的线程是属于用户级线程还是内核级线程？求大神指教? - 大河的回答 - 知乎 https://www.zhihu.com/question/35128513/answer/148038406 linux2.6.11源码 《linux内核设计与实现》 https://www.bilibili.com/video/BV1ov41157pA?from=search&amp;seid=15110093483709811855 http://home.ustc.edu.cn/~hchunhui/linux_sched.html https://cloud.tencent.com/developer/article/1759921 cgroups:https://tech.meituan.com/2015/03/31/cgroups.html","link":"/2021/07/26/Linux%E5%86%85%E6%A0%B8%E4%B9%8B%E8%BF%9B%E7%A8%8B%E7%AE%A1%E7%90%86/"},{"title":"Linux内核套接字实现","text":"套接字数据结构 linux系统下，每个套接字都有一个struce socket和struc sock的数据结构实例。 struct socket1234567891011struct socket { socket_state state;//套口状态，如SS_FREE unsigned long flags;//套口标志位，如SOCK_ASYNC_NOSPACE struct proto_ops *ops;//传输层提供的接口方法。如inet_stream_ops，inet_dgram_ops，inet_sockraw_ops struct fasync_struct *fasync_list;//异步通知队列。用于异步IO struct file *file;//与套口相关联的文件指针。 struct sock *sk;//与套口相关联的传输控制块。 wait_queue_head_t wait;//等待该套口的进程列表。 short type;//套口类型，如SOCK_STREAM。 unsigned char passcred;//是否设置了SO_PASSCRED选项。}; struct socke与socket描述符一一对应，每个套接字都对应内核中唯一的struct socket，struct sock是struce socket中的一个字段。 struct socksock结构体包含了套接字的全部属性，其中的一个sock_common是套接字的共有属性，所有协议族的这些属性都是一样的。 sock_common是sock里的一个成员，最重要的成员就在sock_common里。 12345678910111213struct sock { struct sock_common __sk_common; ...//很多特性很少用到，重点看sock_common}struct sock_common { unsigned short skc_family;//所属协议族 volatile unsigned char skc_state;//连接状态，对UDP来说，存在TCP_CLOSE状态 unsigned char skc_reuse;//是否可以重用地址和端口,SO_REUSEADDR设置 int skc_bound_dev_if;//如果不为0，则为绑定的网络接口索引，使用此接口输出报文 struct hlist_node skc_node;//通过此节点，将控制块加入到散列表中 struct hlist_node skc_bind_node;//如果已经绑定端口，则通过此节点将控制块加入到绑定散列表中 atomic_t skc_refcnt;//引用计数}; 从hlist_node成员可以看出，sock组织在特定协议的哈希链表中，skc_node是哈希节点。 socket在内核中的组织 套接字接口socketsocket()创建套接字，产生系统调用中断，调用内核套接字函数sys_socketcall，在将调用传送到sys_socket函数， sock_create函数完成通用的套接字创建初始化工作，其中就创建了新的struct socket。 sock_alloc分配了struct socket需要的预留内存空间，也会分配struct inode实例的内存空间。 然后调用特定的协议族创建函数。 sock_map_fd返回了分配的文件描述符。 bindsys_bind将套接字和地址绑定起来 12345678910111213141516171819202122asmlinkage long sys_bind(int fd, struct sockaddr __user *umyaddr, int addrlen){ struct socket *sock; char address[MAX_SOCK_ADDR]; int err; if((sock = sockfd_lookup(fd,&amp;err))!=NULL)/* 根据文件描述符查找套接口 */ { if((err=move_addr_to_kernel(umyaddr,addrlen,address))&gt;=0) {/* 从用户态复制地址到内核中 */ err = security_socket_bind(sock, (struct sockaddr *)address, addrlen);/* 安全审计 */ if (err) { sockfd_put(sock); return err; } /* 调用套接口层的bind回调，对IPV4来说，就是inet_bind */ err = sock-&gt;ops-&gt;bind(sock, (struct sockaddr *)address, addrlen); } /* 释放对文件句柄的引用 */ sockfd_put(sock); } return err;} 首先根据文件描述符查找到socket实例，绑定之前，先将用户空间的地址拷贝到内核空间，然后检查传入地址是否正确。 bind函数完成绑定操作。 connect主动连接 12345678910111213141516171819202122232425262728asmlinkage long sys_connect(int fd, struct sockaddr __user *uservaddr, int addrlen){ struct socket *sock; char address[MAX_SOCK_ADDR]; int err; sock = sockfd_lookup(fd, &amp;err);/* 查找文件句柄对应的socket */ if (!sock) goto out; /* 从用户态复制地址参数到内核中 */ err = move_addr_to_kernel(uservaddr, addrlen, address); if (err &lt; 0) goto out_put; /* 安全审计 */ err = security_socket_connect(sock, (struct sockaddr *)address, addrlen); if (err) goto out_put; /* 调用传输层的connet方法inet_stream_connect或inet_dgram_connect */ err = sock-&gt;ops-&gt;connect(sock, (struct sockaddr *) address, addrlen, sock-&gt;file-&gt;f_flags);out_put: sockfd_put(sock);out: return err;} listenlisten 的主要工作就是申请和初始化接收队列，包括全连接队列和半连接队列。 调用listen后，内核会建立两个队列 SYN队列，接受到请求，但是没完成三次握手 ACCEPT队列，已经玩长城了三册握手的队列 accept1int accept(int listen_sockfd, struct sockaddr *addr, socklen_t *addrlen) 从ACCEPT队列中拿一个连接，并生成一个新的描述符，跟原来的listen_sockfd相比，新fd的请求端IP地址，请求端口被初始化了。 参考资料https://mp.weixin.qq.com/s?__biz=MjM5Njg5NDgwNA==&amp;mid=2247485737&amp;idx=1&amp;sn=baba45ad4fb98afe543bdfb06a5720b8&amp;scene=21#wechat_redirect linux2.6.11 https://www.cnblogs.com/zengzy/p/5107516.html","link":"/2021/07/26/Linux%E5%86%85%E6%A0%B8%E5%A5%97%E6%8E%A5%E5%AD%97%E5%AE%9E%E7%8E%B0/"},{"title":"Oranges操作系统实现-前两章","text":"前两章主要是一些准备工作，扇区引导，环境配置 引导扇区开机过程： 计算机电源被打开时，先进行加电自检（Power-On Self-Test；POST），这是BIOS的一个功能，针对硬件如CPU、主板、存储器进行检查，速度很快。 BIOS将磁盘的第一个扇区512字节（引导程序）载入内存，放到内存07c00处。 寻找启动盘，比如从软盘启动，就检查软盘的0面0磁道1扇区，如果发现以0xAA55结束，BIOS就认为这是一个引导扇区 引导扇区除了以0xAA55（这是一个结束标志）结束，还应该包含512字节的执行码（510吧？） 一旦BIOS发现引导扇区，就会将这512字节的内容装入到内存地址07c00h处，然后头转到这里，将控制权交给这段引导代码，计算机的控制就从BIOS转到了操作系统。 123456789101112131415161718 org 07c00h ; 告诉编译器程序加载到7c00处 mov ax, cs mov ds, ax mov es, ax call DispStr ; 调用显示字符串例程 jmp $ ; 无限循环 $表示当前行被汇编之后的地址DispStr: mov ax, BootMessage ;NASM中，没有[]的被认为是地址，访问标签中的内容使用[] mov bp, ax ; ES:BP = 字符串地址 mov cx, 16 ; CX = 串长度 mov ax, 01301h ; AH = 13, AL = 01h mov bx, 000ch ; 页号为0(BH = 0) 黑底红字(BL = 0Ch,高亮) mov dl, 0 int 10h ; 10h 号中断 retBootMessage: db \"Hello, OS world!\"times 510-($-$$) db 0 ; 填充剩下的空间，使生成的二进制代码恰好为512字节，$$ 表示一个section开始处被汇编后的地址，$-$$表示本行距离程序开始处的相对距离dw 0xaa55 ; 结束标志 用NASM编译后，得到一个512字节的bin文件，用工具写入到第一个扇区上。 环境搭建Bochsubuntu20.04安装bochs， 装bochs-2.6.9 123456789$tar vxzf bochs-2.6.9.tar.gz$cd bochs-2.6.9$./configure --enable-debugger --with-sdl --enable-disasm --enable-readline LIBS='-lX11' $make$sudo make install","link":"/2021/03/29/Oranges%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%AE%9E%E7%8E%B0-%E5%89%8D%E4%B8%A4%E7%AB%A0/"},{"title":"Oranges操作系统实现-第三章保护模式","text":"","link":"/2021/04/12/Oranges%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%AE%9E%E7%8E%B0-%E7%AC%AC%E4%B8%89%E7%AB%A0%E4%BF%9D%E6%8A%A4%E6%A8%A1%E5%BC%8F/"},{"title":"SVD奇异值分解及应用","text":"特点 优点：简化数据，去除噪声，提高算法结果 缺点：数据的转换可能难以解释 适用于数值型数据 原理$M_{m\\times n} = U_{m\\times n}D_{n\\times n}V_{n\\times n}^T\\approx U_{m\\times k}D_{k\\times k}V_{k\\times n}^T$ 对于矩阵$U$可表示为： $U = (u_1,u_2,…,u_n)$ 对于$V$： $V =(v_1,v_2,…,v_n)$ 则有： $M=d_{1} u_{1} v_{1}^{T}+d_{2} u_{2} v_{2}^{T}+\\cdots+d_{n} u_{n} v_{n}^{T}=\\sum_{i=1}^{n} d_{i} u_{i} v_{i}^{T}=\\sum_{i=1}^{n} A_{i}$ $M_n \\approx M_{k}=\\sum_{i=1}^{k} A_{i}$ 应用图像压缩存储一张 1000×622 大小的图片，实际上就是存储一个 1000×622 的矩阵，共 622000 个元素。这个矩阵用 SVD 可以分解为 622 个矩阵之和，如果我们选取其中的前 100 个之和作为对图像数据的近似，那么只需要存储 100 个奇异值 $d_i$，100 个 $u_i$ 向量和 100 个 $v_i$ 向量，共100×(1+1000+622)=162300 个 元素，大约只有原始的 26% 大小。","link":"/2019/07/27/SVD%E5%A5%87%E5%BC%82%E5%80%BC%E5%88%86%E8%A7%A3/"},{"title":"The google file system","text":"谷歌文件系统：面向大规模数据密集型应用的可扩展分布式文件系统。 概述GFS的作用： 存储BigTable的子表文件 提供大尺寸文件存储功能 文件组织形式 分成Chunk(块)64MB/块，分布和复制在服务器上 两个实体 一个Master 维护所有文件系统Meta data（命名空间、访问控制信息、文件名到块的映射、块的当前位置） 复制其数据以实现容错 定期与所有chunkserver通信：发送心跳信息、获取状体并发送命令 多个chunkserver 响应read\\write请求和master的命令 在磁盘上存储实际的数据，Master只存了元数据 设计动机 组件失效是常态事件 文件非常大 绝大部分文件的修改是追加写的形式 应用程序和文件系统协同设计，以提高系统灵活性 设计思想 文件以数据块形式存储，每个数据块有自己的句柄 副本技术保证可靠性：每个数据块至少有3个副本，作为本地文件存储在Linux文件系统中 Master维护所有文件系统的元数据，并利用周期性的心跳信息向chunkserver发送命令和收集状态 master不存在性能瓶颈的原因 只存元数据：磁盘容量、内存容量不会是瓶颈 元数据可以在内存里：磁盘IO不会是瓶颈 数据流和数据缓存不通过master，带宽不会是master的瓶颈 元数据可以缓存在client，CPU不会成为Master瓶颈 GFS的体系结构 系统流程读操作 应用程序发起读取请求。 Client从（文件名，字节范围）-&gt;（文件名，组块索引）转换请求，并将其发送到Master。 Master以块句柄和副本位置（即存储副本的Chunkserver）作为响应。 Client选择一个位置，然后将（块句柄，字节范围）请求发送到该位置。 Chunkserver将请求的数据发送到Client。 Client将数据转发到应用程序。 比如这里，2048是要读的字节数，Master中根据文件名找到了属于该文件的块编号，还有所在的chunkserver号 写操作任何写或者追加操作要求互斥 要求：数据需要被写到所有的副本上。当多个Client请求修改操作时，保证同样的次序 Client发送请求到Master Master返回块的句柄和副本的位置信息 Clinent将写数据发送给所有的副本 数据存储在副本的缓存中 client发送写命令到primary primary给出写次序 primary将次序发送给secondaries secondaries响应primary primary响应client 添加操作 client 将数据推送给所有副本，然后向primary发送请求 primary检查append操作是否会使块超过64MB 如果小于，正常处理 大于，块被填充为0（放弃该块的写），所有secondary也同样操作，然后通知client在下一个块上重新尝试。 一致性问题区别两个概念： 一致：所有的client读取相同的数据 确定：所有的client读取有效的数据 串行化成功：多个client串行写，写入并没有相互干扰。 并发成功：primary决定client的写的顺序，多个client可能并发写多个存在交叉的chunk，由于primary之间不通信，不同的primary可能选择不同的client写顺序，如果执行成功，所有的client会看到相同的数据，但是数据无效。","link":"/2021/01/22/The-google-file-system/"},{"title":"UNIX操作系统设计-存储管理策略","text":"《UNIX操作系统设计》第九章 对换对换算法的描述分三个部分：对换设备上的空间管理、将进程换出内存、将进程换入内存。 对换空间的分配对换设备：在一个磁盘的可配置段中的一个块设备。 内核在对换设备上可以以一组连续的磁盘块为单位分配空间。而文件一次只分配一个磁盘空间，这样可以减少碎片量 。而在对换设备上，进程驻留的时间是短暂的，最终会被释放掉，速度更关键，这时系统操作多个块速度要快的多。 对换设备分配方法和文件系统的分配方法不同，记录空闲区的数据结构也不一样。 内核用空闲块链接表管理文件系统的空闲空间，在超级块中可以存取到该链表。 内核通过存放在内存中的，叫做映射图的表来管理对换设备的空间。 映射图也用于管理其他一些资源，如设备驱动程序。采用最先适配算法，分配连续块。 映射图结构： 映射图是一个数组 每一项包含：一个可分配资源的地址、该地址上可用资源的单位数。 开始时，映射图只有一项（因为还没有被用过），指出资源的地址和全部可用资源的数目。后面随着分配和释放资源，内核会不断修改映射图，使其总是保存着空闲资源的准确信息。 映射图分配算法malloc 当释放资源时，有三种情况： 被释放的资源完全填满映射图中的一个空洞。释放的这个资源和前后两个表项合并，变成一项。 被释放的资源部分地填充映射图中的一个空洞。项数不变，修改表项地址和单位数 被释放的资源部分太南充一个空洞但不连接映射图中的任何表项。新建项 进程的换出以下事件会引起进程换出 系统调用fork必须为子进程分配空间 系统调用brk扩大一个进程大小 进程由于栈的自然增长而变大 运行以前被换出，现在应该被换入的进程 fork的情况最特殊，是唯一不能放弃被进程先前占据的内存映象空间的情况。 换出的过程： 换出进程时，进程的每个区引用数减一，并把引用数为0的区换出。内核分配对换设备空间，并将该进程锁在内存中，防止对换操作过程中对换进程将它对换出来？？内核将区的对换地址保存在区表表项中。 对换的时候绕过高速缓冲。如果按页面组织内存，换出的数据在物理存储器上可能时不连续的，内核需要收集被换出数据的页面地址，磁盘驱动程序也可能要用这些页面地址驱动IO？？对换进程在换出剩下的数据之前要等待每一个IO操作完成。 内核没有必要将一个进程的整个虚地址空间全部写到对换设备上去。仅将物理存储拷贝到对换设备空间，忽略未分配的虚地址。 例子： 换入时，内核查找进程存储映射表得知进程有一个62k字节的空区，并指定相应的物理存储。进程占据的物理地址单元在换出前和换入后时不同的。 能不能换出的问题： 如果U区含有进程地址转换表，内核就不能换出U区。实现上要决定一个进程能否将自己换出，还是必须由另一个进程将其换出。 fork对换：如果内存不足以创建子进程的上下文，内核将子进程换出到对换设备上，父进程的内存并不释放，父进程将子进程设置为就绪态，自己返回用户态。子进程直到换入内存调度后，才会完成它的fork系统调用部分然后返回用户态。 扩展对换：进程需要的内存比分配给的内存还多，如栈增长或brk引起，内核就要进行进程的扩展对换。内核在对换设备上预定足够多的空间，然后修改进程地址转换映射来适应新的虚存空间，但此时并不分配物理存储地址。内核通过一次正常的换出，将对换设备上新分配的空间清零。再次换入时，按新的增加了尺寸的地址转换映射图来分配物理地址。 进程的换入进程0，就是对换进程，是唯一的将进程从对换设备上换入内存的进程。系统初始化结束后，对换进程就进入一个无限循环。它总是试图将进程从对换设备换入内存，如果需要主存空间，就将进程换出内存。如果对换进程没事做或不能做任何事就睡眠，内核会定期唤醒对换进程，并和其他进程一样进行调度。但对换进程仅在核心态下运行，使用内核内部函数来执行对换，这是所有核心进程的主要工作方式。 对换进程怎么工作的？ 对换进程被唤醒后，就进行换入进程的工作，查找所有处在就绪且换出状态的进程，从中选取换出时间最长的（这个时间是时钟处理程序记录的），如果内存够，就换入。换入是换出操作的逆过程：分配物理存储，将进程从对换设备读入，然后释放对换空间。 如果对换进程找到了应该被换入的进程，但系统没有足够的内存空间，这时，对换进程试图换出另一个进程，如果成功则重新启动对换算法，查找要换入的进程。换出的另一个进程是正在睡眠的进程，如果没有睡眠的进程，就根据进程的nice值和在内存中驻留的时间换出就绪进程。 如果找不到可用换出的进程或要换入换出的进程在自己的环境里驻留时间不超过两秒（规定），对换进程就睡眠在一个事件上，这个事件表示，对换进程要换入一个进程，但内存不够。之后，时钟每秒一次唤醒对换进程，当有进程进入睡眠状态，内核也要唤醒对换进程。 举例： malloc实现：看brk，mmap","link":"/2020/11/17/UNIX%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1-%E5%AD%98%E5%82%A8%E7%AE%A1%E7%90%86%E7%AD%96%E7%95%A5/"},{"title":"UNIX操作系统设计-数据缓冲区高速缓冲","text":"《UNIX操作系统设计》第三章 数据缓冲区高速缓冲（buffer cache）简称高速缓冲。内核通过保持其内部数据缓冲池来减小对磁盘的存取频率，高速缓冲中含有最近被使用过的磁盘块的数据。 概述数据缓冲区高速缓冲（buffer cache）简称高速缓冲。内核通过保持其内部数据缓冲池来减小对磁盘的存取频率，高速缓冲中含有最近被使用过的磁盘块的数据。 这里这是一个软件结构，和cache硬件不同。 高速缓冲模块位于文件子系统与设备驱动程序之间，如图： 高层内核算法让告诉缓冲模块把数据预先缓存起来，或者延迟写数据以扩大高速缓冲的效果。 缓冲头部 缓冲区组成：一个含有磁盘上的的数据的存储器数组 + 一个用来标识该缓冲区的缓冲头部。缓冲头部到数据数组一对一映射，所以统作为“缓冲区”。 一个缓冲区的数据与文件系统上体格逻辑磁盘块中的数据对应，缓冲区是磁盘块在主存中的拷贝。 缓冲头部包含一个设备号字段和一个块号字段，两者指令了文件系统与磁盘上的数据的块号，并唯一标识该缓冲区。 设备号是逻辑文件系统号，而不是物理设备（磁盘）号。 指向数据数组的指针至少有磁盘块那么大。 缓冲区状态是如下条件的组合 缓冲区当前为“上锁” 缓冲区包含有效数据 延迟写，内核把某缓冲区重新改分配出去之前必须把缓冲区内容写到磁盘上。 正在读或写，内核正从磁盘往缓冲区读或者把缓冲区写道磁盘上。 一个进程当前正在等候缓冲区变为闲。 缓冲池结构空闲表 内核维护一个缓冲区的空闲表，保存最近使用的次序 采用双向循环链表 哑缓冲区头标，标志缓冲区空闲表的开始和结束 内核按最近最少用算法把数据缓存于缓冲池 缓冲区还给缓冲池时，添加到尾部。申请时，从头部取出。 空闲表头部是最近最少使用的 散列队列为了方便内核搜索相应的缓冲区，内核使用设备号和块号的组合找相应的缓冲区，它把缓冲区组织成多个队列，这些队列以设备号和块号散列。 一个缓冲区总是在某个散列队列上，但是可以在或不在空闲表中。 缓冲区的检索","link":"/2020/10/14/UNIX%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1-%E6%95%B0%E6%8D%AE%E7%BC%93%E5%86%B2%E5%8C%BA%E9%AB%98%E9%80%9F%E7%BC%93%E5%86%B2/"},{"title":"UNIX操作系统设计-文件的内部表示","text":"《UNIX操作系统设计》第四章 UNIX系统中每个文件都有一个唯一的索引节点，记录了进程存取文件所必须的信息，如文件所有者、存取权限、文件长度、文件数据在文件系统中的位置。 每个路径名唯一指明一个文件，内核把路径名转换成文件的索引节点。 本章算法层次在高速缓冲算法之上。 算法 功能 iget 返回一个先前标识了的索引节点，可能是由高速缓冲从磁盘上读出的 iput 释放索引节点 bmap 存取一个文件设置内核参数 namei 使用iget、iput、bmap把一个用户级路径名转换成一个索引节点 alloc、free 为文件分配及释放磁盘块 ialloc、ifree 为文件分配及释放索引节点 索引节点定义索引节点有两份，在磁盘上和内存上，在内存上缓冲是便于内核操作，提高效率，这里的缓冲采用的第三章高速缓冲。 索引节点以静态形式存在于磁盘上，核心把它们读进内存索引节点表中以操纵它们，索引节点字段组成： 文件所有者标识号 文件类型：正规类型、目录类型、字符设备类型、块设备类型、管道类型 文件存取许可权：chmod，Linux/Unix 的文件调用权限分为三级 : 文件所有者（Owner）、用户组（Group）、其它用户（Other Users）。 文件存取时间 文件联结数目：本目录树中有多少文件名指向该文件 文件数据的磁盘地址明细表 文件大小 并不标明该文件的路径名 内存中的索引节点除了磁盘索引节点那些字段外，还包含： 内存索引节点状态：是否上锁，是否有进程在等它变为开锁等等 含有该文件系统的逻辑设备号 索引节点号：索引节点存储在磁盘上的线性数组中，内核需要用下标来标识这个节点号。 指向其他内存索引节点的指针：内核也会把索引节点链接到散列队列和空闲表上。 引用数：该文件的活跃实例数目（如open），仅当索引节点的引用计数为0时才位于空闲表上，标识内核可以把这个内存索引节点重新分配给另一个磁盘索引节点。 对索引节点的存取 igetiget分配一个索引节点的内存拷贝，与getblk算法几乎时完全相同的。内核把设备号和索引节点号映射到一个散列队列上，便于搜索找到索引节点。如果找不到，就从空闲表分配，并上锁。 然后就在磁盘中找对应的磁盘块号，块号 = （int（索引节点号-1）/每块的索引节点数目）+ 索引节点表的起始块号 知道块号后，利用bread从缓冲区读块，计算索引节点在块中的字节偏移量：((索引节点号-1) mod (每块的索引节点数目))*磁盘索引节点大小。 找到后，拷贝到内存索引节点表中，放到正确的散列队列，引用计数设置为1 释放索引节点 iput当内核释放一个索引节点时（iput）,将他的索引节点引用计数减1，当减为0，且内存拷贝和磁盘不同，则内核需要往磁盘写入。内核还会把该索引节点放到空闲索引节点表中，当再次需要时，可以高效把该节点加入高速缓冲。如果联结数减为0，则释放与该文件有关的数据块，并将索引节点变为空闲。 正规文件的结构 把文件字节流的字节偏移量到物理磁盘块号的转换 bmap 例子： 两个发展： 允许使用大磁盘块，一个磁盘块可以包含若干个文件的分段 把文件数据存储到索引节点中。 目录目录是文件，记录了一系列目录表项，每个表项由一个索引节点号和一个包含在这个目录中的文件名组成。 路径名到索引节点的转换 namei如何根据路径名搜索索引节点 超级块描述文件系统的状态，有多大，能存多少文件等等。 超级块字段组成： 文件系统的规模 文件系统中空闲块的数目 在文件系统上可用的空闲块表 空闲块表中下一个空闲块的下标 索引节点表的大小 文件系统中空闲索引节点数目 文件系统中空闲索引节点表 空闲索引节点表中下一个空闲索引节点的下标 空闲块表的锁字段和空闲索引节点表的锁字段 用来指示出超级块已经被修改了的标志 索引节点的分配文件系统包含一个索引节点线性表，类型字段为0，说明这个索引节点是空闲的。当一个进程需要一个新的索引节点，如果内核搜索索引节点表，以寻找一个空闲节点，但这样代价太高了，至少对每个索引节点都需要一个读操作（可能从磁盘）。为了改善性能，文件系统超级块包含一个数组，以便把文件系统从空闲的索引节点号缓存起来。 分配索引节点ialloc把一个磁盘索引节点号分配给一个新建立的文件 铭记的索引节点：如果超级块中没有空闲，即去磁盘搜索，当搜索到超级块装不下时停止搜索，此时记录下最高序号的索引节点，即下次搜索时从铭记索引节点开始。 ifree 释放索引节点 磁盘块的分配文件系统的超级块包含一个用来把文件系统中的空闲磁盘块号高速缓冲起来的数组。 mkfs把一个文件系统的数据块组织到一张链表中，表中每个链是一个磁盘块大小，块中包含的是一个数组，数组的分量给是空闲磁盘块号，一个分量是下一个链表的块号。 文件系统块分配 alloc功能：把超级块空闲磁盘块号表中下一个可用的块分配出去。 当分配的是超级块高速缓冲中的最后一个可用块时，内核把他指向的块读出，填充到这个链表里，再加入一条新链，示例d。 释放磁盘块free与分配磁盘块算法相反。 如果超级块未满，新释放的块的块号就被放到超级块表中。 如果超级块表满了，则新释放的块就变成一个链接块，内核把超级块表写到这个块上，然后把这个块写到磁盘上，然后把新释放的块的块号放到超级块表中作为下一个链表的指针，块号就成了表中唯一成员。 例子： 索引节点和磁盘块两者的分配和释放算法类似，内核都使用超级块作为高速缓冲 内核维护的有一个块号链接表，文件系统中的每个空闲块号都作为其中的元素。 对索引节点不存在这样的链表，原因： 内核观察到文件类型字段被清除，则索引节点空闲。 一个磁盘块可以很容易容纳大的空闲块号表。 用户消耗磁盘块资源比消耗索引节点要快，所以快速得到空闲磁盘块更重要。 其他文件类型管道文件、特殊文件 管道文件的数据时短暂的，先进先出，下一章介绍 特殊文件包括：块设备特殊文件、字符设备特殊文件，第10章介绍","link":"/2020/10/15/UNIX%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1-%E6%96%87%E4%BB%B6%E7%9A%84%E5%86%85%E9%83%A8%E8%A1%A8%E7%A4%BA/"},{"title":"UNIX操作系统设计-进程控制","text":"《UNIX操作系统设计》第七章进程控制 进程的创建UNIX中，创建新进程的唯一方法就是系统调用fork，进程0使唯一不通过fork创建的进程，由内核内部的创建。 pid = fork() 父子进程除了返回值pid不同外，具有完全一样的用户级上下文。 父进程pid为子进程的进程号 子进程的pid值为0 fork完成的操作： 为新进程在进程表中分配空槽 为新进程赋值唯一的pid 做一个父进程上下文的逻辑副本 进程关联的文件表和索引节点表的引用数++ 父子进程分别返回pid fork会先确认由足够的资源来完成fork，对换系统中在内存或磁盘上存放子进程、请求调页系统中，内核为页表分配存储空间，如果资源不足，调用失败 pid分配的时候使累加的，达到最大值后会从0重新分配。 一个用户可以同时运行的进程数有限制，也不能占用最后一个进程表表项，否则不能调用exit正常退出。超级用户可以创建进程表所能容纳的任意多个进程，也可以占用最后一个空槽，它能启动一个子进程强制其他进程退出kill。 初始化子进程的进程表项，从父进程拷贝各各字段，填写父进程pid。再初始化各种调度参数，初始状态为“创建”状态。 然后调整引用数。子进程位于父进程的当前目录，所以当前目录的进程数+1，内核要层架该目录索引节点的引用数。如果父进程调用了chroot，子进程也继承这一改变，并增加其索引节点的引用数。内核查找父进程的用户文件描述符表，把其中的每一个打开的文件的全局文件表中的引用数+1。 创建子进程上下文时，对于静态部分，算法dupreg复制父进程的所有区，attachreg将每个区附接到子进程。在对换系统，内核拷贝非共享区的内容到一个新的内存区域。子进程的U区被初始化和父进程一样，除了指向进程表表项的指针。 对于动态部分，子进程和附近成的内核栈完全一样。 子进程上下文就绪后，父进程将子进程状态改为“在内存中就绪”。 软中断信号简称信号，通知进程发生了异步事件。 进程之间可以调用kill相互发送软中断信号，内核从内部也可以发送软中断信号 UNIX系统V中有19个软中断信号，分为几类： 进程终止相关 进程例外事件相关，如访问越界、写 只读的内存区、硬件错误 系统调用期间遇到的不可恢复的条件相关 系统调用时遇到非预测错误条件 用户态进程发出 和终端交互有关 跟踪进程执行 相关问题： 内核如何向进程发送软中断信号？ 内核在进程表中，按所要接受的信号类型设置软中断信号字段的某一位。 进程如何接受软中断信号？ 进程从内核态返回用户态，或者进入或离开低调度优先级睡眠状态，内核会检查进程是否收到了软中断信号。 进程如何对中断信号反应？ 软中断信号的处理内核在收到软中断信号的进程上下文中处理软中断信号。处理分三种情况：进程收到软中断信号后退出；进程忽略信号；收到信号后执行一个特殊的用户函数。 进程可以调用signal来定义当收到某一信号时要做的特殊动作 oldfunction = signal(signum,function) u区中含有一个软中断处理程序字段的数组，每一个字段对应系统中定义的一个信号。 内核可以对进程有错的那些软中断信号转储内存映像，便于调试程序。 进程接受到一个决定要捕获的信号，当返回用户态，便执行用户定义的软中断处理函数，执行前，内核要执行下列步骤： 存取用户保存的寄存器上下文，找出PC和栈指针 清除u区软中断信号处理函数字段，设置为缺省 在用户栈上创建一个新的栈层，写入PC和栈指针，根据需要分配新空间 改变寄存器上下文 例子 可能产生竞争条件 进程组系统有时用组来标识进程。用进程组号标识进程，这组进程对于某些事件应该收到共同的信号。进程表中有记录组标识号。 grp = setpgrp用来初始化一个进程的进程组号，并设置为与该进程标识号相同的值。 从进程发送软中断信号进程使用系统调用kill发送软中断信号 kill(pid,signum) pid为正值，发送给pid的进程；为0发送给所有同组进程；为-1发送给真正用户标识号等于发送进程的有效用户标识号的进程，如果发送进程有超级用户的有效用户标识号，信号将被发送给除进程0和进程1以外的所有进程。pid为非-1的负数，发送个组好为pid绝对值的进程组中的所有进程。 进程的终止退出的进程进入僵死状态，释放它的资源，撤出进程上下文，但保留它的进程表项 exit(status) status的值返回给父进程。main结束调用；内核在进程收到非捕获信号时，可以内部调用exit，status是软中断信号号。 等待进程的终止进程调用wait使它的执行与子进程终止同步 pid = wait(stat_addr) pid使僵死子进程的进程号； stat_addr使一个整数在用户空间的地址，将含有子进程的退出状态码。 执行wait的进程有子进程，但没有僵死进程，则该进程睡眠在可被中断的优先级上，直到出现一个软中断信号。 内核对睡眠与系统调用wait中的进程没有显示的唤醒调用，只有收到软中断信号时才被唤醒。 特殊点是，如果软中断信号是“子进程死”，该进程将采用不同的对策 缺省情况下，进程从wait的睡眠中醒来 如果进程捕俘“子进程死”软中断信号，内核将像处理其他信号一样，安排调用用户的软中断信号处理子程序 如果进程忽略“子进程死”软中断信号，内核将重新开始wait中的循环，释放僵死进程的进程表项，然后寻找其他的子进程。 对其他程序的引用exec实现引用一个程序，用一个可执行文件的副本覆盖一个进程的存储空间。 12345execve(filename,argv,envp);//filename是要引用的可执行文件的文件名//argv是一个字符指针数组的指针，这组字符指针是可执行程序的参数//envp是另一个字符指针数组的指针，这一组字符指针是执行程序的环境系统调用exec的库函数有好几个，如execl，execv，execle等待。这些库函数最终都要调用execve 文件系统中一个可执行文件的逻辑格式，通常由汇编程序或装配程序（loader）所组成 四部分组成： 主文件头：魔数给出了可执行文件的类型 若干个段头：段头描述了文件中的每个段，给出了段的大小、在系统中运行时该段所占据的虚地址和其他信息 数据段：如正文 其他信息段：如符号表、其他数据，这些信息对debug很有用 ？？？ 进程的用户标识号内核将两个用户标识号和一个进程关联，独立于进程标识号。用户标识号分为：真正用户标识号和有效用户标识号（setuid设置的用户ID），真正用户标识号标识负责运行进程的用户。有效用户标识号用于给新创建的文件赋所有权、检查文件的存取权限和检查通过系统调用kill像进程发送软中断信号的许可权限。 进程可以用exec执行一个setuid程序，或显示的系统调用setuid来改变有效用户标识号 改变进程数据区的大小12brk(endds);//endds是进程数据区的最高虚地址值，称为break值oldendds = sbrk(increment);//increment以字节为单位对当前break值的改变量 shell程序 系统自举和进程init自举：系统管理员通过自举过程来初始化一个处于非活动状态的系统。将操作系统装入内存，并开始执行。 系统管理员设置计算机控制台上的开关，规定一个特殊的硬编码的程序地址，按下一个按钮，指示机器从他的微代码装入自举程序，这个程序仅有几条指令组成，只是机器执行另一个程序。UNIX中，自举最后读一个磁盘自举块，并装入内存，自举块中的程序将内核从文件系统装入内存，内核装入内存后，自举程序将控制转到内核的起始地址，内核开始运行start。 init进程是一个进程派遣者，除了产生其他进程外，还产生一些使用户在系统上注册的进程。进程init读文件“/etc/inittab”来得到关于要产生那些进程的指示。 UNIX三种进程：用户进程、守护进程、核心进程 守护进程执行系统功能，如管理和控制网络，执行与时间相关的活动、行打印机假脱机输出等等 核心进程只在内核态运行，由进程0产生，核心进程在提供系统范围服务方面类似于守护进程，但执行优先权上具有更大的权力，因为他们是内核代码的一部分。","link":"/2020/11/03/UNIX%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1-%E8%BF%9B%E7%A8%8B%E6%8E%A7%E5%88%B6/"},{"title":"UNIX操作系统设计-进程结构","text":"《UNIX操作系统设计》 第六章进程结构 进程状态九状态 1、在用户态下执行 2、在核心态下执行 3、在内存中就绪 4、在内存中睡眠 5、就绪且换出 6、睡眠且换出 7、被抢先，进程正从核心态返回用户态 8、刚被创建，是除进程0以为的所有进程的初始状态 9、调用了exit，僵死，留下一个记录，由父进程收集，包含了出口码和一些计时统计信息，是进程的最后状态 “被抢先”和“在内存中就绪”是等价的，分为两种是为了强调：在核心态运行的进程，只有在即将返回用户态时，才能被抢先。 进程执行系统调用，从用户态进入内核态 如果系统调用需要等待，比如磁盘请求操作需要等待输入输出完成，将进入在内存中睡眠 输入输出完成，硬件中断cpu，中断处理程序唤醒进程，进入内存中就绪 描述进程状态的内核数据结构：进程表项和U区。内核总是可以存取进程表，而U区只能由正在运行的进程存取 进程表字段：进程状态字段、进程和其U区在内存或二级存储器中的位置、uid、pid、事件描述符字段、调度参数、软中断信号字段、各种计时字段 U区字段，进一步刻画进程状态的特性：指向进程表的指针、计时器、软中断信号反应数组等等 系统存储方案UNIX上的进程由三个逻辑段组成：正文段、数据段、栈 区区是进程虚拟地址空间的一段连续区域，被看作是可被共享和保护的独立实体。区可以共享，几个进程执行同一个程序，会共享一个正文区。 内核中有一个区表，每个在系统中活动的区对应表中的一个表项。每个进程都有一个私有的本进程区表，称为pregion表，表项可以放在进程表、U区或独立分配的存储区域中，取决于实现。进程区表和区的结构类似与文件表和索引节点结构。 页和页表页：由存储管理的硬件将物理存储器分成的一些大小相等的块。 内核向区分配物理页，页不一定是连续的，分页的目的是为了增加灵活性，减少因为分割所造成的不可用空间，类似磁盘块分配给文件。 内核的安排内核的页表类似于进程的页表，转化内核虚地址的方法也类似与转换用户虚地址采用的方法。 U区每个进程都有一个U区，但是对于内核来说，好像只有一个，即正在运行的进程的U区。内核可以动态的改变U区的虚地址映射，使U区的地址映射到另一个物理地址上。 进程在核心态运行时才能访问U区 进程的上下文进程上下文：用户地址空间的内容、硬件寄存器的内容、该进程有关的内核数据结构。分为用户级上下文、寄存器上下文、系统级上下文 用户级上下文：进程的正文、数据、用户栈、共享存储区 寄存器上下文：程序计数器、处理机状态寄存器、栈指针、通用寄存器 系统级上下文由动态和静态两部分组成 静态：一个进程的进程表表项、一个进程u区、区表表项、区表、页表 动态：内核栈帧、系统上下文层 内核压入上下文层，当中断发生、进程进行系统调用、进程切换上下文时。 内核弹出上下文层，当从中断处理中返回、从系统调用中返回、上下文切换发生时 进程上下文的保存内核每压入一个新的系统上下文层，就要保存一个进程的上下文。当系统收到一个中断、一个进程执行系统调用、内核做上下文切换时，就要对进程的上下文进行保存。 中断和例外内核处理中断的操作顺序： 保存当前进程的寄存器上下文并压入一个新的上下文层 识别中断类型，根据中断向量表。 内核调用中断处理程序 中断处理程序工作完毕前返回 系统调用的接口 syscallC编译程序采用一个预定义的函数库，解决了用户程序中请求系统调用的问题。这些库函数都执行一条指令，将进程的执行方式变为核心态，这个指令称为操作系统陷入（OS trap）。简单来讲，系统调用的接口是一个中断处理程序的特例。 上下文切换发生在四种情况： 进程使自己进入睡眠 进程从一个系统调用返回用户态但不是最有资格运行的进程 进程在内核完成中断处理后返回用户态，但不是最有资格运行的进程 退出exit时。 上下文切换和处理中断类似，不同的是，内核恢复的是一个不同进程的上下文层。 为废弃返回而保存上下文发生在内核必须种植他当前的执行顺序，立即从先前保存的上下文执行时 在系统和用户地址空间之间拷贝数据许多系统调用要在内核和用户空间之间传递数据 进程地址空间的管理本节定义区数据结构和区上的操作 区表表项描述一个区的必要信息，包含以下字段： 指向文件的索引节点的指针 区的类型（正文、共享存储区、私有数据和栈） 区的大小 区的物理存储器中的位置 区的状态 锁住 在请求中 正在被装入内存的过程中 有效，已被装入内存 引用数，引用该区的进程数 管理区的操作：锁区、解锁区、分配区、将区附接attach到某个进程的存储空间、释放一个区、使区和一个进程的存储空间断接detach、复制区的内容。 区的上锁和解锁上锁和解锁操作与分配和释放无关，内核能上锁和分配一个区，然后又解锁但不释放它 区的分配 allocreg系统调用fork、exec、shmget期间，内核将分配一个新区（allocreg）。内核有一个区表，表项在一个自由链表或者一个活动链表中。内核要分配一个区表项时，就从自由链表中取出第一个可用表项，并放到活动表中，该区上锁并表示他的类型（共享或私有）。 区附接到进程 attachreg在调用fork、exec、shmat期间，内核要使一个区和一个进程的地址空间联系起来名称为附接（attach）。附接的区可以使一个新分配的区，也可以是该进程要与其他进程共享的、已存在的区。 区大小的改变 growreg进程用系统调用sbrk来扩展或者压缩虚地址空间。内核在内部调用算法growreg来改变区的大小。growreg用于两种情况：用户栈的自动增长、系统调用sbrk用于一个进程的数据区。这两种区都是私有区，正文区和共享存储区在初始化以后不能再被扩展。 内核通过扩展现存的页表来适应更大的区。如果进程要压缩区，内核只要简单的释放分配给该区的存储空间即可。 区的装入 loadreg12对换系统：内存不够时，进程真个被写到swap上请求调页系统：内存不够时，把存储器的某些页写到兑换设备上 在请求调页系统，内核在系统调用exec期间将一个文件映射到进程的地址空间，然后按要求安排读入每个物理页。 在不支持请求调页的系统中，内核要将可执行文件拷贝到存储器中，将进程的区装到在可执行文件中指定的虚地址上。内核可以将区附接到一个虚地址上，这个地址不同于文件装入的实际地址，从而造成了页表中的间隙。 例子：内核要把一个7K大小的正文装入一个区，这个区被附接到某个进程的虚地址0上，且内核要在该区的开头留1k字节的间隙。 区的释放 freereg一个区不在与任何进程相附接，内核便释放区并把它移动到自由链表 区与进程的断接 detachreg系统调用exec、exit、shmdt中，内核使有关的区与进程相断接。它更新本进程区表表项，使有关的存储管理寄存器三元组无效，而从切断区与物理存储的联系。 区的复制fork系统调用，内核会复制进程的所有区，如果某个区是共享的（例如共享正文或共享存储区），内核只会增加该区的引用数，允许父进程和子进程共享该区。如果区不是共享的，内核就物理的拷贝该区，并为它分配新的区表表项、页表和该区的物理存储空间。 例如A 创建B并复制自身的区 睡眠sleep将进程由”核心运行“变成”在内存中睡眠“，wakeup将进程状态由睡眠变成“在内存中就绪“或”就绪且换出“。 进程在系统调用期间进入睡眠：操作系统陷入，等待资源，存取尚未物理地装入虚地址而导致页面错误。 睡眠事件及其地址进程在一个事件上睡眠，实际上是将一组事件映射到内核虚地址上。这种实现不区别由多少进程在等待该事件。 这样就产生了两种异常情况：多个进程在等待一个事件，当事件发生时，这些进程都被唤醒，可能同时竞争一个上锁的结构，因此这些进程就又回到了睡眠状态。 另一种异常情况：若干个事件映射到同一个地址上。多个事件发生任何一个，所有进程都会被唤醒，因为他们在同一个地址上休眠。但实际情况，这种冲突发生很少。 sleep和wakeupsleep：内核提高处理机优先级来屏蔽所有中断，保存旧处理机优先级，以便进程唤醒时可以恢复。睡眠地址和优先级保存在进程表中，并把进程放到睡眠进程的散列队列中。 wakeup不是立即使一个进程被调度，只是使该进程有资格被调度。 对睡眠在输入地址上的每个进程，状态设置为就绪，从睡眠队列中移出，放到就绪队列。然后清除进程表中标志睡眠地址的字。如果进程被唤醒不在内存，则要换入内存（假设系统不支持请求调页）。 进程有可能睡眠在一个不一定发生的事件，内核会通过给进程发送软中断信号来中断睡眠的进程。 为了区别各种类型的睡眠，内核会设置睡眠优先级参数，然后用优先级值调用sleep，？？","link":"/2020/10/27/UNIX%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1-%E8%BF%9B%E7%A8%8B%E7%BB%93%E6%9E%84/"},{"title":"UNIX操作系统设计-进程调度和时间","text":"内核做上下文切换时，选取有最高优先权的进程，切换到该进程的上下文。当运行的进程从核心态切换到用户态时，内核重新计算它的优先权，并定期的调整在用户态就绪的每个进程的优先权。 进程调度UNIX采用多级反馈循环调度 算法上下文切换结束时，内核选取处于在内存中就绪和被抢先状态的进程，选择优先权最高的进程来调度，如果若干进程都有最高的优先权，内核按循环调度策略选择在就绪状态时间最长的进程。 没有合格进程，内核休闲，直到下次中断再次调度，下次中断最迟发生在下一个时钟。 调度参数进程有一个优先权域，用户态进程的优先权是关于最近使用CPU时间的函数。进程优先权范围分为：用户优先权和核心优先权，每种优先权有几个优先权值，每个优先权都有一个进程队列。 用户级优先权的进程在从核心态返回用户态时被抢先，从而得到用户及优先权，而核心级优先权的进程是在算法sleep中得到核心级优先权的。 用户级优先权低于一个阈值，核心级优先权高于该阈值。核心级优先权又可以进一步划分为：在收到一个软中断信号时，具有低核心优先权的进程可以被换新，高核心优先权的进程继续睡眠（见7.2.1） 内核会在不同的进程状态下计算下进程的优先权： 内核将一个固定的优先权值和睡眠的原因联系起来 内核调整从核心态返回到用户态的进程的优先权 时钟处理程序以1s的间隔调整用户态下的所有进程的优先权，并使内核运行调度算法 进程表中的一个字段记录了进程的最近CPU使用时间，每次时钟中断，由时钟处理程序使该字段增加 12decay(CPU) = CPU/2 priority = (\"recent CPU usage\"/2)+(base level user priority) base level user priority 为核心态和用户态之间的优先权阈值。 最近CPU使用时间衰减的越慢，一个进程的优先权达到其基级优先权的时间越慢（也就是已经执行CPU时间的惩罚力度越大） 重新计算优先权使，具有用户级优先权的进程在优先队列之间移动 内核计算活动优先权的时间间隔为1s，但这个间隔是可以变化的，当内核执行一段临界区代码时，如果时钟中断已经到来（处理机优先级已被提高，但还没有高到足以屏蔽时钟中断），如果这时候计算优先权会使内核在临界区呆的时间过长。这时，内核只记住它应该重新计算优先权，当以前的处理及执行级降低之后的一次时钟中断时，内核才做计算。 进程调度的例子系统V上三个进程ABC的调度 进程优先权的控制系统调用nice(value)，来增加或减少进程表中的nice字段，只有超级用户才能提供nice值 在执行强计算作业，通过nice降低其进程优先权，这对系统中其他用户来说是友好的，因此得名nice? value被加入到进程优先权的计算中： priority = (\"recent CPU usage\"/constant)+(base priority)+(nice value) nice仅作用在正在运行的进程，一个进程不能设置另一个进程的nice值，也就是说如果一个进程消耗了太多时间，系统管理员只能kill掉它。 公平共享调度上述的调度算法对不同类型的用户不做区分，不可能将CPU时间分一般给一组特殊的进程，为了解决这个问题，提出了公平共享调度策略。 原则是，将用户团体分为一些公平共享组，每个组的成员受到常规的进程调度的限制。系统将CPU时间按比例平均分给每个组，并不考虑组中的成员的多少。 举个例子，有四组进程，分别含有1、2、3、4个进程，如果按常规的调度算法，每个进程得到10%的CPU时间，但是按照公平共享调度，第一组进程得到的CPU时间是第二组的2倍，第三组的3倍，第四组的4倍。 实现方法： 在计算进程优先权值的公式中，加入了一个“公平共享组优先权”的项，进程的u区有个新字段 ，指向一个公平共享CPU使用字段，由该组所有进程共享。时钟中断程序增加公平共享CPU使用字段，并每秒一次衰减所有公平共享组CPU使用字段的值。 例子： 2个组 3个进程 A在一个组，BC在另一个组 实时处理实时处理 指 对外部事件进行立即响应，在该时间发生后的一个指定时间内，调度指定的进程去运行。这种实现存在两个问题，一个是调度算法，上面的调度算法都是为分时环境设计的，这里是实时环境。另一个问题是内核时不可抢先的，但是现在的内核时可以抢先的，这本书很老了。解决方法是允许实时进程动态存在，并提供一种机制来通知内核实时要求，目前UNIX还没有这种。 强实时一般时嵌入式做的，比如飞机的检测系统 有关时间的系统调用stime,time是关于全局的系统时间，stimes,alarm是关于单个进程的时间。 stime允许超级用户将一个表示当前时间的值赋给一个内核全局变量 stime(pvalue)，pvalue是一个指针，指向一个以秒为单位的长整数时间，时钟中断程序每秒一次使该变量加一 time(tloc)，查询由stime所设置的时间time(tloc)，tloc指向一个用户进程中用作返回值的单元 times给出调用进程在用户态和核心态执行时所花费的积累时间以及它的所有僵死子进程在用户态和执行态时曾花费的累积时间。 12times(tbuffer);struct tms *tbuffer; tms定义如下 时钟时钟中断处理程序的功能： 重新启动时钟 按内部定时器有计划的调用内部的内核函数 对核心进程和用户进程提供运行直方图分析的能力 手机系统和进程几张及统计信息 计时 在有请求时，项进程发送时钟软中断信号 定期地唤醒对换基础南横 控制进程的调度 时钟中断处理程序在高处理机执行级上运行，来防止中断处理程序工作期间发生其他事件。 重新启动时钟当时钟中断系统时，多数机器由软件指令重新启动时钟，这些指令和机器有关，这里不讨论。 系统的内部定时有些系统操作需要在实时基础上调用内核的一些函数，如设备驱动和网络协议。 内核将必要的信息存放在callout表中，其中含有当定时事件到时所要调用的函数名、该函数的一个参数以及时钟滴答为单位的定时时间。 callout表用户不能直接控制，由内核算法创建，按照各自的启动时间排序。各表项记录的是前一表项启动后，到该表项被启动时的时间量。 实现上讲，callout表使用链表实现，也可以用表然后调整表项的位置。 时钟中断处理程序在每次时钟中断时，会使callout表中的字段减1。 内核准备好调用callout表中的某个函数的时刻和软件中断发生的时刻之间，可能发生很多中断，因此第一项可能为负？ 直方图分析用来确定系统在用户态的执行时间和核心态的执行时间之比，以及内核执行内核各个子程序所花费的时间的度量方法。 内核有一个直方图分析程序，在时钟中断时，对内核的活动进行采样，以便监视内核模块的相对性能。程序有一个内核地址表，用来采样，装有内核函数的地址。进程实现通过write写直方图驱动程序来装入这些地址。 流程：中断处理程序调用直方图驱动工程系的中断处理程序，首先确定处理机在中断时时处于核心态还是用户态，如果是核心态，对应程序计数器的一个内部计数器+1，如果是用户态，用户执行计数器+1。用户进程可以读直方图驱动程序，来获得内核计数并做统计。 例子： 用户可以使用系统调用profil对进程的执行做统计 profil(buffer,bufsize,offset,scale) 记账和统计进程U区有一个字段，记录消耗的内核时间和用户时间，当处理时钟中断时，进程根据进程是在核心态运行还是在用户态运行，来修改该运行进程在U区中对应的字段。父进程调用wait收集子进程的统计信息。 u区中还有一个记录进程使用的内存情况字段。时钟中断一个运行的进程时，内核计算一个进程使用的总内存数，该数是该进程的私有存储区和它在共享存储区中所占的比例的函数。 例如，一个进程和其他四个进程共享50k字节的正文区，并使用大小分别为25k和40k字节的数据区和栈区，则总内存数为50/5+25+40。 对于请求调页的系统，内核计算每个区中的有效页数来计算内存的使用情况，共享区的收费也是平均分。 进程退出时，内核将这个信息写到记账记录中，并用作向用户收费的依据。 计时内核在每个时钟中断，使一个时间变量加1。系统的计时是以时钟滴答为单位，从系统自举之时开始。","link":"/2020/11/12/UNIX%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1-%E8%BF%9B%E7%A8%8B%E8%B0%83%E5%BA%A6%E5%92%8C%E6%97%B6%E9%97%B4/"},{"title":"UNIX环境高级编程-第三章文件IO","text":"本章讨论的是不带缓存的IO。 文件描述符对于内核，打开的文件都由文件描述符引用。 按照惯例，文件描述符0对应标准输入，文件描述符1对应标准输出，文件描述符2对应标准错误。这是UNIX shell 和很对应用程序的惯例。 文件描述符数量有上限范围，在其UNIX上限是19，能打开20个，现在很多系统增加到了63，有的没限制。 open函数O_APPEND选项，文件表中的偏移量被设置成索引节点表中的文件长度。 open返回的文件描述符一定是最小的未使用的数字。可以用这个特性在标准输入、标准输出或者标准错误上打开一个新的文件。如先关闭标准输出，然后打开一个文件，这个文件一定会在描述符1上打开。 dup2函数可以正好的保证在给定的描述符上打开一个文件。 creat函数创建新文件 close函数关闭一个打开文件 关闭一个文件也释放该进程加在这个文件上的所有记录锁。 进程终止时，内核会自动关闭他打开的文件。 lseek函数设置文件偏移量。只修改文件表项中的文件偏移量，没有进行任何I/O操作。 读写操作都是从文件偏移量开始的，打开一个文件，除非指定O_APPEND，否则偏移量都被设置为0。 123#include &lt;sys/types.h&gt;#include &lt;unistd.h&gt;off_t lseek(int fd, off_t offset, int whence) ; 对于offset相对哪里偏移，通过whence设置，whence可以设置为SEEK_SET,SEEK_CUR,SEEK_END,分别对应文件开始处，当前位置，文件结尾。 返回值可以用来判断文件是否可以设置偏移量，如果文件描述符引用的是以管道或FIFO，lseek返回-1，errno设置为EPIPE。 文件偏移量可以大于当前文件长度，形成空洞。 read函数123#include &lt;unistd.h&gt;ssize_t read(int fd, void *buffer, size_tn bytes);//返回：读到的字节数，若已到文件尾为0，若出错为- 1 实际读到的字节数少于要求的字节数： 到达了文件尾还没读够 从终端设备读，一次之只能读一行 从网络读，网络缓冲机构原因 读面向记录的设备，如磁带，一次返回一个记录 write函数123#include &lt;unistd.h&gt;ssize_t write(int fd, const void *buff, size_t nbytes) ;//返回：若成功为已写的字节数，若出错为- 1 写出错常见原因：磁盘满，超过了一个给定进程的文件长度限制。 I/O效率文件共享UNIX支持不同的进程共享打开的文件。 每个进程都有自己文件表项：使得每个进程对自己的文件有一个偏移量。 多个进程读同一个文件都能正确的工作，因为有自己的文件表项，其中有自己的文件偏移量，但是多个进程在写一个文件时，就可能发生问题，所以下面介绍原子操作。 原子操作下面是要实现原子操作的两个例子。 写数据到文件尾部在早期没有O_APPEND的时候，假设两个进程AB都对同一个文件的尾部进行写入，先调用lseek到文件尾部，然后write，这时候第二个写操作可能会覆盖第一个写操作，从而出现问题。 这种逻辑的问题在于先定位，后写使用了两个分开的函数调用，解决办法是使这两个操作对于其他进程而言成为一个原子操作。也就有了O_APPEND,内核每次对这种文件写之前，都将进程的对该文件的偏移量设置到文件的尾端。 创建文件考虑open函数的O_CREAT和O_EXCL选项。 O_EXCL选项配合O_CREAT选项使用，若文件存在，则出错。若文件不存在，则创建文件成为一个原子操作。 情形是要打开一个文件，若不存在则创建，如果打开和创建之间，另一个进程创建了文件，而且写入了数据，则本进程再创建，刚写上的数据就会被擦除。因此要合并在一个原子操作。 dup和dup2函数复制以一个现存的文件描述符。 1234#include &lt;unistd.h&gt;int dup(int fd) ;//返回的是可用文件描述符的最小值int dup2(int fd, int fd2) ;//通过fd2指定新的描述符的值。//两函数的返回：若成功为新的文件描述符，若出错为- 1 dup2中，如果fd2已经打开，则先关闭。fd可以和fd2相等。 返回的新文件描述符与参数fd共享同一个文件表项（进程表—文件表—索引节点表），fd存在进程表项中，指向的是同一个文件表项，所以共享一个文件的状态标志和偏移量。 fcntl函数改变已经打开文件的性质。 12345#include &lt;sys/types.h&gt;#include &lt;unistd.h&gt;#include &lt;fcntl.h&gt;int fcntl(int fd, int cmd, int arg) ;返回：若成功则依赖于c m d(见下)，若出错为- 1 通过cmd设置五种功能： 复制一个现存的描述符（cmd＝F_DUPFD）。新的文件描述符取可用的大于等于第三个参数的最小值 获得/设置文件描述符标记（cmd = F_GETFD或F_SETFD）。 获得/设置文件状态标志（cmd = F_GETFL或F_SETFL）。 获得/设置异步I / O有权（cmd = F_GETOWN或F_SETOWN）。 获得/设置记录锁（cmd = F_GETLK , F_SETLK或F_SETLKW） oictl函数用于终端IO、磁带IO、套接字IO /dev/fd目录里是名为0、1、2等的文件，打开文件/dev/fd/n等效于复制描述符n。","link":"/2021/01/21/UNIX%E7%8E%AF%E5%A2%83%E9%AB%98%E7%BA%A7%E7%BC%96%E7%A8%8B-%E7%AC%AC%E4%B8%89%E7%AB%A0%E6%96%87%E4%BB%B6IO/"},{"title":"WSL使用主机shadowsocks代理","text":"WSL使用主机shadowsocks代理 双击小飞机，查看代理端口 编辑bashrc，然后source生效 12345# proxy configexport hostip=$(cat /etc/resolv.conf |grep -oP '(?&lt;=nameserver\\ ).*')export https_proxy=\"http://${hostip}:1080\"export http_proxy=\"http://${hostip}:1080\"export all_proxy=\"socks5://${hostip}:1080\" 测试生效","link":"/2021/11/05/WSL%E4%BD%BF%E7%94%A8%E4%B8%BB%E6%9C%BAshadowsocks%E4%BB%A3%E7%90%86/"},{"title":"XGBoost和LightGBM","text":"2014年Tianqi Chen开发了XGBoost，2017年微软团队开发了LightGBM都是针对同一个算法。 Gradient Boosting 是一种ensemble method，同一组数据构建n个相互独立的classifier，假设每个classifier的犯错概率相同，则n个独立的classifier的结论结合在一起，实际得到的出错概率服从伯努利期望，这个期望远远小于p，这就是ensemble method的基本原理 Boosting GB中采用决策树当作基本的classifier 对原始数据做predictor，然后计算第一个model的预测值和真实值之间的差值，第二个model用来预测error，得到第二个模型后会把第一个模型和第二个模型做综合，以此类推。 基本思想就是根据当前模型的残差来加入新的弱分类器，然后将训练好的弱分类器以累加的形式结合到现有的模型中。 从梯度的角度思考Boosting对平方误差来说，Boosting计算出的error实际就是负梯度 也就是说，对于总体模型的更新是基于负梯度的。 XGBoost","link":"/2021/11/10/XGBoost%E5%92%8CLightGBM/"},{"title":"cmake&make","text":"","link":"/2022/02/21/cmake-make/"},{"title":"cpp优化","text":"Optimizing software in C++：An optimization guide for Windows, Linux, and Mac platforms 不同C++ 结构的效率不同变量类型的存储栈存储函数在调用过程中在栈上分配内存空间，返回时候再释放。函数调用过程中使用了相近范围的地址，如果没有很大的数组，这一部分的数据基本能缓存在一级cache中。 因此，变量和对象最好在使用他们的函数中声明 全局或静态存储全局变量存储在静态内存中。 静态内存还用于static声明的变量，浮点常量（如3.5，整数常量一般包含在指令代码中了），字符串常量，switch跳转表，虚函数表。 静态数据优点是可以在程序启动前就完成初始化，缺点是内存空间在整个程序执行过程中都占用。 通常查找表最好声明为static const，比如 12345// Example 7.16float SomeFunction (int x) { static const float list[] = {1.1, 0.3, -2.0, 4.4, 2.5}; return list[x];} static可以让这个表第一次调用就初始化，后面就不需要了。这样多了一个开销是要检查这是第一次调用还是已经被调用，因此引入const让编译器确定这个表永远不会变化，不需要对第一次调用进行检查。 寄存器存储编译器优化时会自动选择函数中常用的变量存储在寄存器。这也是推荐使用局部变量的一个原因（另一个是栈存储的cache命中高） 易变变量（volatile）valatile指明变量可能被其他线程修改，阻止编译器进行用从先前分配的值进行优化。 线程本地存储（TLS）关键字__thread或__declspec(thread)实现静态变量和全局动态变量线程本地存储。tls比较低效，通过存储在线程环境块中的指针进行访问。应该避免，使用栈上的存储，存储在栈上的变量综述属于创建他们的线程。 Far在分段内存的系统中用 动态内存分配当以随机分配释放大小不同的对象，堆容易碎片化。堆碎片化时，顺序分配的对象不一定顺序分配在其中，造成cache效率低下。 类中声明的变量类中声明的变量按照声明的顺序存储。static修饰的类成员变量存储在静态内存中，只有一个实例。 整型变量和运算符整数大小建议使用stdint.h中的整数类型，如int8_t定义特定大小的整数类型，可移植性也强。 但是避免大于寄存器带下的整数，如32位系统中使用64位int。 size_t在32位系统中是32位，在64位系统中是64位。 注意检查整数溢出问题 有符号整数vs无符号整数多数情况下，有符号整数和无符号整数在速度上没有区别，但在某些情况下： 除以常数和取模：无符号要快 大多数指令集，有符号整数转成浮点数要快 两者的溢出行为不同，无符号溢出得到小整数 有符号整数和无符号整数的转化无代价，负整数被阶数为大整数。 不要比较（如&gt;）有符号整数和无符号整数。 整数运算符 简单整数操作，如加减、比较、位操作、移位只要一个时钟周期 乘法3-4个周期，除法40-80个时钟周期 自增和自减++i和i++是一样快的。 一些下情况，如x = array[i++]比x = array[++i]快，因为计算数组元素地址不用等待i的新值。 a = ++b比a=b++快，以为编译器会认为a=b，这样就可以用相同的编译器 浮点变量和运算符x86中有两种不同类型的浮点寄存器 枚举enum是一个隐藏的整形，效率跟整数一样 bool布尔操作数的顺序如a&amp;&amp;b ,a||b 如果a和b的计算时间相同，分支预测的预测可能性相同，把true多的操作数放到&amp;&amp;最后，||最前 计算速度快的操作符放前 可预测的操作数放前 布尔变量被过度检查bool变量放在8位int中，编译器会检查以bool变量作为运算符输入时是否为0和1，因此布尔变量作为输入可以优化。 如用char代替bool 布尔向量操作ab都是32位整数，则y=a&amp;b可以在一个时钟周期内完成 指针和引用指针vs引用两者效率一样，编译器实现一样，区别在于编程风格 使用指针的优点： 指针变量可以被清楚的看到，引用在函数体内跟变量的写法是一样的 指针的指向位置可以改变 使用引用的优点： 语法简单 更安全，引用一定指向一个有效的地址 拷贝构造函数和重载运算符中常用 被声明位const引用的函数参数接受表达式作为参数，而指针和非常量引用需要一个变量 效率编译器中的优化编译器如何优化函数内联编译器可以用被调函数主体替换函数调用，如果函数很小，或者只从较少地方调用这个函数，编译器则可能使用函数内联。 节约了函数调用返回传参的开销 代码连续，代码cache效率高 常量折叠和常数传播只包含常量的表达式或子表达的计算结果被替换，常量也可以通过一系列计算进行传播 消除指针指针指向的目标已知，指针或引用可能被消除 消除公共子表达式相同子表达式出现多次，那么编译器可能只计算一次。 寄存器变量编译器把常用的变量作为寄存器变量 典型的有：临时中间变量、循环计数器、函数参数、指针、引用、this指针、公共子表达式、归纳变量 有指针指向和引用的变量不能存储在寄存器中，为了利用寄存器变量的优化，应该避免使用对这种变量使用指针或引用。 活动范围分析活动范围：指变量被使用的代码范围。 对活动范围不重叠的变量，编译器可以优化使用相同的寄存器 合并相同的分支比如两个分支中用了相同的操作，编译器会把相同的操作提到分支外 消除跳转通过复制跳转的代码来避免跳转 循环展开循环展开并不一定就是最优的，因为展开太多代码会占用代码缓存空间 优化内存访问cache结构多路组相联形式，cache分为行和组 (addr/line size) % (set num)得到缓存组 内存中地址差值为关键步长的变量将争夺相同的缓存线 critical stride = (total cache size)/(ways num) 一起使用的函数放在一起经常使用的函数和很少使用的函数分开，代码中关键部分中使用的函数集中放在一个源文件中。或者调整模块的连接顺序，调用多的链接在一起（针对静态链接）。 一起使用的变量放在一起从缓存中加载一个变量只需要几个时钟周期，如果cache不命中，就要耗费超过100个时钟周期从ram中加载。 面向对象编程时将数据存储在一起的有效办法 在比如以a[0],b[0],a[1],b[1]...访问数组，则可以用结构体数组组织 struct Sab{int a,int b} 然后 用Sab[i]来访问 数据对齐变量存储在可被变量大小整除的内存地址，这样访问效率最高 对象和数组对其与cache line大小一致，这样可以保证对象或数组的起始位置刚好位于cache line起始位置。 动态分配内存可以用alloc代替new或者malloc alloca的优势： 分配的开销小，cpu有对栈操作的硬件支持。 栈的先进后出的特性，不会造成内存碎片 不需要垃圾收集 跟栈上的其他数据对象连续，cache更高效 容器类STL以通用性和灵活性为准测设计，而在执行速度、内存占用、缓存效率上考虑较低。 补救措施是使用内存池，参考容器类优化代码 字符串string在每次创建和修改字符串时使用new来分配新的内存块，如果程序多次创建修改字符串，这样做是低效的。 编译优化CMAKE配置的编译选项，有很多开关，基本上Release版本会打开以下选项 Use google tcmalloc代替标准的malloc(开关控制) 打开编译警告选项， -Wall-Wextra-Wlogical-op-Wcast-align-Wdisabled-optimization-Wvector-operation-performance-Wstack-protector-Wno-ignored-qualifiers -Wno-unused-parameter3. 把编译警告当成错误（开关控制， -Werror）4. Enable C++ 205. -O3 -DNDEBUG6. LTO优化相关选项（开关控制）-flto -fuse-linker-plugin -fdevirtualize-speculatively -Wmaybe-uninitialized7. Fast math-ffast-math8. 其它-pipe -Winvalid-pch -pthread-Wl,–disable-new-dtags9. native或AVX之类的开关一般情况下，因为编译机器和生产机器有差异，一般情况下未打开 参考资料容器类优化：https://www.agner.org/optimize/cppexamples.zip","link":"/2021/09/26/cpp%E4%BC%98%E5%8C%96/"},{"title":"cpu亲和性","text":"https://cloud.tencent.com/developer/article/1835296","link":"/2022/05/26/cpu%E4%BA%B2%E5%92%8C%E6%80%A7/"},{"title":"docker入门","text":"对于 Docker 等大多数 Linux 容器来说，Cgroups 是用来制造约束的主要手段，而 Namespace 技术则是用来修改进程视图的主要方法。 namespacenamespace是linux内核支持的特性，来实现进程资源隔离。 创建新进程fork时，底层调用clone函数，通过设置参数实现。 比如一个骨干程序，对clone可以传入不同的参数达到不同的namespace隔离: 12345678910111213141516171819202122232425262728293031#define _GNU_SOURCE#include &lt;sys/types.h&gt;#include &lt;sys/wait.h&gt;#include &lt;stdio.h&gt;#include &lt;sched.h&gt;#include &lt;signal.h&gt;#include &lt;unistd.h&gt;#define STACK_SIZE (1024 * 1024)static char container_stack[STACK_SIZE];char* const container_args[] = { \"/bin/bash\", NULL};// 容器进程运行的程序主函数int container_main(void *args){ printf(\"在容器进程中！\\n\"); execv(container_args[0], container_args); // 执行/bin/bash return 1;}int main(int args, char *argv[]){ printf(\"程序开始\\n\"); // clone 容器进程 int container_pid = clone(container_main, container_stack + STACK_SIZE, SIGCHLD, NULL); // 等待容器进程结束 waitpid(container_pid, NULL, 0); return 0;} clone可以选择传入不同的参数，比如： 1int container_pid = clone(container_main, container_stack + STACK_SIZE, SIGCHLD | CLONE_NEWUTS | CLONE_NEWIPC | CLONE_NEWPID, NULL); ipc隔离可s以通过ipcmk和ipcs命令验证 从内核实现角度，task_struct里有一个指向namespace的指针nsproxy clone时候： cgroup在task_struct里有一个字段： 123456#ifdef CONFIG_CGROUPS /* Control Group info protected by css_set_lock */ struct css_set *cgroups; /* cg_list protected by css_set_lock and tsk-&gt;alloc_lock */ struct list_head cg_list;#endif 里面包含了一个css_set结构体，里面存储了与进程相关的cgroups信息。 cg_list是一个链表，链接到同一个css_group的进程被组织成一个链表。 12345678struct css_set { atomic_t refcount;//被几个进程共用 struct hlist_node hlist;//所有css_set组织成一个hash表，用来快速查找 struct list_head tasks;//链接到该css_set的所有进程 struct list_head cg_links; struct cgroup_subsys_state *subsys[CGROUP_SUBSYS_COUNT]; struct rcu_head rcu_head;}; 参考docker namespace详解 namespace内核实现 cgroup内核实现","link":"/2022/05/11/docker%E5%85%A5%E9%97%A8/"},{"title":"eBPF学习","text":"基本使用bpf程序加载到内核后，并不会立刻执行。ebpf程序需要事件触发后才会执行，这些事件包括：系统调用、内核跟踪点、内核函数和用户态函数的调用退出、网络事件等等。 首先写一个c程序，ebpf程序： 12345int hello_world(void *ctx){ bpf_trace_printk(\"Hello, World!\"); return 0;} 然后通过bbc的python库，加载这个ebpf程序： 12345678#!/usr/bin/env python3# This is a Hello World example of BPF.from bcc import BPF# load BPF programb = BPF(src_file=\"hello.c\")b.attach_kprobe(event=\"do_sys_openat2\", fn_name=\"hello_world\") #内核跟踪b.trace_print() 然后执行：sudo python3 hello.py即可启动这个ebpf程序 一个完成的ebpf程序包括用户态和内核态两个部分 用户态负责ebpf程序的加载，事件的绑定，ebpf程序运行结果的汇总输出。 内核态运行在ebpf虚拟机中，负责定制和控制系统的运行状态 用户态和内核态的交互通过系统调用bpf()来完成。 123#include &lt;linux/bpf.h&gt;int bpf(int cmd, union bpf_attr *attr, unsigned int size); cmd ，代表操作命令，比如上 BPF_PROG_LOAD 就是加载 eBPF 程序 attr，代表 bpf_attr 类型的 eBPF 属性指针，不同类型的操作命令需要传入不同的属性参数 size ，代表属性的大小 运行原理eBPF是一个运行在内核中的虚拟机。虽然叫虚拟机，但是跟系统虚拟化比如KVM还是有本质的不同。 系统虚拟化基于X86或arm的通用指令集，来完成计算机的所有功能。而eBPF只提供了非常有限的指令集，只用于完成一部分内核的功能。 eBPF在内核运行是的5个模块组成： ebpf辅助函数：提供ebpf程序与内核其他模块进行交互的函数 ebpf验证器：确保ebpf程序的安全，保证执行的指令是一个有向无环图（DAG），确保程序不包含不可达指令，不会执行无效指令 存储模块：11个64位寄存器，一个程序计数器，一个512字节的栈 即时编译器：将ebpf字节码编译成本地机器指令，从而在内核中执行。bpf指令加载到内核后，即使编译器会将其编译成本地机器指令，最后才会执行编译后的机器指令。c源代码-&gt;bpf指令-&gt;机器指令。 bpf映射：提供给用户空间程序来访问 BPF辅助函数ebpf程序不能随意调用内核函数，隐私内核定义了一些列的辅助函数，用来ebpf程序与内核其他模块进行交互。比如的上面例子中的bpf_trace_printk()，用来向debugfs（/sys/kernel/debug/tracing/trace_pipe）中写入调试信息。 bpftool feature probe可以查看当前系统支持的辅助函数列表。 bpf映射bpf映射提供大块的kv存储，可以被用户程序访问，进而获取ebpf程序的运行状态 bpf映射智能通过用户态程序的系统调用来创建，比如： 123456789101112int bpf_create_map(enum bpf_map_type map_type, unsigned int key_size, unsigned int value_size, unsigned int max_entries){ union bpf_attr attr = { .map_type = map_type, .key_size = key_size, .value_size = value_size, .max_entries = max_entries }; return bpf(BPF_MAP_CREATE, &amp;attr, sizeof(attr)); //返回映射的文件描述符} 比较关键的是设置映射类型，bpftool feature probe | grep map_type可以查看支持的映射类型 另外，如果ebpf程序使用了bbc库，还可以通过预定义的宏来简化bpf映射的创建过程，比如对于hash表映射，bbc定义了PF_HASH(name, key_type=u64, leaf_type=u64, size=10240) 123456789101112// 使用默认参数 key_type=u64, leaf_type=u64, size=10240BPF_HASH(stats);// 使用自定义key类型，保持默认 leaf_type=u64, size=10240struct key_t { char c[80];};BPF_HASH(counts, struct key_t);// 自定义所有参数BPF_HASH(cpu_time, uint64_t, uint64_t, 4096); bpftool查看操作映射的常用指令： 12345678910111213141516171819202122//创建一个哈希表映射，并挂载到/sys/fs/bpf/stats_map(Key和Value的大小都是2字节)bpftool map create /sys/fs/bpf/stats_map type hash key 2 value 2 entries 8 name stats_map//查询系统中的所有映射bpftool map//示例输出//340: hash name stats_map flags 0x0//key 2B value 2B max_entries 8 memlock 4096B//向哈希表映射中插入数据bpftool map update name stats_map key 0xc1 0xc2 value 0xa1 0xa2//查询哈希表映射中的所有数据 bpftool map dump name stats_map//示例输出//key: c1 c2 value: a1 a2//Found 1 element//删除哈希表映射rm /sys/fs/bpf/stats_map 内核数据结构定义问题bbc在编译ebpf程序时，需要从内核头文件中找到相应的内核数据结构定义，这就会带来问题。 比如内核头文件的数据结构在不同的内核版本不一样。 从内核 5.2 开始，只要开启了 CONFIG_DEBUG_INFO_BTF，在编译内核时，内核数据结构的定义就会自动内嵌在内核二进制文件 vmlinux 中。 可以借助：bpftool btf dump file /sys/kernel/btf/vmlinux format c &gt; vmlinux.h 把这些数据结构的定义导出到一个头文件中，这样在开发ebpf程序时只要引入一个vmlinux.h即可。 事件触发内核中不同事件会触发不同的eBPF程序。eBPF程序类型决定了一个eBPF程序可以挂载的事件类型和事件参数。 bpftool feature probe | grep program_type查看支持的程序类型 主要可以分类三大类 跟踪：从内核和程序的运行状态中提取跟踪信息 网络：对网络数据包进行过滤和处理 其他，包括安全控制，BPF扩展等等 跟踪类主要用于从系统中提取跟踪信息，进而为监控、排错、性能优化等提供数据支撑。 网络类对网络数据包进行过滤和处理，进而实现网络的观测、过滤、流量控制以及性能优化。 根据触发位置不同，有可以分为XDP（express data path）程序、TC（traffic control流量控制）程序、套接字程序以及cgroup程序。 XDP程序在网络驱动程序刚刚收到数据包时触发执行，定义为BPF_PROG_TYPE_XDP XDP程序并没有绕过内核协议栈。而是在内核协议栈之前处理数据包，处理后的数据包还可以正常通过内核协议栈继续处理。 根据网卡和网卡驱动是否原生支持XDP程序，XDP可以分为三种： 通用模式：xdp程序运行在内核中，性能差，一般用于测试，不需要网卡和网卡驱动支持 原生模式：需要网卡驱动支持 卸载模式：网卡固件支持XDP卸载，XDP程序直接运行在网卡上，不需要消耗CPU资源，具有最好的性能。 XDP程序通过ip link命令加载到具体的网卡上。 内核跟踪问题即时编译器是事件被触发才会编译吗？ 参考XDP","link":"/2022/05/07/eBPF%E5%AD%A6%E4%B9%A0/"},{"title":"ef_vi soolarflare开发","text":"简介ef_vi允许应用程序直接访问Solarflare网卡数据路径，以降低延迟并减少每条消息的处理开销。它可以直接用于那些需要最低延迟的发送和接收API，并且不需要POSIX套接字接口的应用程序。 特点ef_vi的主要特点是： 用户空间：ef_vi可由非特权用户空间应用程序使用。 内核旁路：数据路径操作不需要系统调用。 低CPU开销：数据路径操作占用很少的CPU周期。 低延迟：适用于超低延迟应用。 高数据包速率：每个核心每秒支持数百万个数据包。 零拷贝：对于过滤和转发应用程序特别有效。 ef_vi位于数据链路层，OSI第二层，用来收发以太网数据帧。本质上是网络适配器提供的VNIC（虚拟网络接口控制器）接口的封装。 ef_vi可以用来指定只处理某个端口的数据包，也就是可以与标准linux内核网络栈和其他加速技术同时使用。 用途加速socket可用于替代socketsAPI。 例如：在hft系统中处理多播UDP数据报。 应用程序将建立一个ef_vi实例 应用程序给定目标IP地址和端口号。 只有需要加速的数据包才由ef_vi处理。 其他还是内核处理。 应用程序可以创建多个ef_vi实例来处理不同的数据包流，或者在多个线程上分散负载。如果每个传输线程都有自己的ef_vi实例，那么它们可以在无锁和不共享状态的情况下并发传输数据包。这大大提高了效率。 啥意思？可以多线程处理同一条数据路径？ 抓包Solarflare的SolarCapture软件构建在ef_vi API之上。与传统的捕获API一样，ef_vi可用于捕获到达网络端口或子集的所有数据包，并打时间戳。 其他用途：包重放、作为end-station、网络虚拟化。 概念每个ef_vi实例，提供了一个网卡的虚拟接口，如下： 一个虚拟接口包括三个组件：Event queue、Transmit descriptor ring、Receive descriptor ring。（这是软件资源） 一个虚拟接口（就是一个ef_vi实例）的硬件资源： 两个寄存器，用来通知TX、RX 缓冲区可用。？ 一些定时器? 一个共享的中断。 event queue用来网卡和应用程序之间传递消息。比如通知应用程序有数据包到达的事件。 transmit descriptor ring将数据包从应用程序传递到网卡。环中的每个条目都是一个描述符，它引用包含数据包的缓冲区。每个数据包由一个或多个描述符描述。数据包的传输在后台进行，适配器在数据包传输完成后通过事件队列通知应用程序。 Receive descriptor ring将数据包从适配器传递到应用程序。应用程序必须预先分配缓冲区并将其发送到接收描述符环。环中的每个条目都是一个描述符，它引用适配器可以将数据包放入的“空闲”缓冲区。当适配器向ef_vi实例发送数据包时，它会将数据包复制到下一个可用的接收缓冲区，并通过事件队列通知应用程序。 大数据包可以分散在多个接收缓冲区上。 Protection Domain 每个虚拟接口都与一个保护域相关联。 每个内存区域都注册了一个或多个保护域。这样可用共享资源，做零拷贝转发。 Memory Region发送或接收缓冲区的内存区域要使用ef_memreg接口注册。 这确保了内存区域符合ef_vi的要求： 内存被固定，因此无法交换到磁盘。 内存映射为DMA，以便网络适配器可以访问它。适配器将应用程序提供的DMA地址转换为PCIe总线上使用的I/O地址。 内存区域与页面对齐，以提高性能。 内存区域的大小是数据包缓冲区大小的倍数，因此不会浪费内存。 Packet Buffer就是收发数据包的buffer，通常大小2kb，只有同一保护域中的虚拟接口才能访问。是memory region么。 大数据包可能分散在多个packet buffer上。 Packet Buffer Descriptor每个包缓冲区用一个descriptor引用，包含了： 一个指针，指向实际的buffer内存区 一个偏移量，谁的偏移量？ 一个长度 rings上存放的就是这些描述符。 Programmed I/O?没看懂 Fliter选择哪些数据包被传递到虚拟接口。其他的走内核。 根据数据包的特征过滤。比如以太网MAC地址、VLAN标记、IP地址和端口号。 问题ef_vi用到的硬件资源怎么理解。","link":"/2022/05/11/ef-vi-soolarflare%E5%BC%80%E5%8F%91/"},{"title":"fail2ban配置","text":"记录一次服务器被黑的经历，， 看到有奇怪的进程在跑，sudo切换到其用户下，看history。。 fail2ban配置12345sudo apt install fail2bancp /etc/fail2ban/jail.conf /etc/fail2ban/jail.localsudo cp /etc/fail2ban/jail.conf /etc/fail2ban/jail.local","link":"/2021/11/19/fail2ban%E9%85%8D%E7%BD%AE/"},{"title":"gdb学习","text":"gdb笔记 GDB功能 gdb有四个主要功能： 启动程序，指定任何可能影响其行为的内容 打断点，让程序在特定条件下停下来 当程序停止时，检查发生了什么 改变程序变量 启动gdb 命令行输入: gdb program gdb program core gdb program 1234 或者 gdb -p 1234 ，调试一个正在运行的进程 常用命令 break [file:]function 在function中设置断点 run [arglist] 使用arglist启动程序 print expr 显示表达式的值 c 继续运行程序 next 执行下一行代码，step over function step 执行下一行代码，step into function help [name] 显示name的帮助，name是命令 quit 退出gdb 命令选项 -help / -h 列出所有选项 -symbols=file / -s file 从file中读符号表 -write 开启写入到可执行与核心文件？？ -exec=file / -e file","link":"/2021/01/09/gdb%E5%AD%A6%E4%B9%A0/"},{"title":"git原理及使用","text":"git是一个内容寻址文件系统，核心部分是一个键值对数据库。以hexo博客的git管理为例分析。 .git文件夹下有什么六个文件先用tree命令看下.git文件夹下的内容 git将整个数据库存储在.git目录下 首先看几个文件 COMMIT_EDITMSG：记录了最后一次commit时的msg，比如 HEAD ：文本文件，指向当前工作区所在的分支，比如以下，表示当前工作分支在hexo 然后看refs/heads/hexo下有什么 config：文本文件，git相关配置，比如 description：关于该仓库的描述 index：这个就是git三分区中的索引，也叫暂存区。index是一个二进制文件，直接cat出来是乱码 可以用git ls-files -s显示index中的部分数据，实际index文件结构复杂的多，见https://zhuanlan.zhihu.com/p/142289703 包含了四个字段：文件类型和权限（file mode bits）、文件sha-1值、用来处理冲突的stage number、文件路径 packed-refs：ref下文件的打包，比如 六个文件夹branches hooks：里面放了一些shell脚本，比如 info： logs：每个分支的提交日志 object：最重要的文件夹，存放git对象object refs： git中的四种对象 blobblob：存储的是文件内容，是二进制的数据文件，只包含文件内容，不包含其他文件信息如文件名创建时间等。 这样设计的优点，比如只修改一个文件名，只需要在tree里进行修改，而不需要重新创建blob。 修改文件后的每一次add，都会为文件创建新的blob，也就是文件的全新快照，而不是文件的变更部分，空间换时间。不过git本身自己也有优化，pack。blob的文件名就是sha-1的值。 treetree：对应文件系统里的目录结构，保存了文件类型，权限，hash（这个指向了blob），文件名。比如 各字段解释如下： commit1git log --graph --pretty=format:'%Cred%h%Creset -%C(yellow)%d%Creset %s %Cgreen(%cr)%Creset' --abbrev-commit --date=relative #查看commit commit：是一次修改的集合，指向对应目录结构快照tree 指向的tree: 可以看出这就是当时的整个目录结构。 commit各字段解释如下： refstag是一个固化的分支，就是这个tag代表的内容永远不可改变，关联了当时版本库中最后一个commit，软件发布时候一般用tag git操作时obj发生了什么变化add操作这里将a.txt文件内容111修改为333，然后add。这时git仓库中新建了一个新的blob保存a文件的新内容，然后更新索引，将a.txt指向了新的blob对象 commit操作首先根据当前索引指向情况创建新的tree obj（图中的三角），这样保证新建的tree指向的是最新的文件，作为提交的快照。 然后创建新的commit obj，保存本次的commit信息，父亲节点指向上一个commit，形成链状的变更历史 更新分支指向。 git基本使用参考资料https://zhuanlan.zhihu.com/p/96631135 https://zhuanlan.zhihu.com/p/142289703","link":"/2021/07/28/git%E5%8E%9F%E7%90%86%E5%8F%8A%E4%BD%BF%E7%94%A8/"},{"title":"google c++ 代码规范","text":"Ctrl + ,， 打开设置 输入 clang-format 将C_Cpp.clang_format_fallbackStyle值从Visual Studio改为 Google","link":"/2021/08/09/google-c-%E4%BB%A3%E7%A0%81%E8%A7%84%E8%8C%83/"},{"title":"hexo图片插入","text":"配置Typora文件 $\\longrightarrow$ 偏好设置 安装hexo-asset-image安装0.0.1版，1.0.0会出现.com问题 打开博客根目录下的package.json文件，如下修改： 1\"hexo-asset-image\": \"0.0.1\", 然后在博客根目录下 1npm install 使用以下格式在md文件中即可插入图片： 1![](xxxx/example.jpg) vscode remote 图片上传插件https://marketplace.visualstudio.com/items?itemName=sakamoto66.vscode-paste-image${fileBasenameNoExtension}这样就可以remote编写markdown插入图片了,ctrl+alt+v markdown 导出 pdfhttp://sunqunyan.net/2019/08/11/markdown-pdf/ 参考资料：https://alreadyright.github.io/2019/06/16/aboutHexo/","link":"/2019/07/27/hexo%E5%9B%BE%E7%89%87%E6%8F%92%E5%85%A5/"},{"title":"hft warm up","text":"内存管理Linux 内存管理 C++内存管理 hft低延迟技术编程细节 硬件架构 系统性能调优Linux低延迟服务系统调优 Linux 对CPU core 屏蔽timer interrupt Linux获取ns时间戳 RDTSC的坑 Linux 性能优化 CPUCPU如何读写数据、CPU如何选择线程 CPU cache 基本工具perf、strace、netstat、lsof、vtune 理解内存性能kungfu易筋经一个journal由多个page组成，一个page由page header和若干个frame组成。一个frame由一个frame header和data组成。frame是数据的最小写入单元。 一个journal只能有一个写入线程，writer在写入时，每一次都是通过一个院子操作在journal中形成一个frame。 每个写入线程对应了一种特定的应用，如行情接受，交易下单等。 x86指令相关https://www.felixcloutier.com/x86/","link":"/2022/04/06/hft-warm-up/"},{"title":"leveldb入门到放弃","text":"leveldb是LSM（Log Structured-Merge Tree）树的经典实现，除去测试部分，代码量大概1.5W行，遵循google c++代码规范。 调试环境搭建1234567#先git clonemkdir -p build &amp;&amp; cd buildcmake -DCMAKE_BUILD_TYPE=Debug .. &amp;&amp; cmake --build .#回到根目录sudo cp -R include/leveldb /usr/local/includesudo cp ./build/libleveldb.a ./test LSM-tree 设计LSM tree的目的是为了实现高效写入操作。 为什么要提出LSM-Tree，因为原有的B+树的写操作太慢了，根本原因是磁盘的随机操作满，顺序读写快。 以此磁盘I/O的时间 = 寻道时间 + 旋转时间 + 数据传输时间 其中寻道是磁头移动到正确的磁道，旋转是讲扇区移动到磁头下，这两个都是机械操作，磁头寻址耗时造成随机操作耗时。 磁盘的顺序读写要远快于随机读写，而且快了三个数量级。 LSM-tree 的通用结构 LSMtree由内存驻留组件和磁盘驻留组件组成。 整体设计 memtable一次leveldb的写入过程并不是直接将数据持久化到磁盘文件中，而是先写将操作写到日志文件中，然后将写操作应用到memtable。 memtable是在内存中维护的一个跳表的数据结构。系统运行过程中，如果memtable中的数据占用达到指定值（write buffer size），memtabe 会转化为immutabel，然后自动生成新的memtable。immutable 被新的线程dump到磁盘中，dump结束后immutable就可以被释放了。 12345678910111213141516171819202122232425262728class MemTable {//是一个接口类，核心的数据结构是里面的skipList，定义在memtable.h里 public: ... // 引用计数 void Ref() { ++refs_; } //自身引用为0，则析构 void Unref() { --refs_; assert(refs_ &gt;= 0); if (refs_ &lt;= 0) { delete this; } } //跳表的一个迭代器，可以用来便利table的内部数据，很好的设计思路，可以用来隐藏table的内部实现 Iterator* NewIterator(); //添加和删除数据的接口，注意到这里没有Delete的接口，是因为memtable的delete是插入一条type为delete的记录 void Add(SequenceNumber seq, ValueType type, const Slice&amp; key, const Slice&amp; value); bool Get(const LookupKey&amp; key, std::string* value, Status* s); private: ... typedef SkipList&lt;const char*, KeyComparator&gt; Table; ... int refs_; Table table_;}; 跳表中KV的存储格式为： 1234| Internal Key size | internal key | value len |value|其中internal key = |user key |sequence number |type |Internal key size = key size + 8 跳表的排序基于： 首先根据user key按升序排列 然后根据sequence number按降序排列 最后根据value type按降序排列 跳表 一种支持二分查找的有序链表 就是在原始的链表上加了多级索引 SStable 数据最终在磁盘上的物理存储，sorted string table. 一个sstable就是一个文件，作者在doc/table_format.md描述了文件的逻辑结构 123456789101112&lt;beginning_of_file&gt;[data block 1][data block 2]...[data block N][meta block 1]...[meta block K][metaindex block][index block][Footer] (fixed size; starts at file_size - sizeof(Footer))&lt;end_of_file&gt; Data Block：存储KV对，有序 Meta Block：每一个DataBlock对应一个Meta Block，存储的是布隆过滤器，可以快速定位key是否在data block中 Meta Index Block：对meta block的索引，&lt;过滤器名字，offset，size&gt; Index Block：是对Data Block的索引，&lt;该块最大key值，该块在sstabl中的偏移量，块大小&gt; Footer：可以理解成文件头 查找key步骤 找文件：找到可能包含key的sstable 加载IB和FB：把sstable中的index block和filter block加载到内存 查找IB：二分查找index block找到可能包含key的data block 查找FB：通过过滤器判断key是否在data block中 加载DB：如果过滤器判断在，则加载data block 查找DB：二分查找data block 读数据 如果fliter判断不存在或者查找不存在，则在下一个搜索候选文件。 Block 存储格式块是sstable的组成单位，一个块约4kb大小，块大不是定长而是一个阈值，为了。 Block有三部分组成：block data, type, crc32，默认每个块大小为4kb。 其中type是压缩方式：none或则snappy。 12345class BlockHandle {private: uint64_t offset_; uint64_t size_;}; 布隆过滤器 布隆过滤器是未来在大量数据中查询某个字符串是否存在 比如： word如何判断某个单词是否拼写正确 网络爬虫中如何不去爬相同的页面 定义布隆过滤器是一种概率型的数据结构，特点是高效的插入和查询，能返回某个字符串一定不存在或者可能存在，相比传统的数据结构，如hash表，set，map更加高效，占用的空间更小，代价是返回的结果是概率存在，同时不支持删除操作。 组成 bitmap + n个hash函数 原理 添加：利用n个hash函数将这个元素映射到位图里的n个点，置为1 查找：用n个hash函数检测位图中的k个点是否都为1，如果有不为1的点，就认为不存在，全部为1，则可能存在（hash冲突） SSTable的合并 合并分两类：minor compaction和major compaction minjor compactionimmutable memtable持久化成sstable的过程，优先级高，完成内存数据的持久化 注意到level 0层的sstable文件数据是可能存在overlap的，所以需要往下合并，去重，提高查找效率。 major compaction触发条件 0层文件超过上限（4个） level i层文件总大小超过（10^i）MB 某个文件无效读取次数过多 合并流程 寻找第一个输入文件：不同触发条件的输入文件不同 根据key的重叠情况扩大输入文件集合 多路合并：i和i+1层文件中的数据项合并，冗余数据清理，保留最新数据，输出到i+1层 缓存系统 缓存的是sstable中的文件对象和相关元数据，如果以此读操作都会发生一次磁盘IO，那么整体效率会非常低下，所以需要把热数据加入cache。 TableCache查找数据时，现在memtable和immutable 中查找，如果都查找不到，那么就要打开sst文件，解析文件中的index block，然后根据index block 找到对应的data block中进行查找，如果对于每次sst查询都经历上述步骤，效率很低。因此引入了table cache来缓存sst文件和对应的index block。 table cache创建/db_impl.cc文件中的的DB构造函数中创建了table_cache_ table_cache_是TableCache的一个实例化对象，然后跳转到TableCache的构造函数里看： 123456TableCache::TableCache(const std::string&amp; dbname, const Options&amp; options, int entries) : env_(options.env), dbname_(dbname), options_(options), cache_(NewLRUCache(entries)) {} 发现TableCache的成员对象cache_是由NewLRUCache函数初始化的，再跳转到NewLRUCache: 1Cache* NewLRUCache(size_t capacity) { return new ShardedLRUCache(capacity); } 发现cache_实际是ShardedLRUCache对象的一个实例。 ShardedLRUCache123456789101112class ShardedLRUCache : public Cache { private: LRUCache shard_[kNumShards]; ... public: explicit ShardedLRUCache(size_t capacity) : last_id_(0) { const size_t per_shard = (capacity + (kNumShards - 1)) / kNumShards; for (int s = 0; s &lt; kNumShards; s++) { shard_[s].SetCapacity(per_shard); } } 可以看出ShardedLRUCache里面维护了一个LRUCache数组。 这样设计的目的是为了减少多线程访问加锁时的竞争，查找key的时候，先计算属于哪一个LRUCache，然后只对一个LRUCache进行加锁，而不是整个cache一把锁。分区是一个减少竞争的策略，比如ptmalloc在管理堆内存的时候也引入了arena分配区的概念，malloc和free时先查找要在哪个分配区上进行操作，只对一个分配区加锁。都是为了减少竞争。 所以看LRUCache的实现就可以了。 LRUCache在跳转到LRUCache: 12345678910111213141516171819202122232425262728293031323334353637383940class LRUCache { public: ... Cache::Handle* Insert(const Slice&amp; key, uint32_t hash, void* value, size_t charge, void (*deleter)(const Slice&amp; key, void* value)); Cache::Handle* Lookup(const Slice&amp; key, uint32_t hash); void Release(Cache::Handle* handle); void Erase(const Slice&amp; key, uint32_t hash); void Prune(); size_t TotalCharge() const { MutexLock l(&amp;mutex_); return usage_; } private: void LRU_Remove(LRUHandle* e); void LRU_Append(LRUHandle* list, LRUHandle* e); void Ref(LRUHandle* e); void Unref(LRUHandle* e); bool FinishErase(LRUHandle* e) EXCLUSIVE_LOCKS_REQUIRED(mutex_); // Initialized before use. size_t capacity_; // mutex_ protects the following state. mutable port::Mutex mutex_; size_t usage_ GUARDED_BY(mutex_); // Dummy head of LRU list. // lru.prev is newest entry, lru.next is oldest entry. // Entries have refs==1 and in_cache==true. LRUHandle lru_ GUARDED_BY(mutex_); // Dummy head of in-use list. // Entries are in use by clients, and have refs &gt;= 2 and in_cache==true. LRUHandle in_use_ GUARDED_BY(mutex_); HandleTable table_ GUARDED_BY(mutex_);}; 缓存失效问题 开始时，M1将immutable memtable刷盘，R2请求285，失效。M2产生了compaction，L1的一个块和L2的两个块合并，新产生的块放在L3，这时R5访问155，155所在的块已经被修改，cache失效，R7访问205，同样失效。 版本控制什么时候产生新的版本sstable的更替对leveldb来说是一个最小的操作单元，具有原子性，leveldb每次生成或者删除sstable，就会产生新的版本。 代码分析Getstatus = db-&gt;Get(leveldb::ReadOptions(),key, &amp;value); 12345678910111213141516171819202122232425262728293031323334353637383940414243444546Status DBImpl::Get(const ReadOptions&amp; options, const Slice&amp; key, std::string* value) { Status s; MutexLock l(&amp;mutex_); SequenceNumber snapshot; if (options.snapshot != nullptr) { snapshot = static_cast&lt;const SnapshotImpl*&gt;(options.snapshot)-&gt;sequence_number(); } else { snapshot = versions_-&gt;LastSequence(); } MemTable* mem = mem_; MemTable* imm = imm_; Version* current = versions_-&gt;current(); mem-&gt;Ref(); if (imm != nullptr) imm-&gt;Ref(); current-&gt;Ref(); bool have_stat_update = false; Version::GetStats stats; // Unlock while reading from files and memtables { mutex_.Unlock(); // First look in the memtable, then in the immutable memtable (if any). LookupKey lkey(key, snapshot); if (mem-&gt;Get(lkey, value, &amp;s)) {//从memtable里查找 // Done } else if (imm != nullptr &amp;&amp; imm-&gt;Get(lkey, value, &amp;s)) {//immutable memtable里查找 // Done } else { s = current-&gt;Get(options, lkey, value, &amp;stats);//查cache和sstable have_stat_update = true; } mutex_.Lock(); } if (have_stat_update &amp;&amp; current-&gt;UpdateStats(stats)) { MaybeScheduleCompaction(); } mem-&gt;Unref(); if (imm != nullptr) imm-&gt;Unref(); current-&gt;Unref(); return s;} 列簇 列簇 column families是rocks db中的概念 数据分片，将键值对按照不同的属性分配给不同的CF 问题 利用sstable中的index block进行快速的数据项位置定位，得到该数据项有可能存在的两个data block；？？为什么两个 引用计数和锁 compaction 为什么能平衡读写 参考资料 讲TableCache的：https://axlgrep.github.io/tech/leveldb-tablecache.html leveldb代码解析：https://github.com/SmartKeyerror/reading-source-code-of-leveldb-1.23 https://wingsxdu.com/post/database/leveldb/","link":"/2021/11/05/leveldb%E5%85%A5%E9%97%A8%E5%88%B0%E6%94%BE%E5%BC%83/"},{"title":"markdown常用公式符号","text":"123456789101112131415161718192021222324252627282930311. 上标$$x^2$$2. 下标$$x_i$$3. 累加$$\\sum$$4. 分数$$\\frac{1}{3}$$5. 开方$$\\sqrt{2}$$6. 矢量$$\\vec{x}$$7. 积分$$\\int$$ $$\\int_0^1x^2$$8. 常见希腊字母 $\\alpha$,$\\beta$,$\\gamma$,$\\delta$,$\\theta$9. 叉乘$$\\times$$10. 点乘$$\\cdot$$11. 除$$\\div$$12. 矩阵$$\\begin{matrix}1 &amp; 2 &amp; 3 \\\\4 &amp; 5 &amp; 6 \\\\7 &amp; 8 &amp; 9 \\end{matrix} \\tag{1}$$13. 带括号的矩阵$$\\left[\\begin{matrix}1 &amp; 2 &amp; 3 \\\\4 &amp; 5 &amp; 6 \\\\7 &amp; 8 &amp; 9 \\end{matrix} \\right]\\tag{2}$$14. 约等于$\\approx$ 上标$$x^2$$ 下标$$x_i$$ 累加$$\\sum$$ 分数$$\\frac{1}{3}$$ 开方$$\\sqrt{2}$$ 矢量$$\\vec{x}$$ 积分$$\\int$$ $$\\int_0^1x^2$$ 常见希腊字母$\\alpha$,$\\beta$,$\\gamma$,$\\delta$,$\\theta$ 叉乘$$\\times$$ 点乘$$\\cdot$$ 除$$\\div$$ 矩阵$$\\begin{matrix}1 &amp; 2 &amp; 3 \\4 &amp; 5 &amp; 6 \\7 &amp; 8 &amp; 9\\end{matrix} \\tag{1}$$ 带括号的矩阵 $$\\left[\\begin{matrix}1 &amp; 2 &amp; 3 \\4 &amp; 5 &amp; 6 \\7 &amp; 8 &amp; 9\\end{matrix} \\right]\\tag{2}$$ 约等于$\\approx$","link":"/2019/07/27/markdown%E5%B8%B8%E7%94%A8%E5%85%AC%E5%BC%8F%E7%AC%A6%E5%8F%B7/"},{"title":"matlab模拟退火工具箱satools","text":"​ 记录了模拟退火的原理和matlab第三方工具箱satools的使用。 算法原理 SATOOLS使用模拟退火主函数anneal调用格式：1234567891011function [W,Ew,Wbsf,Ebsf,Tt,Et,Etarget,ert,Kt,Ebsft,Eh,M,rho,Ebin] = anneal( ... verbose, ... newstate, X, ... cost, moveclass, ... walkers, ... acceptrule, q, ... schedule, P, ... equilibrate, C, maxsteps, ... Tinit, r, ... Tfinal, f, maxtemps, ... v, bins, e) 参数说明输入参数 verbose：flag变量，为1时打印状态变量 newstate：用户自定义函数,产生初始解 X：问题的domain(解空间?)，常量 cost：用户自定义函数，最优化的目标函数 moveclass：用户自定义函数，用来产生新解 walkers：正整数 acceptrule：用户自定义函数，接受规则，工具箱也提供了几个，经常用metropolis准则 q：acceptrule所需要的参数 schedule：温度更新函数，可自定义 P：schedule所需参数 equilibrate：(平衡)可传入函数句柄或其他。当传入函数时，表示温度是否改变的判断函数 C：equilibrate所需参数 maxsteps：同一温度下的迭代最大次数 Tinit：初始化函数，可自定义可使用工具箱提供函数。 r：Tinit所需参数 Tfinal：终止温度，可以是自定义函数，工具箱也提供，或者是数（-INF ok） f：参数 maxtemps：最大温度迭代次数 v：温度变化的快慢$[0,1]$ bins： e： 输出参数 W：每个walker的最终状态 Ew：W对应的最终能量 Wbsf：每个walker的best so far状态 Ebsf：每个walker的best so far能量 Tt(i)：每次温度步的温度记录 Et(i)：Tt(i)对应的平均能量 Etarget（i）：Tt(i)对应的目标平均能量，根据v计算 ert(i)： kt(i)：Tt(i)对应的热平衡步数 Ebsft(i)：Tt(i)对应的best so far能量 Eh：能量和温度的历史记录 i = 1,1 + (steps*walkers) Eh(i,1)：温度步的下标t Eh(i,2)：t对应的温度T Eh(i,3)：在温度T时的达到热平衡步数的编号j Eh(i,4)：walker的编号k Eh(i,5)：在T温度下,第j步，walker k对应的能量 Eh(i,6)：在T温度下,第j步，energy E' attempted from E M： rho： Ebin： 自定义函数编写 newstate产生初始解， 12345678910111213function W = PROBLEMNAME_new(X)% W = PROBLEMNAME_new(X)% See http://www.frostconcepts.com/software for information on SA Tools.%% W = PROBLEMNAME_new(X) ;%% X = behaviorally constant application data%% W = specific data about current state%% Instantiates a new state.%W = [] ; % a typical application will put state specific data here cost最优化目标 12345678910function Ew = PROBLEMNAME_cost(X,W)% Ew = PROBLEMNAME_cost(X,W)%% X = behaviorally constant application data%% W = specific data about current state%% Ew = energy corresponding to W%Ew = rand ; % a typical application will use information from W and X to compute Ew. moveclass产生新解 123456789function W = PROBLEMNAME_perturb(X,W,Ea,T)% W = PROBLEMNAME_perturb(X,W,Ea,T)%% X = behaviorally constant application data%% W = (on input) current state, (on output) next state.%% Ea = current average energy% T = current temperature 产生解空间 123456function X = PROBLEMNAME_init()% X = PROBLEMNAME_init()%% X = behaviorally constant application data%X = [] ; % a typical application will put problem domain data here","link":"/2019/08/11/matlab%E6%A8%A1%E6%8B%9F%E9%80%80%E7%81%AB%E5%B7%A5%E5%85%B7%E7%AE%B1satools/"},{"title":"mcm离散型题目及思路记录","text":"简单记录了题目和思路。 2017B ”拍照赚钱“的任务定价问题描述在拍照赚钱APP中，用户可以领取拍照任务，完成任务后可以获得酬金，不同的任务又不同的定价。 附件一给了任务的位置（经纬度），定价，完成情况，需要分析任务未完成的原因。 制定新的定价方案，并和原方案比较。 考虑任务联合打包发布规则下的定价模型，并分析对最终任务完成情况的影响。 对附件三种的新项目给出定价方案。 思路问题一：从定性和定量角度分析，先使用cftool工具箱绘制定价和经纬度坐标的三维拟合图，观察结果定性得出结论。然后利用kmeans聚类，将地图划分为网格区域，每个网格内定义四个指标，然后利用灰色关联矩阵定量分析定义的指标和定价的相关程度，然后通过对比未完成任务和已完成任务的相关度矩阵得出最显著的影响因素。 问题二：将定价方案看作优化问题，总成本最小化，完成率最大化：$\\left{ \\begin{array} { l } { \\min \\sum _ { i = 1 } ^ { 835 } p _ { i } } \\ { \\max \\sum _ { i = 1 } ^ { 835 } C _ { i } } \\end{array} \\right.$，定义了吸引度矩阵： 定义阈值，$w _ { i } = \\left{ \\begin{array} { l } { \\min \\left{ w _ { i j } \\right} , C _ { i } = 1 } \\ { \\max \\left{ w _ { i j } \\right} , C _ { i } = 0 } \\end{array} \\right.$当第i 个任务被完成时，其阈值至少低于其对一个会员的吸引度；当第i 个任务未被完成时，其阈值不低于任何其对一个会员的吸引度。 问题三：修改优化模型，通过聚类分析打包任务，修改吸引力矩阵，重新进行搜索。 问题四：聚类分析将任务打包，然后用第三问的任务数据和最优定价作为训练数据训练神经网络，再带入附件三的数据得到定价。 2016B 小区开放对道路通行的影响问题描述 建立评价指标体系，评价小区开放对周边道路通行的影响。 建立车辆通行的数学模型，用以研究小区开放对周边道路通行的影响。 小区开放产生的效果，可能会与小区结构及周边道路结构、车流量有关。请选取或构建不同类型的小区，应用你们建立的模型，定量比较各类型小区开放前后对道路通行的影响。 思路问题一:找指标，先找了多个指标，利用聚类分析把影响因素进行归类，然后利用层次分析法构建评价体系。 问题二：利用元胞自动机模拟道路情况，车辆变量更新规则有NS模型， 然后考虑道路通行能力，安全性，便捷度，建立模糊综合评价模型。通行能力利用层次分析法评定，安全性自己定义公式，便携度求最短路径。 问题三：针对不同小区，确定问题二模型中的参数，相当于模型求解。 2015B “互联网+”时代的出租车资源配置问题描述请你们搜集相关数据，建立数学模型研究如下问题： (1) 试建立合理的指标，并分析不同时空出租车资源的“供求匹配”程度。 (2) 分析各公司的出租车补贴方案是否对“缓解打车难”有帮助？ (3) 如果要创建一个新的打车软件服务平台，你们将设计什么样的补贴方案，并论证其合理性。 思路问题一：还是找指标，里程利用率，供求比率 里程利用率 K =载客里程（公里）/行驶里程（公里）*100% 然后确定这两个指标在供求平衡下的理想值（不是1） 然后再对不同时段（高峰，常规），不同空间（市区，郊区）进行模拟。 问题二： 软件使用比例计算： 意愿半径计算：即司机为接单愿意行驶的最大距离。也是用函数拟合的思路，定义一个函数形式，带入已知求出参数。 不同的时间段有不同的补贴金额，缓解率也随时间变化，可以绘制变化曲线。 第三问：开放问题，示例论文中采用了分区域动态实时补贴的方法，自己值定了一些规则，根据规则列出方程，解方程得到的结果。 也可以采用最优化问题的求解思路，站在平台的角度，补贴最少，效益最高。 2014B 创意平板折叠桌做过，不写了，模拟动态变化的过程就是推导桌子角度变量间的一些关系式，加工参数确定看成最优化问题。 2013B 碎纸片拼接复原做过，不写了，有点难。 2012B 太阳能小屋的设计问题描述：问题1：请根据山西省大同市的气象数据，仅考虑贴附安装方式，选定光伏电池组件，对小屋（见附件2）的部分外表面进行铺设，并根据电池组件分组数量和容量，选配相应的逆变器的容量和数量。 问题2：电池板的朝向与倾角均会影响到光伏电池的工作效率，请选择架空方式安装光伏电池，重新考虑问题1。 问题3：根据附件7给出的小屋建筑要求，请为大同市重新设计一个小屋，要求画出小屋的外形图，并对所设计小屋的外表面优化铺设光伏电池，给出铺设及分组连接方式，选配逆变器，计算相应结果。 思路第一问：电池板有三种串并联方式，不同的串并联方式还可以连接不同的逆变器，针对每种串并联方式，设置最优化目标: 全年功率最大化：$\\max W_{jmA}$，逆变器和电池总价最小化：$\\min p_{jmA}$，j表示墙免编号，m表示逆变器型号，A表示不同的电池连接方式。 针对该多目标优化问题，分别先做单目标规划下的最优值，求解出$W’{jmA}$和$p’{jmA}$ 然后再构造单目标规划： $f = (W_{jmA}-W’{jmA})^2+(p{jmA}-p’_{jmA})^2$ 根据此形式构造出优先级函数，得到不同型号逆变器的最佳组合方式定义优先级： $f’ = (\\frac{W_{jmA}-W_{max}}{W_{max}})^2+(\\frac{p_{jmA}-p_{min}}{p_{min}})^2 $ 采用贪心的方法根据优先级进行安装。 第二问：最优化，找到全年辐射强度最大的角度。 然后需要研究电池板的投影情况，阴影情况限制了电池的铺设。 第三问：根据房屋建设的标准制定约束，以全年接受光强之和为优化目标。 2012A 葡萄酒评价问题描述 分析附件1中两组评酒员的评价结果有无显著性差异，哪一组结果更可信？ 根据酿酒葡萄的理化指标和葡萄酒的质量对这些酿酒葡萄进行分级。 分析酿酒葡萄与葡萄酒的理化指标之间的联系。 分析酿酒葡萄和葡萄酒的理化指标对葡萄酒质量的影响，并论证能否用葡萄和葡萄酒的理化指标来评价葡萄酒的质量？ 方法记录熵值法用于特征剔除","link":"/2019/08/15/mcm%E7%A6%BB%E6%95%A3%E5%9E%8B%E9%A2%98%E7%9B%AE%E8%AE%B0%E5%BD%95/"},{"title":"ml4sys笔记","text":"A Learning-based Approach Towards Automated Tuning of SSD Configurations 提出了LearnedSSD框架。对于新的工作负载，LearnedSSD将提取其特征，并使用相似性比较网络将其与ConfDB(实现中使用leveldb)中的记录进行比较。如果LearnedSSD在其ConfDB中识别出类似的工作负载，它将直接推荐相应的SSD配置，这样我们就可以利用之前学到的经验。否则，LearnedSSD将为工作负载学习新的SSD配置，并将它们添加到其ConfDB中以供将来参考。 开发了一种基于块I/O跟踪的基于学习的聚类方法。选择块I/O跟踪来了解存储工作负载的特征。跟踪特征包括I/O时间戳、I/O大小、设备号、块地址和操作类型。使用主成分分析将数据点转换为二维。之后使用k-means对这些数据点进行聚类。 在对一个新工作负载的所有数据点进行聚类后，我们将计算被检查数据点的中心与现有集群中心之间的距离。如果距离低于一个阈值，属于现有的工作负载集群。如果LearnedSSD无法识别类似群集，LearnedSSD将为新工作负载创建一个新群集。 然后这里就又一个问题，如何生成新配置？ LearnedSSD一次调整一个或两个相关参数，然后保留满足约束的参数。对于其他参数，LearnedSSD将在搜索空间中来回调整其值。一旦我们确定了一种配置的参数，LearnedSSD将使用GPR模型来确定具有最佳预测性能等级（4）的配置。如果其性能等级优于搜索根，LearnedSSD将此配置设置为新的搜索根，并继续下一次搜索迭代。SGD程序（3）的主要挑战是平衡学习精度和开发开销。由于无法保证初始配置集将覆盖整个搜索空间，LearnedSSD必须逐步扩展其搜索空间，以确保能够识别最佳配置。然而，这可能会导致搜索空间爆炸。为了解决这个问题，我们引入了一个启发式利用因子，即正在利用的配置与现有学习配置之间的最小曼哈顿距离[77]。我们还为配置探索中的搜索迭代次数设置了一个阈值（LearnedSSD中默认为20次迭代）。 预测已探索配置的等级。LearnedSSD使用GPR[59]预测新配置的等级（4）。这主要有三个原因。首先，GPR可以提供与深度神经网络几乎相同的性能，尤其是在搜索最优配置和提出建议的建模方面。其次，它在探索新知识和学习知识之间提供了极好的权衡[44,67]。第三，默认情况下，GPR以较低的计算开销提供置信区间[9]。在LearnedSSD中，我们通过指定其均值函数和协方差函数来建立一个新的GPR模型。由于在LearnedSSD中学习之前，性能指标的平均值未知，因此平均值函数配置为可训练。我们使用协方差函数来表示模型的两个相邻点之间相关性 ，采用径向基函数（RBF）核[75]和有理二次核[76]作为回归协方差。我们还添加了一个用于随机噪声模拟的白核[47] Lynx: A Learning Linux Prefetching Mechanism For SSD Performance Model 为了执行顺序预取，需要回答两个主要问题：何时预取，以及预取多少数据。传统的Linux预读机制通过将PoM和PoH关联起来来回答第一个问题。在缺页的情况下启动同步预读操作，在命中的情况下启动异步预读操作。对于第二个问题，预读会在32个连续页面的窗口大小内从存储设备预取数据。当特定文件的未命中率增加时，预读窗口会缩小，因为预取被评估为低效。然后，要预取的数据量是动态的。","link":"/2022/03/23/ml4sys%E7%AC%94%E8%AE%B0/"},{"title":"oceanbase 2022 比赛复盘","text":"oceanbase 2022 比赛复盘 初赛初赛在 miniob 上进行 决赛决赛场景针对数据库的数据导入功能，及将csv文件中的数据导入到oceanbase中存储。业界常见的两种导入方式主要有两种，一种是逻辑导入，就是将csv文件要导入的数据编码成sql语句，然后运行这些sql语句完成导入。第二种方法更为高效，称为物理导入，也叫旁路导入，就是不经过sql接口，直接将数据编码成底层存储的kv格式，直接写入db文件，也就是SSTable，更为高效。而oceanbase目前只实现了第一种逻辑导入，决赛的内容就是实现物理导入的功能，然后尽可能从算法逻辑、cpu、内存、磁盘io各方面进行性能优化，最后根据性能进行排名。 baseline实现baseline是一个单线程异步导入的实现，主要包括四个阶段： CSV文件解析：就是根据csv文件的分隔符一行一行读取数据文件，然后存入buffer中 ob内部数据结构转化：转为ob内部一种临时的数据格式DatmRow，比如对数据的列进行组，主键数据放在前面，用来方便后续的操作。 外部排序：获取转化后的DatumRow，进行外部排序，存储在临时文件 SSTable文件写入：读取外部排序的结果，写入SSTable 整体上是一个单线程异步io的框架。 优化点整体多线程框架首先是利用多线程的优势，充分压榨CPU的性能，整个执行过程分为两个阶段：一是外部排序阶段，二是数据持久化阶段。 整个流程如下： 首先对需要导入的数据文件分段； 多个线程分别对数据的不同段利用 ObLoadSequentialFileReader 并行读取到缓存 ObLoadDataBuffer ； 由于读取的文件格式是 CSV 格式，需要对读取的每一行字符串通过 ObLoadCSVPaser 进行解析； 对于解析完成的数据需要通过 ObLoadRowCaster 转化为 ob 的内部表示 ObLoadDatumRow （涉及数据类型转化等）； 然后根据主键的值，将读取的 ObLoadDatumRow 经过 ObLoadDispatcher 分发到对应的排序线程； 排序线程读取对应的 ObLoadDatumRow 然后通过 ObLoadExternalSort 进行外部排序； 各个 ObLoadSSTableWriter 分别读取对应排序完成的数据并完成写入，它们需要共用一个 ObSSTableIndexBuilder 来构建宏块。 多阶段线程池+dispatcher分发器+sort_queue排序队列（seda架构） 多阶段线程池将整个流程分成了三个线程池处理，使用ob提供的TaskQueue实现。 线程池一：负责(do_process)解析CSV文件和datumRow转化，然后将转化后的datum_row提交给dispatcher分发器 线程池二：负责从dispatcher中的获取datum_row，然后做外部排序，排序后的结果提交给sort_queue 线程池三：负责从sort_queue中获取排序后的结果，然后提交给sstable_writer写入底层存储 预处理优化csv文件读取。使用aio prefetch。每次处理数据之前，先发起prefetch请求 get_next_item: wait() + prefetch + process 异步读取可以表示为一个 pipeline()，它包含 prefetch() 以及 wait() 两个阶段。首先，在打开文件的时候发送一个 prefetch() 请求，然后后续每次调用 pipeline() 获取对应的数据，将会首先调用 wait() 等待上一次发送的异步读取请求完成，然后调用 prefetch() 发送下一次读取请求。这样可以很大程度地减少 I/O 等待的事件。这个过程中交替使用两个 file_io_handlers. 异步写入会首先等待下一次写入操作完成，然后发送本次写请求之后直接返回。 外排优化外排的基本思路是，将数据分块，每个块的数据load进内存，内存排序后写入临时文件，然后取每个临时文件的第一个未处理的元素建堆，做整体的排序。 根据dispatcher的数据分发，每个桶之间是有序的，然后每个线程处理一个桶，对桶内的数据进行排序，持久化。然后写sstable。sstable的写入接口可以传入index参数，这要保证每个写入线程的index和数据顺序一致就可以达到sstable写入并行化。排序后的结果会写入到sortbuffer中，写入线程池再并行写入。 外排分为 ObMemorySortRound 和 ObExternalSortRound，分别是内存排序以及外部排序。 待排序的数据会被不断放入 ObMemorySortRound 的缓存中，每次当待排序的数据到达一个阈值时，将会触发一次排序，然后将排序的结果写入临时文件，并返回一个对该临时文件进行读取的 reader。 由于我们需要排序的数据是一个 int64_t 类型和一个 int32_t 类型的组合，因此内存排序的算法使用基数排序来加快排序速度。 在临时文件的写入过程中，每当写入缓存中的数据到达一个阈值，将会首先对缓存中的数据进行压缩，然后写入压缩后的数据。由于比赛使用的磁盘的性能较差，因此对数据进行压缩，然后写入磁盘将很大程度上减少磁盘 I/O 的等待事件。 在所有数据都已经被放入到 ObLoadExternalSort 中之后，将会产生多个临时文件，每个临时文件内部有序，但彼此之间的顺序是不确定的。因此我们需要构建一个最小堆，每次读出一个临时文件头部的一条记录，然后将其放入最小堆中进行排序，然后输出一个最小堆的根节点。 对于临时文件的读取，由于前面进行了压缩的操作，因此读取之后需要进行解压。 ObLoadDispatcherdispatcher是为了桶排序设计 首先会对数据进行采样划分范围，然后根据采样结果划分成不同的外排桶确定划分点 当线程池1解析完datum_row提交给dispatcher后，dispatcher会通过二分查找该条数据所属的桶id，然后将数据交付给对应id的分发队列(push_item)。 桶之间的数据大小是有序的，桶内部的数据还需要经过外排才能有序。 我们通过类似于生产者消费者队列的方式，解析线程将会不断把数据写入这个队列，后续外排线程会不断从这个队列中读取数据。队列采用无锁的设计，通过写入指针与读出指针是否重合来判断队列为空或者满。 另外，解析线程写入数据的时候需要对数据进行深拷贝，深拷贝需要重新分配内存，我们将分配内存与深拷贝的过程分开。分配内存需要使用内存配分器，由于 ob 的内存分配器不是线程安全的，因此分配的过程需要加锁；深拷贝直接对各自分配的内存进行操作，因此这一个部分不需要加锁。从而降低了锁的粒度。最后，通过在分配内存的第一个位增加一个标识为，来表示深拷贝是否已经完成。 最后，实际上我们为每个桶分配了两个队列，当写线程写满一个队列时，将会切换到另外一个队列进行写入。读线程读完一个队列，且这个队列已经满时，就会将这个队列的所有内存一次性全部释放。减少了反复内存释放的开销。 sort优化std::sort 内存排序修改为基数排序 基数排序比基于排序的算法要快，但是需要额外的内存空间。内存换时间。 临时存储文件优化压缩临时文件，cpu换磁盘io换时间。重新设计了临时文件的存储格式，列存格式，提升压缩率。 内存复用减少内存使用，可以多开几个线程 写sstable优化ObLoadSSTableWriter最后第三个线程池从对应的桶中读取外排完成的数据，每个桶内的数据已经有序，并且桶之间也已经有序，然后分别进行写宏块的过程就行。 写宏块过程涉及数据的编码以及压缩的过程，同时还有对数据生成校验和，这个过程也将消耗大量 CPU 资源。 这个过程是读取一条记录，然后调用一次相应的写函数进行一次写入，实际上可以进行批量写入，读取多条然后进行写入，这样效率更高，更能够利用缓存。 测试环境8core + 16G + 50G的导入数据 结果比baseline提升了7倍左右 性能测量工具整体使用情况查看系统整体使用情况，各个进程的运行状态 1top CPU 使用情况查看 CPU 利用率 12top -p $(pidof ...)htop -p $(pidof ...) 磁盘使用情况查看磁盘读写延迟等情况 1iostat -x perfperf 的大致工作原理是每隔一个固定的时间，在 CPU 的每个核上产生一个中断，在中断发生时，查看当前处理的进程的 PID 和函数，然后再给对应的 PID 和函数附加一个统计值。这是一种采样的模式，我们预期，运行时间越多的函数，被时钟中断击中的机会越大，从而推测，那个函数的 CPU 占用率就越高。 perf 中常用的指令如下： list: 列出当前系统支持的所有性能事件。包括硬件性能事件、软件性能事件以及检查点； record: 收集采样信息，并将其记录在数据文件，随后可通过其它工具对数据文件进行分析； report: 读取 perf record 创建的数据文件，并给出热点分析结果； stat: 执行某个命令，收集特定进程的性能概况，包括 CPI、缓存未命中等； top: 类似于 linux 的 top 命令，对系统性能进行实时分析。 在虚拟机上是不支持硬件事件的，因此无法对硬件事件进行采样分析。 另外 perf record/stat/top 都可以通过 -p 和 -e 选项指定进程以及采样的事件。 分不清事件利用 cpu-clock/cpu-cycles/task-clock 之间的区别。 火焰图通过火焰图观察程序各个函数的开销：https://github.com/brendangregg/FlameGraph","link":"/2023/02/27/oceanbase-2022-%E6%AF%94%E8%B5%9B%E5%A4%8D%E7%9B%98/"},{"title":"ptmalloc分析","text":"内存分配器位于用户程序和内核之间，向操作系统申请内存，然后返回给用户程序。 分配器会先向系统批发一块大于用户请求的内存，然后用某种算法进行管理，零售给用户的每次内存请求。 内存管理数据结构主分配区和非主分配区 设置分配区是为了支持多线程 每个进程只有一个主分配区，可能有多个非主分配区。分配区的数量一旦增加，就不会再减少了。 主分配区和非主分配区通过环形链表进行管理。每个分配区使用互斥锁进行访问互斥。 内存分配ptmalloc响应用户内存分配要求的步骤为： 内存回收具体的释放方式是看chunk所处的位置和chunk的大小 获得分配区的锁","link":"/2021/10/08/ptmalloc%E5%88%86%E6%9E%90/"},{"title":"python学习","text":"资料来自网络。 杂记 pass语句 12def sample(n_samples): pass pass 占据一个位置，因为如果定义一个空函数程序会报错。 可以在模块划分是使用，先把要写的函数名写好，用pass占位，之后函数细节再慢慢补。 list()函数 将元组转换为列表，可以去重。一个坑是，转化后不会保持元组中的顺序。 字符串 操作符 描述 实例 + 字符串连接 &gt;&gt;&gt;a + b ‘HelloPython’ * 重复输出字符串 &gt;&gt;&gt;a * 2 ‘HelloHello’ [] 通过索引获取字符串中字符 &gt;&gt;&gt;a[1] ‘e’ [ : ] 截取字符串中的一部分 &gt;&gt;&gt;a[1:4] ‘ell’ in 成员运算符 - 如果字符串中包含给定的字符返回 True &gt;&gt;&gt;”H” in a True not in 成员运算符 - 如果字符串中不包含给定的字符返回 True &gt;&gt;&gt;”M” not in a True r/R 原始字符串 - 原始字符串：所有的字符串都是直接按照字面的意思来使用，没有转义特殊或不能打印的字符。 原始字符串除在字符串的第一个引号前加上字母”r”（可以大小写）以外，与普通字符串有着几乎完全相同的语法。 &gt;&gt;&gt;print r’\\n’ \\n &gt;&gt;&gt; print R’\\n’ \\n OS模块 os.sep:取代操作系统特定的路径分隔符 os.name:指示你正在使用的工作平台。比如对于Windows，它是’nt’，而对于Linux/Unix用户，它是’posix’。 os.getcwd:得到当前工作目录，即当前python脚本工作的目录路径。 os.getenv()和os.putenv:分别用来读取和设置环境变量 os.listdir():返回指定目录下的所有文件和目录名 os.remove(file):删除一个文件 os.stat（file）:获得文件属性 os.chmod(file):修改文件权限和时间戳 os.mkdir(name):创建目录 os.rmdir(name):删除目录 os.removedirs（r“c：\\python”）:删除多个目录 os.system():运行shell命令 os.exit():终止当前进程 os.linesep:给出当前平台的行终止符。例如，Windows使用’\\r\\n’，Linux使用’\\n’而Mac使用’\\r’ os.path.split():返回一个路径的目录名和文件名 os.path.isfile()和os.path.isdir()分别检验给出的路径是一个目录还是文件 os.path.existe():检验给出的路径是否真的存在 os.listdir(dirname):列出dirname下的目录和文件 os.getcwd():获得当前工作目录 os.curdir:返回当前目录（’.’） os.chdir(dirname):改变工作目录到dirname os.path.isdir(name):判断name是不是目录，不是目录就返回false os.path.isfile(name):判断name这个文件是否存在，不存在返回false os.path.exists(name):判断是否存在文件或目录name os.path.getsize(name):或得文件大小，如果name是目录返回0L os.path.abspath(name):获得绝对路径 os.path.isabs():判断是否为绝对路径 os.path.normpath(path):规范path字符串形式 os.path.split(name):分割文件名与目录（事实上，如果你完全使用目录，它也会将最后一个目录作为文件名而分离，同时它不会判断文件或目录是否存在） os.path.splitext():分离文件名和扩展名 os.path.join(path,name):连接目录与文件名或目录 os.path.basename(path):返回文件名 os.path.dirname(path):返回文件路径 文件操作os.mknod(\"text.txt\")：创建空文件fp = open(\"text.txt\",w):直接打开一个文件，如果文件不存在就创建文件 关于open的模式w 写方式a 追加模式打开（从EOF开始，必要时创建新文件）r+ 以读写模式打开w+ 以读写模式打开a+ 以读写模式打开rb 以二进制读模式打开wb 以二进制写模式打开 (参见 w )ab 以二进制追加模式打开 (参见 a )rb+ 以二进制读写模式打开 (参见 r+ )wb+ 以二进制读写模式打开 (参见 w+ )ab+ 以二进制读写模式打开 (参见 a+ ) 关于文件的函数1fp.read([size]) size为读取的长度，以byte为单位 1fp.readline([size]) 读一行，如果定义了size，有可能返回的只是一行的一部分 1fp.readlines([size]) 把文件每一行作为一个list的一个成员，并返回这个list。其实它的内部是通过循环调用readline()来实现的。如果提供size参数，size是表示读取内容的总长，也就是说可能只读到文件的一部分。 1fp.write(str) 把str写到文件中，write()并不会在str后加上一个换行符 1fp.writelines(seq) 把seq的内容全部写到文件中(多行一次性写入)。这个函数也只是忠实地写入，不会在每行后面加上任何东西。 1fp.close() 关闭文件。python会在一个文件不用后自动关闭文件，不过这一功能没有保证，最好还是养成自己关闭的习惯。 如果一个文件在关闭后还对其进行操作会产生ValueError 1fp.flush() 把缓冲区的内容写入硬盘 1fp.fileno() 返回一个长整型的”文件标签“ 1fp.isatty() 文件是否是一个终端设备文件（unix系统中的） 1fp.tell() 返回文件操作标记的当前位置，以文件的开头为原点 1fp.next() 返回下一行，并将文件操作标记位移到下一行。把一个file用于for … in file这样的语句时，就是调用next()函数来实现遍历的。 1fp.seek(offset[,whence]) 将文件打操作标记移到offset的位置。这个offset一般是相对于文件的开头来计算的，一般为正数。但如果提供了whence参数就不一定了，whence可以为0表示从头开始计算，1表示以当前位置为原点计算。2表示以文件末尾为原点进行计算。需要注意，如果文件以a或a+的模式打开，每次进行写操作时，文件操作标记会自动返回到文件末尾。 1fp.truncate([size]) 把文件裁成规定的大小，默认的是裁到当前文件操作标记的位置。如果size比文件的大小还要大，依据系统的不同可能是不改变文件，也可能是用0把文件补到相应的大小，也可能是以一些随机的内容加上去。 目录操作1os.mkdir(\"file\") 创建目录 复制文件: 1shutil.copyfile(\"oldfile\",\"newfile\") oldfile和newfile都只能是文件 1shutil.copy(\"oldfile\",\"newfile\") oldfile只能是文件夹，newfile可以是文件，也可以是目标目录 1shutil.copytree(\"olddir\",\"newdir\") 复制文件夹.olddir和newdir都只能是目录，且newdir必须不存在 1os.rename(\"oldname\",\"newname\") 重命名文件（目录）.文件或目录都是使用这条命令 1shutil.move(\"oldpos\",\"newpos\") 移动文件（目录） 1os.rmdir(\"dir\") 只能删除空目录 1shutil.rmtree(\"dir\") 空目录、有内容的目录都可以删 1os.chdir(\"path\") 转换目录，换路径 属性操作：hasattr()、getattr()、setattr()函数的使用 hasattr(object, name)判断一个对象里面是否有name属性或者name方法，返回BOOL值，有name特性返回True， 否则返回False。需要注意的是name要用括号括起来 1234567891011&gt;&gt;&gt; class test():... name=\"xiaohua\"... def run(self):... return \"HelloWord\"...&gt;&gt;&gt; t=test()&gt;&gt;&gt; hasattr(t, \"name\") #判断对象有name属性True&gt;&gt;&gt; hasattr(t, \"run\") #判断对象有run方法True&gt;&gt;&gt; getattr(object, name[,default]) 获取对象object的属性或者方法，如果存在打印出来，如果不存在，打印出默认值，默认值可选。需要注意的是，如果是返回的对象的方法，返回的是方法的内存地址，如果需要运行这个方法，可以在后面添加一对括号。 12345678910111213141516171819&gt;&gt;&gt; class test():... name=\"xiaohua\"... def run(self):... return \"HelloWord\"...&gt;&gt;&gt; t=test()&gt;&gt;&gt; getattr(t, \"name\") #获取name属性，存在就打印出来。'xiaohua'&gt;&gt;&gt; getattr(t, \"run\") #获取run方法，存在就打印出方法的内存地址。&lt;bound method test.run of &lt;__main__.test instance at 0x0269C878&gt;&gt;&gt;&gt;&gt; getattr(t, \"run\")() #获取run方法，后面加括号可以将这个方法运行。'HelloWord'&gt;&gt;&gt; getattr(t, \"age\") #获取一个不存在的属性。Traceback (most recent call last): File \"&lt;stdin&gt;\", line 1, in &lt;module&gt;AttributeError: test instance has no attribute 'age'&gt;&gt;&gt; getattr(t, \"age\",\"18\") #若属性不存在，返回一个默认值。'18'&gt;&gt;&gt; setattr(object, name, values) 给对象的属性赋值，若属性不存在，先创建再赋值。 123456789101112&gt;&gt;&gt; class test():... name=\"xiaohua\"... def run(self):... return \"HelloWord\"...&gt;&gt;&gt; t=test()&gt;&gt;&gt; hasattr(t, \"age\") #判断属性是否存在False&gt;&gt;&gt; setattr(t, \"age\", \"18\") #为属相赋值，并没有返回值&gt;&gt;&gt; hasattr(t, \"age\") #属性存在了True&gt;&gt;&gt; 一种综合的用法是：判断一个对象的属性是否存在，若不存在就添加该属性。 123456789101112131415&gt;&gt;&gt; class test():... name=\"xiaohua\"... def run(self):... return \"HelloWord\"...&gt;&gt;&gt; t=test()&gt;&gt;&gt; getattr(t, \"age\") #age属性不存在Traceback (most recent call last): File \"&lt;stdin&gt;\", line 1, in &lt;module&gt;AttributeError: test instance has no attribute 'age'&gt;&gt;&gt; getattr(t, \"age\", setattr(t, \"age\", \"18\")) #age属性不存在时，设置该属性'18'&gt;&gt;&gt; getattr(t, \"age\") #可检测设置成功'18'&gt;&gt;&gt;","link":"/2019/10/26/python%E5%AD%A6%E4%B9%A0/"},{"title":"rpc框架","text":"RPC一次RPC调用的流程： 客户端将调用的类名，方法名，参数名，参数值等信息，序列化成二进制流 客户端将二进制流，通过网络发送给服务端 服务端收到二进制流后，进行反序列化，得到要调用的类名，方法名，参数名和参数值，再通过动态代理的方式，调用对应的方法得到返回值 服务端将返回值序列化，再通过网络发送给客户端 客户端反序列化，得到调用结果。 RPC的组成网络通信框架、网络传输协议（序列化）、服务注册和服务发现 服务启动时，服务提供者向注册中心注册服务，暴露自己的地址和端口号。注册中心会更新服务列表。 消费者启动时向注册中心请求可用的服务地址，并在本地缓存一份。 为什么要有服务注册和服务发现：方便业务水平扩展，添加新的业务只需要向注册中心注册即可。 比如etcd就可以用于服务注册和服务发现。 RPC的性能RPC的性能取决与网络传输和反序列化 网络传输性能选择一个高性能的IO模型，及选择IO多路复用。 网络参数调优，比如开启tcp_nodelay，及关闭nagle算法。 序列化方法序列化要考虑性能，时间和空间开销 再考虑跨平台，跨语言。 对性能要求不高，就json 有性能要求就protobuf brpc文档阅读原子指令 c++ 11中引入了原子指令 原子指令的作用为了避免锁成为性能瓶颈。 为了wait-free和lock-free 原子指令 (x均为std::atomic) 作用 x.load() 返回x的值。 x.store(n) 把x设为n，什么都不返回。 x.exchange(n) 把x设为n，返回设定之前的值。 x.compare_exchange_strong(expected_ref, desired) 若x等于expected_ref，则设为desired，返回成功；否则把最新值写入expected_ref，返回失败。 x.compare_exchange_weak(expected_ref, desired) 相比compare_exchange_strong可能有spurious wakeup。 x.fetch_add(n), x.fetch_sub(n) 原子地做x += n, x-= n，返回修改之前的值。 原子指令存在的问题ABA问题一个线程把数据A变为了B，然后又重新变成了A。 解决方法：加入版本号 memory fence指令重排问题。 cacheline同步缓存一致性使得对cache中的更改必须同步到其他cache副本中，且这个过程是原子的，造成原子指令需要等待最新的cacheline。 解决方法： 尽量避免共享，MPMC该SPSC 使用tls，比如所有线程修改一个计数器，性能很慢，因为多核在同步cacheline，因此可以改用tls，需要时再合并 false sharing位于同一个cacheline中的变量可能自身不变，而其他变量频繁改变，同样要等待cacheline同步，因此频繁被多线程修改的变量应该放在独立的cacheline中。 雪崩雪崩指流量过大造成请求超时，且流量减少后仍无法恢复的现象。 雪崩式多服务才会发生的。比如请求访问A服务，A服务又访问了B服务，这时B被打满请求，正常情况下还是不会雪崩的，但是有例外： 流量放大，A可能对B发起了过于频繁的基于超时的重试，造成了恶性循环：B无法恢复-&gt;A超时-&gt;A继续重试-&gt;B无法恢复 解决：重试只在连接出错时发起 A或B没限制缓冲队列的长度 设置最大并发max_concurrency，防止请求积压。 最大qps * 非拥塞时的延时来评估最大并发（little’s law） 一致性哈希一些场景，我们希望同样的请求落到一台服务器上，这样可以利用缓存，不同的机器也不用缓存所有内容。hash可以满足这个要求：输入x总是会发送到第hash(x) % n的服务器。但是有个缺点，m增加时，之前的发送目的地会变，如果目的地时缓存服务，所有缓存就会失效。 一致性哈希解决了这个问题，新增加服务器时，发向旧节点的请求只会有一部分转向新节点。 参考文档： https://brpc.apache.org/zh/docs/","link":"/2022/01/21/rpc%E6%A1%86%E6%9E%B6/"},{"title":"rust学习笔记","text":"参考资料http://rustwiki.org/zh-CN/rust-by-example/https://github.com/rcore-os/rCore/wiki/os-tutorial-summer-of-code-2020#%E5%8F%82%E5%8A%A02020-os%E5%A4%8F%E4%BB%A4%E8%90%A5%E5%AD%A6%E7%94%9F%E7%9A%84blog","link":"/2021/11/08/rust%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"},{"title":"ss服务器搭建","text":"1https://github.com/ishen7/Blog/issues/2 12345wget --no-check-certificate -O shadowsocks-all.sh https://raw.githubusercontent.com/teddysun/shadowsocks_install/master/shadowsocks-all.shchmod +x shadowsocks-all.sh./shadowsocks-all.sh 2&gt;&amp;1 | tee shadowsocks-all.log 123456789101112131415161718192021222324252627启动脚本启动脚本后面的参数含义，从左至右依次为：启动，停止，重启，查看状态。Shadowsocks-Python 版：/etc/init.d/shadowsocks-python start | stop | restart | statusShadowsocksR 版：/etc/init.d/shadowsocks-r start | stop | restart | statusShadowsocks-Go 版：/etc/init.d/shadowsocks-go start | stop | restart | statusShadowsocks-libev 版：/etc/init.d/shadowsocks-libev start | stop | restart | status各版本默认配置文件Shadowsocks-Python 版：/etc/shadowsocks-python/config.jsonShadowsocksR 版：/etc/shadowsocks-r/config.jsonShadowsocks-Go 版：/etc/shadowsocks-go/config.jsonShadowsocks-libev 版：/etc/shadowsocks-libev/config.json","link":"/2020/06/09/ss%E6%9C%8D%E5%8A%A1%E5%99%A8%E6%90%AD%E5%BB%BA/"},{"title":"ubuntu配置","text":"wsl、ubuntu、vm配置相关 VMware tools安装左上虚拟机—&gt;设置—&gt;添加—&gt;CD/DVD—&gt;D:\\VMware\\VMware Workstation\\linux.iso 进入虚拟机后，将tools压缩文件复制进documents文件夹 12345678# 进入目录$ cd Documents# 解压$ tar -zxvf VMwareTools-10.2.5-8068393.tar.gz# 进入到解压之后的目录$ cd vmware-tools-distrib# 执行 .pl 文件$ ./vmware-install.pl 后面yes回车 挂载vmware共享文件夹默认是挂载到/mnt/hdfs下，想修改挂载到home/username下 bashrc和profileshell和bashshell是壳程序，能对操作系统和应用程序进行调用的接口程序。这是一个大类 bash是shell其中的一种，历史上还有sh、csh等等，现在linux默认使用的都是bash。 login shell 和 non-login shell登录式shell 是以tty中的login、ssh守护进程或其他类似方式派生出来。 非登录式式不需要重复登录的，比如登录Linux后，启动终端terminal,并没有要求重新输入账号和密码。 不同的shell类型读取的配置文件不一样login shell配置文件ctrl+h可显示隐藏.文件 按顺序读两个 先读/etc/profile，这个是系统的配置文件，对所有用户生效。一般不要改这个 然后读~/.profile 个人用户配置文件，其实个人配置文件可能会有三个.bash_profile、.bash_login、.profile，依次读这三个文件，直到一个存在停止读取，这样是为了应其他shell转换过来的用户的不同习惯。 ubuntu20.04下是.profile 注意13行，判断home目录下bashrc文件是否存在，存在则读入，也就是说login shell环境下，最终读入的配置文件是~/.bashrc，也就是说自己的偏好设置写入~/.bashrc即可。 non-login shell配置文件只会读取~/.bashrc这一个文件 相关命令source 读入环境配置文件，比如刚修改了.bashrc文件，source以下就可以生效了 终端shell配置环境配置 12sudo apt install tmuxsudo apt install zsh wsl设置走clash代理 1234export hostip=$(cat /etc/resolv.conf |grep -oP '(?&lt;=nameserver\\ ).*');export https_proxy=\"http://$hostip:7890\";export http_proxy=\"http://$hostip:7890\";export all_proxy=\"socks5://$hostip:7891\"; 安装ohmyzsh 1sh -c \"$(curl -fsSL https://raw.githubusercontent.com/ohmyzsh/ohmyzsh/master/tools/install.sh)\" 安装.tmux 1234cd ~git clone https://github.com/gpakosz/.tmux.gitln -s -f .tmux/.tmux.confcp .tmux/.tmux.conf.local . 安装三个zsh插件 1234567git clone https://github.com/zsh-users/zsh-syntax-highlighting.git ${ZSH_CUSTOM:-~/.oh-my-zsh/custom}/plugins/zsh-syntax-highlightinggit clone https://github.com/zsh-users/zsh-autosuggestions ${ZSH_CUSTOM:-~/.oh-my-zsh/custom}/plugins/zsh-autosuggestionsgit clone https://github.com/zsh-users/zsh-completions ${ZSH_CUSTOM:-${ZSH:-~/.oh-my-zsh}/custom}/plugins/zsh-completionssudo apt install autojump 然后在.zshrc中配置 123plugins=(.. zsh-syntax-highlighting zsh-autosuggestions autojump)[[ -s ~/.autojump/etc/profile.d/autojump.zsh ]] &amp;&amp; . ~/.autojump/etc/profile.d/autojump.zshautoload -U compinit &amp;&amp; compinit -u 默认shell修改 .tmux.conf.local中加入 1set -g default-shell /bin/zsh 注意要让tmux配置生效，直接在shell里source是不行的 要进入tmux，然后ctrl+b，输入:source ~/.tmux.conf 安装p10k主题 1git clone --depth=1 https://gitee.com/romkatv/powerlevel10k.git ${ZSH_CUSTOM:-$HOME/.oh-my-zsh/custom}/themes/powerlevel10k 然后修改.zshrc 12ZSH_THEME=\"powerlevel10k/powerlevel10k\"tmux #末尾添加，开启shell默认进入tmux 最后 source .zshrc，会自动配置p10k 中文linux命令手册pip install how conda防止conda污染原本的环境，一定一定一定要记住，不要把conda加到环境变量里。 如果之后我们要启动conda，我们可以用如下命令： source /bin/activate # 默认进入basesource /bin/activate # 进入指定环境 nvimhttps://space.bilibili.com/26319956/video?tid=0&amp;page=1&amp;keyword=&amp;order=pubdate","link":"/2020/12/28/ubuntu%E9%85%8D%E7%BD%AE/"},{"title":"vim使用","text":"vim学习 Vim基础编辑模式vim有五种操作模式 正常模式：在文件中移动光标 插入模式：插入文本 替换模式：替换文本 可视化模式（块模式）：选中文本 命令模式：执行命令 从正常模式进入其他模式： i 进入插入模式insert R（大写）替换模式 v进入可视模式view 或者ctrl+v :进入命令模式 esc键使用会很多，可以考虑键位重定义 缓存、标签页、窗口vim维护的一系列打开的文件，称为缓存 命令行 :q 退出 :w 保存（写） :wq 保存退出 :e {文件名} 打开要编辑的文件 :ls 显示打开的缓存 :help {标题} 打开帮助文档 移动 翻页：ctrl+u往上 ，ctrl+d往下 词移动：w下一个词，b上一个词，e下一个词尾 行：0移动到行初，^到行第一个非空格字符，$移动到行尾 屏幕：H屏幕首行、M屏幕中间、L屏幕底部 查找：f{字符} 搜索：/{正则表达式} 编辑 O在上面插入行、o在下面插入行 d{移动命令}，删除，dw删除词，d$删除到行尾 c{移动命令}，改变 x删除字符 s替换字符 可视化+操作 选中可以d或c u撤销 y复制 p粘贴 计数计数可以执行指定操作若干次，如： 3w 向前移动三个词 5j 向下移动5行 7dw 删除7个词 修饰语？？ 自定义vim来自：https://missing-semester-cn.github.io/2020/editors/ 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980\" Comments in Vimscript start with a `\"`.\" If you open this file in Vim, it'll be syntax highlighted for you.\" Vim is based on Vi. Setting `nocompatible` switches from the default\" Vi-compatibility mode and enables useful Vim functionality. This\" configuration option turns out not to be necessary for the file named\" '~/.vimrc', because Vim automatically enters nocompatible mode if that file\" is present. But we're including it here just in case this config file is\" loaded some other way (e.g. saved as `foo`, and then Vim started with\" `vim -u foo`).set nocompatible\" Turn on syntax highlighting.syntax on\" Disable the default Vim startup message.set shortmess+=I\" Show line numbers.set number\" This enables relative line numbering mode. With both number and\" relativenumber enabled, the current line shows the true line number, while\" all other lines (above and below) are numbered relative to the current line.\" This is useful because you can tell, at a glance, what count is needed to\" jump up or down to a particular line, by {count}k to go up or {count}j to go\" down.set relativenumber\" Always show the status line at the bottom, even if you only have one window open.set laststatus=2\" The backspace key has slightly unintuitive behavior by default. For example,\" by default, you can't backspace before the insertion point set with 'i'.\" This configuration makes backspace behave more reasonably, in that you can\" backspace over anything.set backspace=indent,eol,start\" By default, Vim doesn't let you hide a buffer (i.e. have a buffer that isn't\" shown in any window) that has unsaved changes. This is to prevent you from \"\" forgetting about unsaved changes and then quitting e.g. via `:qa!`. We find\" hidden buffers helpful enough to disable this protection. See `:help hidden`\" for more information on this.set hidden\" This setting makes search case-insensitive when all characters in the string\" being searched are lowercase. However, the search becomes case-sensitive if\" it contains any capital letters. This makes searching more convenient.set ignorecaseset smartcase\" Enable searching as you type, rather than waiting till you press enter.set incsearch\" Unbind some useless/annoying default key bindings.nmap Q &lt;Nop&gt; \" 'Q' in normal mode enters Ex mode. You almost never want this.\" Disable audible bell because it's annoying.set noerrorbells visualbell t_vb=\" Enable mouse support. You should avoid relying on this too much, but it can\" sometimes be convenient.set mouse+=a\" Try to prevent bad habits like using the arrow keys for movement. This is\" not the only possible bad habit. For example, holding down the h/j/k/l keys\" for movement, rather than using more efficient movement commands, is also a\" bad habit. The former is enforceable through a .vimrc, while we don't know\" how to prevent the latter.\" Do this in normal mode...nnoremap &lt;Left&gt; :echoe \"Use h\"&lt;CR&gt;nnoremap &lt;Right&gt; :echoe \"Use l\"&lt;CR&gt;nnoremap &lt;Up&gt; :echoe \"Use k\"&lt;CR&gt;nnoremap &lt;Down&gt; :echoe \"Use j\"&lt;CR&gt;\" ...and in insert modeinoremap &lt;Left&gt; &lt;ESC&gt;:echoe \"Use h\"&lt;CR&gt;inoremap &lt;Right&gt; &lt;ESC&gt;:echoe \"Use l\"&lt;CR&gt;inoremap &lt;Up&gt; &lt;ESC&gt;:echoe \"Use k\"&lt;CR&gt;inoremap &lt;Down&gt; &lt;ESC&gt;:echoe \"Use j\"&lt;CR&gt; 扩展vim只需要创建一个 ~/.vim/pack/vendor/start/ 的文件夹， 然后把插件放到这里 （比如通过 git clone）。 常用插件： ctrlp.vim: 模糊文件查找 ack.vim: 代码搜索 nerdtree: 文件浏览器 vim-easymotion: 魔术操作 打开目录树1234567#vim命令模式下:Explore #当前窗口下打开:Vexplore #竖直分割窗口打开:Sexplore #水平分割窗口打开#命令打开文件夹root@localhost：vim /etc 快捷键gg跳转到文件头 shift+g跳转到文件尾 :n跳转到第n行","link":"/2020/11/03/vim%E4%BD%BF%E7%94%A8/"},{"title":"vmware静态ip配置及网络排查","text":"虚拟机静态ip配置，网络排查 静态IP配置虚拟机设置为NAT模式 在宿主机下可查看虚拟网卡： 然后在虚拟机下配置静态ip： 用route -n查看路由表确定网关是172.16.134.2 网络故障排查先ping www.baidu.com 如果ping不通，试试ping百度的ip，如果ping通了就是dns的问题。 如果ip也ping不同，可能就是网关的问题，ping网关试试，再进行配置。 如果ping www.baidu.com是正常的，但是浏览器访问不正常，curl也不正常，检查是不是代理的配置问题。","link":"/2022/04/13/vmware%E9%9D%99%E6%80%81ip%E9%85%8D%E7%BD%AE%E5%8F%8A%E7%BD%91%E7%BB%9C%E6%8E%92%E6%9F%A5/"},{"title":"windows 控制台 代理配置","text":"123456789set http_proxy=http://127.0.0.1:1080set https_proxy=http://127.0.0.1:1080set http_proxy_user=userset http_proxy_pass=passset https_proxy_user=userset https_proxy_pass=pass","link":"/2020/04/15/windows-%E6%8E%A7%E5%88%B6%E5%8F%B0-%E4%BB%A3%E7%90%86%E9%85%8D%E7%BD%AE/"},{"title":"windows下win+q添加可搜索应用","text":"解决部分应用无法用win+q搜索到问题 将可执行文件的快捷方式移动到该目录下： C:\\ProgramData\\Microsoft\\Windows\\Start Menu\\Programs","link":"/2021/04/29/windows%E4%B8%8Bwin-q%E6%B7%BB%E5%8A%A0%E5%8F%AF%E6%90%9C%E7%B4%A2%E5%BA%94%E7%94%A8/"},{"title":"中断 异常 陷阱","text":"https://www.crifan.com/files/doc/docbook/interrupt_related/release/htmls/index.html 中断interrupt单说中断一般指的是硬件中断，外部设备发生了某些事件，通知CPU，然后CPU跳转到相应的ISR（中断处理程序 interrupt service routine），执行完再回来执行下一条指令。 为什么要有中断针对外设IO的场景： 因为外设IO要远慢与CPU的指令执行速度，CPU指令执行的速度是ns级别的，而外设IO的速度是ms级别的。 假如没有中断要操作外设，CPU一步步按指令顺序执行，CPU给外设发送一个指令，外设开始执行相应的动作，然后CPU开始读取外设的状态，因为CPU指令的执行很快，结果就是CPU执行了多次读取结果的指令（轮询），得到的结果都是外设IO未完成，浪费了CPU时间。 而中断是CPU该干嘛干嘛，不用轮询，等外设的活干完了，再自动发送一个中断给CPU。 轮询poll的含义是：循环等待事件完成 异常 exception异常时当前指令做出了非法操作，不如除0，内存的非法访问 陷阱 trap陷阱又叫软件中断，软件的含义是这种中断是由指令完成的，在x86系统中，就是对应的int指令。CPU执行了int指令，然后跳转到对应的软中断处理函数中，陷阱是软件本身的，是程序员故意实现的，常用用于调试。 广义的中断广义的中断指种植打断正在执行的CPU，所以前面介绍的中断、异常、陷阱都可以叫中断。 Linux的中断Linux将中断的处理过程分成了连个阶段：上半部和下半部 上半部就是硬中断，直接处理硬件请求。快速执行 下半部内核触发，软中断，以内核线程方式运行。 上半部会打断CPU的执行，立即处理中断处理程序。下半部每个CPU都对应一个软中断内核线程，比如叫ksoftirqd/0，0就是CPU编号。 /proc/softirqs 提供了软中断的运行情况； /proc/interrupts 提供了硬中断的运行情况。 12345678910111213$ cat /proc/softirqs CPU0 CPU1 HI: 0 0 TIMER: 811613 1972736 NET_TX: 49 7 NET_RX: 1136736 1506885 BLOCK: 0 0 IRQ_POLL: 0 0 TASKLET: 304787 3691 SCHED: 689718 1897539 HRTIMER: 0 0 RCU: 1330771 1354737 #RCU锁（read copy update），内核常用的锁之一 参考https://www.modb.pro/db/101480","link":"/2022/02/18/%E4%B8%AD%E6%96%AD-%E5%BC%82%E5%B8%B8-%E9%99%B7%E9%98%B1/"},{"title":"信号量、条件变量、管程","text":"条件变量1234567//基本用法#include &lt;condition_variable&gt;std::condition_variable cond_;std::unique_lock &lt;std::mutex&gt; lock(mutex_);cond_.wait(lock);cond_.notify_all();cond_.notify_one(); 管程 管程用来管理类额成员变量和成员方法，让这个类是线程安全的。下面以阻塞队列的实现为例 管程解决了并发编程中的俩个核心问题：互斥，同步 互斥：同一时刻只允许一个线程访问共享资源 同步：线程之间的通信，协作 管程如何解决互斥问题：mutex，将共享变量和对共享变量的操作同一封装了起来，互斥锁就是管程模型的入口 管程如何解决同步问题：引入条件变量 阻塞队列首先是一个队列，有插入和删除操作。当队列中没有元素时，弹出操作将会被阻塞，直到有元素被插入时才会被唤醒。队列满时，队列的插入操作被阻塞，直到有元素被弹出后才会被唤醒。 阻塞队列的应用：在线程池实现中，使用阻塞队列来保存任务，直到线程空闲之后从阻塞队列弹出任务来执行。一旦队列为空，线程就会被阻塞，直到有新任务被插入为止。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384template &lt;typename T, typename D = std::deque&lt;T&gt; &gt;class ThreadQueue { public: typedef D queue_type; bool pop_front(T&amp; t, size_t millsecond); void push_back(T&amp; t); void push_front(T&amp; t); void swap(queue_type&amp; q); void clear(); bool empty(); auto begin(); auto end(); protected: queue_type queue_; size_t size_; private: std::mutex mutex_; std::condition_variable cond_;};template &lt;typename T, typename D&gt;bool ThreadQueue&lt;T, D&gt;::pop_front(T&amp; t, size_t millsecond) { std::unique_lock&lt;std::mutex&gt; lock(mutex_); while (queue_.empty()) { //为什么if不行？ cond_.wait(lock); } assert(!queue_.empty()); t = queue_.front(); queue_.pop_front(); size_--; return true;}template &lt;typename T, typename D&gt;void ThreadQueue&lt;T, D&gt;::push_back(T&amp; t) { std::unique_lock&lt;std::mutex&gt; lock(mutex_); queue_.push_back(t); size_++; cond_.notify_one();}template &lt;typename T, typename D&gt;void ThreadQueue&lt;T, D&gt;::push_front(T&amp; t) { std::unique_lock&lt;std::mutex&gt; lock(mutex_); queue_.push_front(t); size_++; cond_.notify_one();}template &lt;typename T, typename D&gt;void ThreadQueue&lt;T, D&gt;::clear() { std::unique_lock&lt;std::mutex&gt; lock(mutex_); queue_.clear(); size_ = 0;}template &lt;typename T, typename D&gt;bool ThreadQueue&lt;T, D&gt;::empty() { return queue_.empty();}template &lt;typename T, typename D&gt;auto ThreadQueue&lt;T, D&gt;::begin() { std::unique_lock&lt;std::mutex&gt; lock(mutex_); return queue_.begin();}template &lt;typename T, typename D&gt;auto ThreadQueue&lt;T, D&gt;::end() { std::unique_lock&lt;std::mutex&gt; lock(mutex_); return queue_.end();}template &lt;typename T, typename D&gt;void ThreadQueue&lt;T, D&gt;::swap(D&amp; q) { std::unique_lock&lt;std::mutex&gt; lock(mutex_); // if(queue_.empty()) { // cond_.wait(lock); // } q.swap(queue_); //交换两个队列的 内容} 参考 管程：https://zhuanlan.zhihu.com/p/99054391","link":"/2021/11/26/%E4%BF%A1%E5%8F%B7%E9%87%8F%E3%80%81%E6%9D%A1%E4%BB%B6%E5%8F%98%E9%87%8F%E3%80%81%E7%AE%A1%E7%A8%8B/"},{"title":"信号量题目","text":"进程管理——同步作业 图书馆有N个座位，一张登记表，要求(1)阅读者进入时登记，取得座位号；(2)出来时注销。请用P、V操作描述一个读者的使用过程。 123456789101112131415161718192021222324252627// 进入时为生产者 出来时为消费者semaphore s = 0; // 已经登记量semaphore empty = N; // 空余量semaphore mutex = 1; // 互斥信号量void login(){ while (true) { P(empty); // 空余量减少1 P(mutex); // 互斥 // 登记 V(mutex); V(s); // 已登记量增加1 }}void logout(){ while (true) { P(s); // 已登记量减少1 P(mutex); // 互斥，（这里互斥的原因是不可能为多个人注销，或者在注销的时候为另一个人登记，因此申请互斥信号量） // 注销 V(mutex); V(empty); // 空余量增加1 }} 请用P、V操作描述下列过程： 1234567891011121314151617181920212223// 假设一开始车停下，门开启semaphore stop = 1; // 停车信号量semaphore closedoor = 0; // 关门信号量void drive() //司机{ while (true) { P(closedoor); // 检测到门已关 // 启动, 正常运行 V(stop); // 停下 }}void seller() // 售票员{ while (true) { P(stop); // 检测到车已停 // 售票 V(closedoor); // 关门 }} 4个并发执行的进程P1、P2、P3和P4合作解决数据计算问题：Y(i)=X(i)2+X(i)3 (1)P1不断产生随机数并放入的缓冲区A中； (2)P2、P3分别读取缓冲区A中的数据并计算其平方值、立方值，然后分别放入缓冲区B、C中； (3)P4读取缓冲区B、C中的数据，将其相加，并输出； (4)缓冲区A、B、C的容量为1。 用P，V操作实现其同步过程。12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849semaphore A = 1; // 缓冲区Asemaphore B = 0; // 缓冲区Bsemaphore C = 0; // 缓冲区Csemaphore s12 = 0; // P1与P2同步semaphore s13 = 0; // P1与P3同步semaphore s24 = 0; // P2与P4同步semaphore s34 = 0; // P3与P4同步void P1(){ while (true) { P(A); // 上一次计算是否完毕 // 随机产生数据放入缓冲区A V(s12); V(s13); // 通知P2和P3 V(B); V(C); }}void P2(){ while (true) { P(s12); // 收到P1的信号 P(B); // 申请缓冲区B的资源 // 读取缓冲区A中存放数据计算其平方值 写入缓冲区B V(s24); // 通知P4 }}void P3(){ while (true) { P(s13); // 收到P1的信号 P(C); // 申请缓冲区C的资源 // 读取缓冲区A中存放数据计算其立方值 写入缓冲区C V(s34); // 通知P4 }}void P4(){ while (true) { P(s24); // 收到P2的通知 P(s34); // 收到P3的通知 // 将缓冲区B和C中的数值相加并输出 V(B); // 缓冲区B释放 V(C); // 缓冲区C释放 V(A); // 本次计算完毕 可以写入新的i }} 桌上有一空盘，最多允许存放一只水果。爸爸可向盘中放一个苹果或放一个桔子；儿子专等吃盘中的桔子，女儿专等吃苹果。用P、V操作实现爸爸、儿子、女儿三个并发进程的同步。 12345678910111213141516171819202122232425262728293031323334semaphore plate = 1; // 盘子是否可以放入水果semaphore orange = 0; // 盘子中的桔子数 semaphore apple = 0; // 盘子中的苹果数void dad(){ while (true) { result = prepare_fruit(); // 准备水果 result为水果类型 P(plate); // 放入水果 // 将水果放入盘子 if (result == apple) V(apple); // 苹果数+1 else V(orange); // 桔子数+1 }}void daughter(){ while (true) { P(apple); // 盘中是否有苹果 // 拿走苹果 V(plate); // 盘空 }}void son(){ while (true) { P(orange); // 盘中是否有桔子 // 拿走桔子 V(plate); // 盘空 }} 用P、V原语实现东西向单行道上车辆的正确行驶，要求：(1)当有车自东向西方向（或自西向东方向）行驶，另一方向上的车辆须等待；(2)同一方向上的车可以连续通过；(3)当某一方向上已经没有车辆在单行道上行驶时，另一方向上的车辆即可以进入单行道。 12345678910111213141516171819202122232425262728293031323334semaphore mutex_dir = 1; // 互斥东西方向semaphore mutex_eastc = 1;semaphore mutex_westc = 1;int east_count = 0, west_count = 0;void east_to_west(){ while (true) { P(mutex_eastc); east_count++; if (east_count == 1) P(mutex_dir); // 当前方向是否可以通过 V(mutex_eastc); // 从东向西通过 P(mutex_eastc); east_count--; if (east_count == 0) V(mutex_dir); // 单行道上已空 释放方向 V(mutex_eastc); }}void west_to_east(){ while (true) { P(mutex_westc); west_count++; if (west_count == 1) P(mutex_dir); // 当前方向是否可以通过 V(mutex_westc); // 从西向东通过 P(mutex_westc); west_count--; if (west_count == 0) V(mutex_dir); // 单行道上已空 释放方向 V(mutex_westc); }} 某寺庙，有小、老和尚若干，有一水缸，由小和尚提入水缸供老和尚饮用。水缸可容10桶水，水取自同一井中。水井径窄，每次只能容一个水桶取水，水桶总数为3个。每次入、取缸水仅为1桶，且不可同时进行。试给出有关老和尚从缸取水和小和尚打水、入水的算法描述。 12345678910111213141516171819202122232425262728293031semaphore sj = 1; // 水井semaphore sg = 1; // 水缸semaphore st = 3; // 可用水桶数semaphore water = 0; // 已入水数semaphore empty_w = 10; // 可入水数void drwater() // 小和尚打水入水{ P(empty_w); // 是否有空位可以入水 P(sj); // 水井是否可用 P(st); // 是否有水桶 // 打水 V(sj); // 释放水井 P(sg); // 水缸是否可用 // 入水 V(st); // 可用水桶数增加1 V(sg); // 释放水缸 V(water); // 已入水数增加1}void qwater() // 老和尚取水{ P(water); // 是否有水可以取 P(sg); // 水缸是否可用 P(st); // 是否有水桶 // 取水 V(sg); // 释放水缸 V(st); // 可用水桶数增加1 V(empty_w); // 可入水数增加1}","link":"/2019/11/12/%E4%BF%A1%E5%8F%B7%E9%87%8F%E9%A2%98%E7%9B%AE/"},{"title":"公式无法渲染问题","text":"错误情况部分公式无法渲染，显示为源码 环境 解决修改marked\\lib\\marked.js以下语句： 12escape: /^\\\\([!\"#$%&amp;'()*+,\\-./:;&lt;=&gt;?@\\[\\]^_`|~])/,em:/^\\*((?:\\*\\*|[\\s\\S])+?)\\*(?!\\*)/,","link":"/2019/08/10/%E5%85%AC%E5%BC%8F%E6%97%A0%E6%B3%95%E6%B8%B2%E6%9F%93%E9%97%AE%E9%A2%98/"},{"title":"内核开发总结","text":"https://space.bilibili.com/646178510 学习记录 开发基础7、linux内核编译过程顶层根目录有个顶层makefile，各级源代码目录还有一个makefile，顶层makefile去include各子目录的makefile文件，从而把内核源码囊括起来。 9、内核空间和用户空间以及数据拷贝 copy_from_user(addr_kernel, addr_user, len) copy_to_user(addr_user, addr_kernel, len) 为什么不允许内核直接访问用户空间的数据呢？防止缺页？安全性？ 10、x86页式内存管理和页表映射 逻辑地址-&gt;线性地址-&gt;物理地址 分为两个阶段：段页式转换-&gt;页表映射，只是linux内核里段基址是0，也就是逻辑地址等于线性地址。 页表映射以二级页表转换为例。 （物理块就是物理页） cr3-&gt;页目录表-&gt;二级页表-&gt;物理页地址-&gt;加上偏移就是物理地址。 11、内核同步场景比如设备驱动的open，有的设备可以被多个进程访问，比如磁盘、网卡。 一个有问题的例子： 出现问题： 这个例子中，xxx_count就是一个共享资源，并发执行单元对共享资源的访问会引发竞态问题。需要使用内核同步方法来保护临界区。 12、semaphore使用 1234struct semaphore sema;sema_init(&amp;sema, 1);down(&amp;sema);up(&amp;sema); 13、semaphore内核实现本质上是基于进程调度器实现的，UP和SMP实现无差异 结构体 list_head是双向链表 初始化 初始化一个结构体，然后赋值。 down获取一个锁 如果获取不到，进入down 就是第二个进程进来后，会创建一个waiter，加入到sem的wait_list里。然后进入while 1,把当前这个进程设置为休眠，然后释放down函数里申请的自旋锁，让这个把当前的进程调度出去，等被唤醒后，看下waiter.up，为true就返回。 传入的state是进程的状态，task_uninterruptable，不可运行且不能被打断的。 updown里检查waiter.up，就是在up里设置的。跟down是对应的 理一下，就是当资源不够，当前进程会休眠，休眠之前，这个task_struct会加入到这个sem的wait_list里面。 up时候，如果wait_list有进程，就把它拿出来，然后wake_up。 14、内核原子变量为啥要有原子变量，比如刚刚的例子，只是要对一个open_count进行保护，使用信号量的开销太大了，信号量会让进程调度。也就是atomic适合针对int变量进行同步的场景。 atomic_dec_and_test就是原子减一 ,结果为0 返回 true，atomic_inc就是原子加一，不会被调度，不会被cpu打断。 15、atomic内核实现实现跟体系结构相关。视频中讲的是arm下的，这里看x86的 16、spinlock使用信号量不支持进程和中断之间的同步，但是spinlock可以。中断上下文不允许睡眠，适合spinlock。 死等是用特殊的汇编指令实现的。 1234spinlock_t count_lock;spin_lock_init(&amp;count_lock);spin_lock(&amp;count_lock);spin_unlock(&amp;count_lock); 使用自旋锁的临界区代码尽可能少，不能调用睡眠或可能引起睡眠的函数。 17、spinlock内核实现（UP）实现也跟体系结构相关。 结构体封装了三层：spinlock，raw_spinlock，arch_spinlock_t（具体实现），多一层封装多一层灵活性。 使用owner和next来保证先到先唤醒。 初始化就是对raw_lock进行初始化，owner和next都等于0 读内核时候，check函数可以不仔细看，就是辅助函数 spin_lock _raw_spin_lock的实现有两种，分别对应UP和SMP的。 up的实现比较简单，关闭抢占，__LOCK就什么都没做了 在include/linux下 18、spinlock内核实现（SMP）接上，区别在_raw_spin_lock的实现，在kernel/locking下 多核也是先关抢占，然后要同步其他cpu，最后是体系结构相关的代码。 19、spinlock、rw spinlock、seqlock、rcu机制比较 lock更新后，引起其他cpu核的cache失效。性能满足不了需求，就提出了RCU机制。 22、页框和伙伴算法和slab 23、内存管理和分配方法 kmem_cache_alloc会调用slab_aclloc。flags是运行睡眠还是不允许睡眠。 给硬件分配的一般要求连续，用kmalloc 24、kmalloc实现kmalloc-&gt;__kmalloc-&gt; __do_kmalloc 主体实现kmalloc依赖slab分配器实现，slab又依赖伙伴系统实现。 根据size找到对应的高速缓存，然后调用slab_alloc找到一个空闲的object，然后把它的指针返回。 kasan_kmalloc是内存调试用的，先忽略。 根据size获取kmem_cache(高速缓存)kmem_cache 换算成一个index，从kmalloc_caches数组里拿。 25、高速缓存和size的对应关系过 26、虚拟地址空间管理不同的区域用不同的vma管理 27、虚拟地址空间管理的内核结构 对于线程来说，多个线程共享一个地址空间，也就是多个 task_struct 使用同一个 mm_struct 结构，所以执行 fork 时只需要把父进程的 mm 赋值给子进程的 mm; 28、mmap实现pass 29、用户栈和内核栈 用户栈是vma来管理，另一个作为task_struct的一部分。 我记得内核栈是8k。 内核会有其他方式来保证内核栈不溢出。 thread_info是体系结构相关的，可以看下arm的： 30、进程上下文和中断上下文preempt_count这个变量保存在thread_info里面 32、软中断特点以及softirq注册和触发 哪个cpu触发软中断，哪个cpu执行这个软中断处理函数 每个cpu都有一个__softirq_pending变量，所以只能看到本地cpu软中断的状态。 33、do_softirq()的执行时机ksoftirqd线程每个cpu都会创建这么一个线程，ksoftird/%u 这里的代码解释下，local_irq_disable()关闭中断是为了保护数据，__do_softirq()里又把硬中断打开了，所以说在软中断的执行过程中是打开cpu中断的。 硬件中断返回irq_exit() 如果本地cpu上有待处理的软中断，只有不处于中断上下文的时就会调用__do_softirq()。 为什么需要判断 !in_inerrupt() ？那是因为在某些时候，软中断被硬件中断抢占执行，硬中断退出时，尽管退出了硬中断上下文，但是仍处于软中断上下文中，这时候不应该嵌套执行软中断，因为硬中断函数返回之后会继续执行被打断的软中断。 12345678910111213static inline void invoke_softirq(void){ if (ksoftirqd_running(local_softirq_pending())) return; if (!force_irqthreads) { ... __do_softirq();#endif } else { wakeup_softirqd(); }} 直接调用例如在网络子系统，对实时性要求比较高，所以会直接调用do_softirq进行处理。 参考https://zhuanlan.zhihu.com/p/363225717 34、软中断的执行过程 得到已经触发的软中断flag，然后一个个调它的软中断处理函数。 不同软中断优先级如何体现 ksoftirqd优先级高于普通进程 硬件中断返回时候，就会调用： 这里几乎没什么条件，就会调用invoke_softirq 35、free memory和avaliable memoryfree memory是完全没有被用到的内存，而Linux认为内存不用也是浪费，因此会尽量“多”地把内存用来做各种缓存，提高系统的性能。而available memory是应用程序认为可用内存数量，它是free memory，buffer和cache的总和。 追踪调试基础1、linux追踪技术三大件 前端工具：应用层工具。 tracing framework：把追踪的事件返回到用户空间 事件源：比如printk就是一种事件源 2、事件源","link":"/2023/03/20/%E5%86%85%E6%A0%B8%E5%BC%80%E5%8F%91%E6%80%BB%E7%BB%93/"},{"title":"决策树ID3算法Python实现","text":"参考西瓜书第4章编写，并用graphviz实现可视化。 代码123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146import numpy as npfrom collections import Counterfrom graphviz import Digraphimport osos.environ[\"PATH\"] += os.pathsep + 'D:/Graphviz2.39/bin'def loadData(filename): with open(filename) as f: line = f.readline() res = [] while line: c = line.split() content = [float(x) for x in c] res.append(content) line = f.readline() #print(res) return resdef getEnt(data): num = len(data) labelCount = {} for feature in data: label = feature[-1] if label not in labelCount.keys(): labelCount[label] = 0 labelCount[label] += 1 Ent = 0 for key, p in labelCount.items(): p = p / num Ent -= p*np.log2(p) return Entdef splitDate(data,feature,point):#整体数据集、特征编号、分割点 data1 = [x for x in data if x[feature]&lt;point] data2 = [x for x in data if x[feature]&gt;point] return data1,data2def chooseBF(data):#选择最佳的划分属性 featureValue = [] num = len(data) Ent = getEnt(data) numFeature = len(data[0])-1#获取属性的个数 maxGain = float('-inf') for i in range(numFeature):#对每个属性，统计出现的值 featureList = [feature[i] for feature in data]#统计该属性出现的可能值 featureList = sorted(list(set(featureList))) for j in range(len(featureList)-1): data1,data2 = splitDate(data,i,(featureList[j]+featureList[j+1])/2) Ent1 = getEnt(data1) Ent2 = getEnt(data2) Gain = Ent - (len(data1)/num)*Ent1 - (len(data2)/num)*Ent2 if Gain&gt;maxGain: feature = i point = (featureList[j]+featureList[j+1])/2 dataLeft = data1 dataRight = data2 maxGain = Gain return feature,point,dataLeft,dataRight#返回分割的属性和分裂点def creatTree(data): node = {} label = [sample[-1] for sample in data] if len(set(label))==1: node['label'] = label[0] return node unique = [] for i in range(len(data[0])-1): unique.append(len(set([sample[i] for sample in data]))) tot = sum([1 for x in unique if (x == 1)]) dataCount = Counter([sample[-1] for sample in data]) if (tot == 4): node['label'] = list(dataCount.most_common(1)[0])[0] return node featureIndex,point,dataLeft,dataRight = chooseBF(data)#分裂属性编号，分裂值 node['value'] = point node['feature'] = featureIndex node['leftChild'] = creatTree(dataLeft) node['rightChild'] = creatTree(dataRight) return nodedef predict(sample,node): if 'feature' in node: if sample[node['feature']]&gt;node['value']: label = predict(sample,node['rightChild']) else: label = predict(sample,node['leftChild']) else: return node['label'] return labeldef test(data,tree): num = len(data) ans = [] for i in range(num): ans.append(predict(data[i],tree)) return ansdef plot_model(tree, name): g = Digraph(\"G\", filename=name, format='png', strict=False) g.node(\"0\", str(tree['feature']))#根节点的feature _sub_plot(g, tree, \"0\") return g g.view()root = \"0\"def _sub_plot(g, tree, inc): global root ts = tree for i in ts.keys():#i是字典的key 根节点的key if i == 'leftChild': # 上次的节点指向刚刚画的节点 root = str(int(root) + 1) if 'feature' in tree[i]: g.node(root,str(tree[i]['feature']))#新生成的子节点root else: g.node(root, str(tree[i]['label'])) # 新生成的子节点root g.edge(inc, root, '&lt;' + str(tree['value'])) _sub_plot(g, tree[i], root) if i == 'rightChild': root = str(int(root) + 1) if 'feature' in tree[i]: g.node(root, str(tree[i]['feature'])) # 新生成的子节点root else: g.node(root, str(tree[i]['label'])) # 新生成的子节点root g.edge(inc, root, '&gt;' + str(tree['value'])) _sub_plot(g, tree[i], root) if i == 'label': g.node(root, 'label:' + str(tree['label'])) # 画出儿子节点if __name__ == '__main__': trainData = loadData('traindata.txt') testData = loadData('testdata.txt') tree = creatTree(trainData) ans = test(testData,tree) trueLabel = [sample[-1] for sample in testData] rightCount = 0 for i in range(len(ans)): if ans[i]==trueLabel[i]: rightCount = rightCount + 1 g = plot_model(tree, \"决策树\") g.view() print(rightCount/len(ans)) 结果及可视化acc = 96% 实验数据每行一个样本，前三列为属性，最后一列为label 训练集1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374755 3 1.6 0.2 15 3.4 1.6 0.4 15.2 3.5 1.5 0.2 15.2 3.4 1.4 0.2 14.7 3.2 1.6 0.2 14.8 3.1 1.6 0.2 15.4 3.4 1.5 0.4 15.2 4.1 1.5 0.1 15.5 4.2 1.4 0.2 14.9 3.1 1.5 0.2 15 3.2 1.2 0.2 15.5 3.5 1.3 0.2 14.9 3.6 1.4 0.1 14.4 3 1.3 0.2 15.1 3.4 1.5 0.2 15 3.5 1.3 0.3 14.5 2.3 1.3 0.3 14.4 3.2 1.3 0.2 15 3.5 1.6 0.6 15.1 3.8 1.9 0.4 14.8 3 1.4 0.3 15.1 3.8 1.6 0.2 14.6 3.2 1.4 0.2 15.3 3.7 1.5 0.2 15 3.3 1.4 0.2 16.6 3 4.4 1.4 26.8 2.8 4.8 1.4 26.7 3 5 1.7 26 2.9 4.5 1.5 25.7 2.6 3.5 1 25.5 2.4 3.8 1.1 25.5 2.4 3.7 1 25.8 2.7 3.9 1.2 26 2.7 5.1 1.6 25.4 3 4.5 1.5 26 3.4 4.5 1.6 26.7 3.1 4.7 1.5 26.3 2.3 4.4 1.3 25.6 3 4.1 1.3 25.5 2.5 4 1.3 25.5 2.6 4.4 1.2 26.1 3 4.6 1.4 25.8 2.6 4 1.2 25 2.3 3.3 1 25.6 2.7 4.2 1.3 25.7 3 4.2 1.2 25.7 2.9 4.2 1.3 26.2 2.9 4.3 1.3 25.1 2.5 3 1.1 25.7 2.8 4.1 1.3 27.2 3.2 6 1.8 36.2 2.8 4.8 1.8 36.1 3 4.9 1.8 36.4 2.8 5.6 2.1 37.2 3 5.8 1.6 37.4 2.8 6.1 1.9 37.9 3.8 6.4 2 36.4 2.8 5.6 2.2 36.3 2.8 5.1 1.5 36.1 2.6 5.6 1.4 37.7 3 6.1 2.3 36.3 3.4 5.6 2.4 36.4 3.1 5.5 1.8 36 3 4.8 1.8 36.9 3.1 5.4 2.1 36.7 3.1 5.6 2.4 36.9 3.1 5.1 2.3 35.8 2.7 5.1 1.9 36.8 3.2 5.9 2.3 36.7 3.3 5.7 2.5 36.7 3 5.2 2.3 36.3 2.5 5 1.9 36.5 3 5.2 2 36.2 3.4 5.4 2.3 35.9 3 5.1 1.8 3 测试集1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374755.1 3.5 1.4 0.2 14.9 3 1.4 0.2 14.7 3.2 1.3 0.2 14.6 3.1 1.5 0.2 15 3.6 1.4 0.2 15.4 3.9 1.7 0.4 14.6 3.4 1.4 0.3 15 3.4 1.5 0.2 14.4 2.9 1.4 0.2 14.9 3.1 1.5 0.1 15.4 3.7 1.5 0.2 14.8 3.4 1.6 0.2 14.8 3 1.4 0.1 14.3 3 1.1 0.1 15.8 4 1.2 0.2 15.7 4.4 1.5 0.4 15.4 3.9 1.3 0.4 15.1 3.5 1.4 0.3 15.7 3.8 1.7 0.3 15.1 3.8 1.5 0.3 15.4 3.4 1.7 0.2 15.1 3.7 1.5 0.4 14.6 3.6 1 0.2 15.1 3.3 1.7 0.5 14.8 3.4 1.9 0.2 17 3.2 4.7 1.4 26.4 3.2 4.5 1.5 26.9 3.1 4.9 1.5 25.5 2.3 4 1.3 26.5 2.8 4.6 1.5 25.7 2.8 4.5 1.3 26.3 3.3 4.7 1.6 24.9 2.4 3.3 1 26.6 2.9 4.6 1.3 25.2 2.7 3.9 1.4 25 2 3.5 1 25.9 3 4.2 1.5 26 2.2 4 1 26.1 2.9 4.7 1.4 25.6 2.9 3.6 1.3 26.7 3.1 4.4 1.4 25.6 3 4.5 1.5 25.8 2.7 4.1 1 26.2 2.2 4.5 1.5 25.6 2.5 3.9 1.1 25.9 3.2 4.8 1.8 26.1 2.8 4 1.3 26.3 2.5 4.9 1.5 26.1 2.8 4.7 1.2 26.4 2.9 4.3 1.3 26.3 3.3 6 2.5 35.8 2.7 5.1 1.9 37.1 3 5.9 2.1 36.3 2.9 5.6 1.8 36.5 3 5.8 2.2 37.6 3 6.6 2.1 34.9 2.5 4.5 1.7 37.3 2.9 6.3 1.8 36.7 2.5 5.8 1.8 37.2 3.6 6.1 2.5 36.5 3.2 5.1 2 36.4 2.7 5.3 1.9 36.8 3 5.5 2.1 35.7 2.5 5 2 35.8 2.8 5.1 2.4 36.4 3.2 5.3 2.3 36.5 3 5.5 1.8 37.7 3.8 6.7 2.2 37.7 2.6 6.9 2.3 36 2.2 5 1.5 36.9 3.2 5.7 2.3 35.6 2.8 4.9 2 37.7 2.8 6.7 2 36.3 2.7 4.9 1.8 36.7 3.3 5.7 2.1 3 graphviz安装先pip install praphviz windows端需要去官网下载msi文件进行安装 然后将D:\\Graphviz2.39\\bin添加到环境变量","link":"/2019/11/02/%E5%86%B3%E7%AD%96%E6%A0%91ID3%E7%AE%97%E6%B3%95Python%E5%AE%9E%E7%8E%B0/"},{"title":"决策论","text":"决策论中的一些基本概念。 基本内容 不确定型决策的几种准则：悲观准则、乐观准则、最小后悔准则、等可能性准则与乐观系数法 风险型决策的最大期望收益值法（EMV）、贝叶斯决策准则及信息价值（EVPI）、决策树法 不确定型决策决策基本要素 状态空间：$S=\\left{S_{1}, S_{2}, S_{3} \\cdots, S_{m}\\right}=\\left{S_{i}\\right} \\quad i=1, \\cdots m$ 策略空间：$A=\\left{A_{1}, A_{2}, \\cdots, A_{n}\\right}=\\left{A_{j}\\right} \\quad j=1, \\cdots, n$ 损益函数：$U_{i j}=u\\left(S_{i}, A_{j}\\right) \\quad i=1,2, \\cdots m ; j=1,2, \\cdots n$ 所以决策系统可以表示为三个主要素的函数： $$D=D(S, U, V)$$ 不确定决策例子公司决策生产那种新商品 悲观主义准则（小中取大） 乐观主义准则（大中取大） 最小后悔值准则：编制机会损失表$r_{i j }=\\left{\\max {j}\\left{a{i j }\\right}-a_{i j}\\right}$,找出每个方案的最大机会损失$Z_{i}=\\max {i}\\left{r{i j}\\right}$,选择最小的机会损失值$Z_{l}^{*}=\\min {i}\\left{Z{i}\\right}$ 等可能型决策：不同状态等可能，计算平均收益 乐观系数法：给出乐观系数$\\alpha \\in[0,1]$ 风险型决策对发生各事件的概率已知，一般采用期望值作为决策准则。 贝叶斯决策准则及信息价值（EVPI）已知先验概率，可以通过增加花费（信息费用）修正概率，修正概率通过贝叶斯公式得到。","link":"/2019/08/09/%E5%86%B3%E7%AD%96%E8%AE%BA/"},{"title":"分布式系统","text":"分布式系统 分布式事务事务事务是数据库上进行的一系列操作的集合，是数据改变的不可分割的基本单位。 原子性，不可分割，要不都成功要不都失败， 一致性，比如转账事务，转账前后钱总和不变，事务做完后，数据完整性不会被破坏 隔离性，一个事务不会看到另一个事务正在修改的数据，事务之间的安全，事务修改不会又相互的影响 持久性，事务提交完成后，修改一定会保存到数据库里不会丢失，数据安全落地的问题 隔离性 数据库必须遵照一种隔离级别，现象是几种隔离级别产生的 脏读 事务A修改了数据data，但未提交 此时事务B读到了data的修改，称为脏读 不可重复读 事务A的两次读data之间，事务B访问了数据data，并进行了修改提交 事务A的前后两次读由于事务B的修改，导致的不一致成为不可重复读 幻读 与不可重复度的区别是，幻读涉及的是插入操作，不可重复读是更新 同一个事务的不同时刻读到的数据可能多了（有另外的事务insert data） 未提交读 提交读 可重复读（整个事务从开始到结束，读某个数据的结果不会改变） Raft协议 raft是一个公式算法，raft将集群中的角色分为leader、follwer、candidate。正常情况下集群中只能由一个leader，然后一群follower，没有candidate。当leader挂了，这个时候follwer收不到来自leader的心跳，就会变成candidate进行选举。选举是节点先自己给自己投一票，然后向其他节点拉票，如果拉到的票数超过集群数目的一半，就可以成为leader。集群只有Leader能写入日志，Leader负责复制日志到Follower节点，并强制Follower节点与自己保持相同。 leader：整个集群的管理者，所有客户端的读写都走leader follower：被管理者，对其他服务做出相应 conditate：follower演变过来，leader长时间没有统计信息 写数据时候只写leader，leader将写入指令变成日志的方式向所有follower复制，当集群中的大多数节点都收到了日志并且都持久化，则认为该日志已经commited，leader就可以把写入apply到db中变成kv数据。 数据以region形式存放，每一个region就是一个kv结构，相邻两个region不允许出现间隙，每一个region的key是一个前闭后开的区间，比如[1,1000)。region有一个最大限制，比如96M，超过后就会分裂。 一个region构成一个raft组，多个raft group就是multi raft。 日志复制写数据只发送给leader，leader开始相应，数据同步到其他follower 第一步叫propose：leader收到请求，将请求转化成日志 写入请求变成一条写入日志，存入到自己的日志文件里日志格式，每条日志有一个标识：region号+日志号，日志存储在db实例中，这个实例时专门存log的。 第二步叫append：将raft日志中写到db中，把日志进行持久化。follower收到日志后也写入到自己的存储中。 第三步commited：大多数region都返回append成功的消息。 leader选举 term，一个时期的意思。raft将时间分成了一小段一小段的term。对于raft，时间由一个个term组成，一个term代表一段固定的关系。 集群刚开始创建的时候时没有leader的，全是followe，每一个region有一个计时器，每个计时器有个election time out， 就是等待leader心跳的时间。那个region先超过election time out，就会从follower变成candidate，递增自己的term，并发出我要当leader的请求，然后其他的follower根据term是否比自己大进行投票，多数同意leader就产生了。 选举流程： 节点以Follower状态启动，同时随机生成自己的选举超时时间 选举超时时，节点向自己发送MSGhup消息。 节点进行选举：首先将自己的term + 1，然后广播给其他节点选举消息，带上其他字段，包括：节点当前的最后一条日志索引（Index），最后一条日志对应的任期号（LogTerm），选举任期号（Term），Context字段。 如果选举成功，就切换为leader，同时发送sendAppend。 问答题https://blog.csdn.net/zhou920786312/article/details/115457979 ### 参考资料可视化raft：http://thesecretlivesofdata.com/raft/ 幽灵复现问题：https://zhuanlan.zhihu.com/p/362679439","link":"/2021/09/15/%E5%88%86%E5%B8%83%E5%BC%8F%E7%B3%BB%E7%BB%9F/"},{"title":"前端传参到后台中文乱码问题解决","text":"前端传参到后台中文乱码问题解决 在项目的web.xml文件中使用字符编码过滤器： 1234567891011121314151617&lt;filter&gt; &lt;filter-name&gt;CharacterEncodingFilter&lt;/filter-name&gt; &lt;filter-class&gt;org.springframework.web.filter.CharacterEncodingFilter&lt;/filter-class&gt; &lt;init-param&gt; &lt;param-name&gt;encoding&lt;/param-name&gt; &lt;param-value&gt;UTF-8&lt;/param-value&gt; &lt;/init-param&gt; &lt;init-param&gt; &lt;param-name&gt;forceEncoding&lt;/param-name&gt; &lt;param-value&gt;true&lt;/param-value&gt; &lt;/init-param&gt; &lt;/filter&gt;&lt;filter-mapping&gt; &lt;filter-name&gt;CharacterEncodingFilter&lt;/filter-name&gt; &lt;url-pattern&gt;/*&lt;/url-pattern&gt;&lt;/filter-mapping&gt;","link":"/2019/10/21/%E5%89%8D%E7%AB%AF%E4%BC%A0%E5%8F%82%E5%88%B0%E5%90%8E%E5%8F%B0%E4%B8%AD%E6%96%87%E4%B9%B1%E7%A0%81%E9%97%AE%E9%A2%98%E8%A7%A3%E5%86%B3/"},{"title":"协程","text":"libco分析，以32位为例 协程协程结构体作用类似进程对应的PCB，这里看作协程控制块，包含了协程的上下文数据。 12345678910111213141516171819202122232425262728struct stCoRoutine_t{ stCoRoutineEnv_t *env; pfn_co_routine_t pfn; //实际待执行的协程函数 void *arg; //参数 coctx_t ctx;//协程上下文，就是那些寄存器 //一些状态和标志变量 char cStart; char cEnd; char cIsMain; char cEnableSysHook; char cIsShareStack; void *pvEnv;//用于保存系统环境变量的指针 //char sRunStack[ 1024 * 128 ]; stStackMem_t* stack_mem; //协程栈 //save satck buffer while confilct on same stack_buffer; char* stack_sp; unsigned int save_size; char* save_buffer; stCoSpec_t aSpec[1024];}; 协程栈libco提供了两种实现方式：独立栈和共享栈 独立栈：为每一个协程分配一个单独的、固定大小的栈。一个协程默认128K. 共享栈：仅为当前正在运行的协程分配栈内存。协程切换出去后，会把他的栈内存拷贝到一个独立的缓冲区，再次调度的时候再拷贝回来。一般来说，一个协程实际的栈空间要小于128KB，这样的方案占用内存会小很多，但是拷贝内存也有时间开销，各有利弊。 协程环境结构体这个结构体是跟线程绑定的，运行再一个线程上的各个协程共享该环境结构体。 当前运行的协程、上次挂起的协程、嵌套调用的协程栈，一个epoll的封装结构 123456789101112131415struct stCoRoutineEnv_t{ stCoRoutine_t *pCallStack[ 128 ]; //递归调用的协程栈，最深128 int iCallStackSize; //当前递归深度 stCoEpoll_t *pEpoll; //for copy stack log lastco and nextco stCoRoutine_t* pending_co;//共享栈时候用这两个指针 stCoRoutine_t* occupy_co;};stCoRoutine_t *GetCurrCo( stCoRoutineEnv_t *env )//获取当前协程{ return env-&gt;pCallStack[ env-&gt;iCallStackSize - 1 ];} 这里的调用协程栈要跟前面的协程栈区分开，是调用栈。 先要知道，libco实现的协程是非对称协程。非对称的意思就是协程间存在明确的调用关系，被调协程只能返回调用者协程。（go实现的是对称协程）。因此这里的调用关系必须用链保存下来，也就是这里的pCallStack。 每次启动（resume）一个协程，就将他的协程控制块的指针保存到栈顶。然后切换上下文到带启动协程。当协程要让出CPU时，也即是yield，就要弹栈，返回切换上下文到栈顶的协程。 主协程，也就是libc的第一个协程，执行main函数的协程，不会yield。 上下文上下文结构体12345678910111213141516171819struct coctx_t{#if defined(__i386__) void *regs[ 8 ];#else void *regs[ 14 ];#endif size_t ss_size;//栈大小 char *ss_sp;//栈顶 };// | regs[0]: ret |// | regs[1]: ebx |// | regs[2]: ecx |// | regs[3]: edx |// | regs[4]: edi |// | regs[5]: esi |// | regs[6]: ebp |// | regs[7]: eax | = esp 上下文创建初始化上下文的栈和跳转点 12345678910111213141516171819202122int coctx_make(coctx_t* ctx, coctx_pfn_t pfn, const void* s, const void* s1) { // make room for coctx_param char* sp = ctx-&gt;ss_sp + ctx-&gt;ss_size - sizeof(coctx_param_t); sp = (char*)((unsigned long)sp &amp; -16L); coctx_param_t* param = (coctx_param_t*)sp; void** ret_addr = (void**)(sp - sizeof(void*) * 2); *ret_addr = (void*)pfn; param-&gt;s1 = s; param-&gt;s2 = s1; memset(ctx-&gt;regs, 0, sizeof(ctx-&gt;regs));//通用寄存器初始化 ctx-&gt;regs[kESP] = (char*)(sp) - sizeof(void*) * 2; return 0;}struct coctx_param_t{ const void *s1; const void *s2;}; 上下文切换coctx_swap.S 1234567891011121314151617181920 movl 4(%esp), %eax movl %esp, 28(%eax) movl %ebp, 24(%eax) movl %esi, 20(%eax) movl %edi, 16(%eax) movl %edx, 12(%eax) movl %ecx, 8(%eax) movl %ebx, 4(%eax) movl 8(%esp), %eax movl 4(%eax), %ebx movl 8(%eax), %ecx movl 12(%eax), %edx movl 16(%eax), %edi movl 20(%eax), %esi movl 24(%eax), %ebp movl 28(%eax), %espret 协程生命周期协程创建12345678910int co_create( stCoRoutine_t **ppco,const stCoRoutineAttr_t *attr,pfn_co_routine_t pfn,void *arg ){ if( !co_get_curr_thread_env() ) { co_init_curr_thread_env(); } stCoRoutine_t *co = co_create_env( co_get_curr_thread_env(), attr, pfn,arg ); *ppco = co; return 0;} 协程创建后，这时协程还没启动 协程切换非共享栈情况下，切换上下文即可。 为了节约内存，采用共享栈，每个协程栈无需占据128K而是根据size动态分配。 123456789101112131415161718192021222324252627282930313233343536373839404142434445void co_swap(stCoRoutine_t* curr, stCoRoutine_t* pending_co){ stCoRoutineEnv_t* env = co_get_curr_thread_env(); //get curr stack sp char c; curr-&gt;stack_sp= &amp;c; if (!pending_co-&gt;cIsShareStack)//非共享栈情况下，切换上下文即可。 { env-&gt;pending_co = NULL; env-&gt;occupy_co = NULL; } else { env-&gt;pending_co = pending_co; //get last occupy co on the same stack mem stCoRoutine_t* occupy_co = pending_co-&gt;stack_mem-&gt;occupy_co; //set pending co to occupy thest stack mem; pending_co-&gt;stack_mem-&gt;occupy_co = pending_co; env-&gt;occupy_co = occupy_co; if (occupy_co &amp;&amp; occupy_co != pending_co) { save_stack_buffer(occupy_co); } } //swap context coctx_swap(&amp;(curr-&gt;ctx),&amp;(pending_co-&gt;ctx) ); //stack buffer may be overwrite, so get again; stCoRoutineEnv_t* curr_env = co_get_curr_thread_env(); stCoRoutine_t* update_occupy_co = curr_env-&gt;occupy_co; stCoRoutine_t* update_pending_co = curr_env-&gt;pending_co; if (update_occupy_co &amp;&amp; update_pending_co &amp;&amp; update_occupy_co != update_pending_co) { //resume stack buffer if (update_pending_co-&gt;save_buffer &amp;&amp; update_pending_co-&gt;save_size &gt; 0) { memcpy(update_pending_co-&gt;stack_sp, update_pending_co-&gt;save_buffer, update_pending_co-&gt;save_size); } }} 参考资料https://zhuanlan.zhihu.com/p/338767781 https://zhuanlan.zhihu.com/p/178525588","link":"/2021/01/07/%E5%8D%8F%E7%A8%8B/"},{"title":"卷积网络中的一些操作","text":"参考：https://zhuanlan.zhihu.com/p/28749411记录了一些卷积神经网络种的操作。 Group convolution（分组卷积） 卷积核的总数不变，通道数变为原来的$1/G$,故参数量也变为原来的$1/G$,减少了参数（G为分组数）。 1nn.functional.conv2d(x,self.convWeight2,bias = self.mybias,stride=1, padding=1, dilation=1, groups=1) groups参数就表示分组卷积的组数，传统卷积下groups=1。 3*3卷积核之前人们的观念是，卷积核越大，receptive field（感受野）越大，看到的图片信息越多，因此获得的特征越好。虽说如此，但是大的卷积核会导致计算量的暴增，不利于模型深度的增加，计算性能也会降低。于是在VGG（最早使用）、Inception网络中，利用2个3×3卷积核的组合比1个5×5卷积核的效果更佳，同时参数量（3×3×2+1 VS 5×5×1+1）被降低，因此后来3×3卷积核被广泛应用在各种模型中。 Inception结构 一个输入的feature map分别同时经过1×1、3×3、5×5的卷积核的处理，得出的特征再组合起来，获得更佳的特征。 Bottleneck为了解决Inception带来的参数变多的问题，引入$1 \\times 1$的卷积核。 对比两种结构： 输入为256通道的feature map，$3 \\times 3 \\times 256$ 表示256个3*3卷积核，通常省略通道数，那么参数量为：256×3×3×256 = 589,824 若先通过1×1×64的卷积层，维度变为64通道，再经过一个3×3×64的卷积层，最后经过一个1×1×256的卷积层，输出256维，参数量为：256×1×1×64 + 64×3×3×64 + 64×1×1×256 = 69,632。 Resnet残差网络解决网络退化问题：随着深度增加，网络表现变差，很大程度上的原因是因为当层数加深时，梯度消散得越来越严重，以至于反向传播很难训练到浅层的网络。 1234567891011121314151617181920212223# Residual block定义残差块class ResidualBlock(nn.Module): def __init__(self, in_channels, out_channels, stride=1, downsample=None): super(ResidualBlock, self).__init__() self.conv1 = conv3x3(in_channels, out_channels, stride) self.bn1 = nn.BatchNorm2d(out_channels) self.relu = nn.ReLU(inplace=True) self.conv2 = conv3x3(out_channels, out_channels) self.bn2 = nn.BatchNorm2d(out_channels) self.downsample = downsample def forward(self, x): residual = x out = self.conv1(x) out = self.bn1(out) out = self.relu(out) out = self.conv2(out) out = self.bn2(out) if self.downsample: residual = self.downsample(x) out += residual out = self.relu(out) return out DepthWise操作 假设输入通道数为3，要求输出通道数为256，两种做法： 1.直接接一个3×3×256的卷积核，参数量为：3×3×3×256 = 6,912 2.DW操作，分两步完成，参数量为：3×3×3 + 3×1×1×256 = 795 ShuffleNet对通道进行随机分组，传统Group Convolution只能在最后时刻才融合不同组之间的特征，对模型的泛化性是相当不利。 ShuffleNet在每一次层叠这种Group conv层前，都进行一次channel shuffle，shuffle过的通道被分配到不同组当中。进行完一次group conv之后，再一次channel shuffle，然后分到下一层组卷积当中，以此循环。 SEnet通道间的特征可以加入权重，第一条直接通过，第二条首先进行Squeeze操作（Global Average Pooling），把每个通道2维的特征压缩成一个1维，从而得到一个特征通道向量（每个数字代表对应通道的特征），把这一列特征通道向量输入两个全连接层和sigmoid，建模出特征通道间的相关性，得到的输出其实就是每个通道对应的权重，把这些权重通过Scale乘法通道加权到原来的特征上（第一条路），这样就完成了特征通道的权重分配。 Dilated convolution（空洞卷积）1nn.functional.conv2d(x,self.convWeight2,bias = self.mybias,stride=1, padding=1, dilation=1, groups=1) dilation=1就是空洞的大小。 这样即使卷积核大小不变，但它看到的区域变得更大了。 Deformable convolution 可变形卷积核直接在原来的过滤器前面再加一层过滤器，这层过滤器学习的是下一层卷积核的位置偏移量（offset），这样只是增加了一层过滤器，或者直接把原网络中的某一层过滤器当成学习offset的过滤器，这样实际增加的计算量是相当少的，但能实现可变形卷积核，识别特征的效果更好。 参考资料分组卷积：https://www.cnblogs.com/shine-lee/p/10243114.html 残差网络demo：https://shenxiaohai.me/2018/10/19/pytorch_tutorial_intermediate_02/","link":"/2019/11/10/%E5%8D%B7%E7%A7%AF%E7%BD%91%E7%BB%9C%E4%B8%AD%E7%9A%84%E4%B8%80%E4%BA%9B%E6%93%8D%E4%BD%9C/"},{"title":"右键添加管理员取得所有权","text":"12345678910111213141516171819Windows Registry Editor Version 5.00 [HKEY_CLASSES_ROOT\\*\\shell\\runas] @=\"管理员取得所有权\" \"NoWorkingDirectory\"=\"\" [HKEY_CLASSES_ROOT\\*\\shell\\runas\\command] @=\"cmd.exe /c takeown /f \\\"%1\\\" &amp;&amp; icacls \\\"%1\\\" /grant administrators:F\" \"IsolatedCommand\"=\"cmd.exe /c takeown /f \\\"%1\\\" &amp;&amp; icacls \\\"%1\\\" /grant administrators:F\" [HKEY_CLASSES_ROOT\\exefile\\shell\\runas2] @=\"管理员取得所有权\" \"NoWorkingDirectory\"=\"\" [HKEY_CLASSES_ROOT\\exefile\\shell\\runas2\\command] @=\"cmd.exe /c takeown /f \\\"%1\\\" &amp;&amp; icacls \\\"%1\\\" /grant administrators:F\" \"IsolatedCommand\"=\"cmd.exe /c takeown /f \\\"%1\\\" &amp;&amp; icacls \\\"%1\\\" /grant administrators:F\" [HKEY_CLASSES_ROOT\\Directory\\shell\\runas] @=\"管理员取得所有权\" \"NoWorkingDirectory\"=\"\" [HKEY_CLASSES_ROOT\\Directory\\shell\\runas\\command] @=\"cmd.exe /c takeown /f \\\"%1\\\" /r /d y &amp;&amp; icacls \\\"%1\\\" /grant administrators:F /t\" \"IsolatedCommand\"=\"cmd.exe /c takeown /f \\\"%1\\\" /r /d y &amp;&amp; icacls \\\"%1\\\" /grant administrators:F /t\" 在txt文件中写入，使用ANSI编码，重命名为.reg文件，双击","link":"/2019/07/29/%E5%8F%B3%E9%94%AE%E6%B7%BB%E5%8A%A0%E7%AE%A1%E7%90%86%E5%91%98%E5%8F%96%E5%BE%97%E6%89%80%E6%9C%89%E6%9D%83/"},{"title":"实验室服务器日常运维","text":"用户管理添加新用户1adduser username adduser和useradd的区别是adduser会在/home下创建同名目录，也会设置密码，设置shell，用adduser就可以。 添加到sudo用户组1usermod -aG sudo username 文件备份1rsync 安全防护禁用密码登录使用密钥1234567ssh-keygen#回车即可#会在.ssh下生成一个公钥一个私钥#将私钥拷贝到自己主机上#在服务器上安装公钥cat id_rsa.pub &gt;&gt; authorized_keyschmod 600 authorized_keys 配置SSH 打开/etc/ssh/sshd_config文件设置 1234Port XXXX#修改默认端口号RSAAuthentication yesPubkeyAuthentication yesPasswordAuthentication no 然后重启SSH service sshd restart 本地使用私钥登录 fail2ban使用密钥登录这个就用不到了 123sudo apt install fail2bansudo cp /etc/fail2ban/jail.{conf,local}sudo fail2ban-client status sshd #查看fail2ban日志 炼丹环境安装驱动选择自己的显卡型号，系统 https://www.nvidia.cn/Download/index.aspx?lang=cn wget url下载NVIDIA-Linux-x86_64-xx.xx.run驱动 魔法搭建不少机场都是给一个订阅url，然而v2ray命令行版并不支持订阅，需要解析工具：https://github.com/arkrz/v2sub 1234567891011121314# 因 ping 与 服务重启 权限需要，以 root 权限运行:sudo v2sub# 快速切换节点：sudo v2sub -q# 允许监听外部连接：sudo v2sub -wan# 修改监听端口：sudo v2sub -http 7890 -socks 7891# 更多帮助：v2sub -help vmess可以直接用下面脚本转json https://github.com/boypt/vmess2json v2ray安装没梯子的话安装脚本大概率下载不了，自己下载预编译文件后传到服务器上，把文件copy到对应文件夹 https://github.com/v2fly/v2ray-core/releases 安装v2gen，生成config,默认端口号是1080和1081，需要在 https://github.com/teasiu/v2gen/blob/main/README_zh_cn.md 开启samba服务123sudo apt install sambasudo useradd sambausersudo smbpasswd -a sambauser 编辑/etc/samba/smb.config 12345678[shareFold] #共享文件夹名称 comment = 共享文件说明摘要 #comment是对该共享的描述，可以是任意字符串 path = home/shareFold #共享文件夹路径 writable = yes #用户是否可写入，此处的值千万不能写错，如果写成Yes，则会报错，samba服务启动会失败 valid users = user1,user2 #此处的user1为上一步中使用adduser创建的用户名，不同用户名之间用逗号隔开 browseable = yes #用户是否可浏览目录 guest ok = no #是否可以随意访问 directory mask = 1777 #上传的目录具有所有权限 常用命令： 1234pdbedit -L #列出samba用户pdbedit -Lv #详细列出samba用户信息systemctl enable smb #设置开机启动samba服务pdbedit -x username #删除samba账号 autossh内网穿透公网机器上需要在ect/ssh/sshd_config下修改GatewayPorts yes然后sudo service sshd restart内网机器： 12autossh -p 公网ssh端口号 -M 本地监听端口号 -NR '*:对外端口号:localhost:本地ssh端口号' 公网username@公网ipautossh -p 2333 -M 27400 -NR '*:2334:localhost:22' xxx@xxx 内网机器添加service 1234567891011[Unit]Description=Auto SSH TunnelAfter=network-online.target[Service]User=rootExecStart=/usr/bin/autossh -p 2333 -M 27400 -NR '*:2334:localhost:22' xxx@xxxx -i ~/.ssh/id_rsa_cloud -o TCPKeepAlive=yes -o ServerAliveInterval=30ExecReload=/bin/kill -HUP $MAINPIDRestart=on-failure[Install]WantedBy=multi-user.targetWantedBy=graphical.target id_rsa_cloud生成：ssh-keygenssh-copy-id -p port 公网主机username@ip 注意公网机器的端口是否开放 zerotier1、在线安装zerotiercurl -s https://install.zerotier.com/ | sudo bash 2、添加开机自启 $ sudo systemctl enable zerotier-one.service 3、启动zerotier-one.service $ sudo systemctl start zerotier-one.service 4、加入网络 $ sudo zerotier-cli join xxxxxxx cgrouphttps://blog.csdn.net/weixin_41855380/article/details/109553353 https://www.jianshu.com/p/5edb9f4e4c94","link":"/2022/01/07/%E5%AE%9E%E9%AA%8C%E5%AE%A4%E6%9C%8D%E5%8A%A1%E5%99%A8%E6%97%A5%E5%B8%B8%E8%BF%90%E7%BB%B4/"},{"title":"对象池与operator重载","text":"对象池与operator重载 new作为关键字和运算符operator new can be called explicitly as a regular function, but in C++, new is an operator with a very specific behavior: An expression with the new operator, first calls function operator new (i.e., this function) with the size of its type specifier as first argument, and if this is successful, it then automatically initializes or constructs the object (if needed). Finally, the expression evaluates as a pointer to the appropriate type. 代码里写的new是关键字，编译器根据实际情况调用new运算符。 代码里写下new关键字，编译器会：1、调用operator new，也就是调用new运算符malloc，返回ptr。new运算符可以用户重载。2、调用A::A()构造函数在ptr上初始化对象。3、void*类型转化，返回对象的指针。 placement new1A* p = new(ptr) A() placement new也是new运算符的重载，多传入了一个参数void* ptr，定义在#incldue&lt;new&gt;中，对步骤一来说，直接返回ptr, 不再分配内存（用户已经分配好了，传入ptr）。 对象池123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189#ifndef _ObjectPoolBase_hpp_#define _ObjectPoolBase_hpp_#include&lt;stdlib.h&gt;#include&lt;assert.h&gt;#include&lt;mutex&gt;#ifdef _DEBUG#ifndef xPrintf#include&lt;stdio.h&gt;#define xPrintf(...) printf(__VA_ARGS__)#endif#else#ifndef xPrintf#define xPrintf(...)#endif#endif // _DEBUG//模板给对象池提供参数接口template&lt;class Type, size_t nPoolSzie&gt;//对象池的实现class CELLObjectPool{public: CELLObjectPool() { initPool(); } ~CELLObjectPool() { if (_pBuf) delete[] _pBuf; }private: //NodeHeader是每个对象的描述信息 class NodeHeader { public: //下一块位置 NodeHeader* pNext; //内存块编号 int nID; //引用次数 char nRef; //是否在内存池中 bool bPool; private: //预留 char c1; char c2; };public: //释放对象内存 void freeObjMemory(void* pMem) { //首地址往前偏移，对象和对象描述信息的内存一起释放 NodeHeader* pBlock = (NodeHeader*)((char*)pMem - sizeof(NodeHeader)); xPrintf(\"freeObjMemory: %llx, id=%d\\n\", pBlock, pBlock-&gt;nID); assert(1 == pBlock-&gt;nRef); //内存在对象池的部分释放之后，指针回到第一个未分配的对象 if (pBlock-&gt;bPool) { std::lock_guard&lt;std::mutex&gt; lg(_mutex); if (--pBlock-&gt;nRef != 0) { return; } pBlock-&gt;pNext = _pHeader; _pHeader = pBlock; } else { if (--pBlock-&gt;nRef != 0) { return; } //不在对象池的直接释放内存 delete[] pBlock; } } //申请对象内存，优先向内存池申请内存，内存池不够在向系统申请内存 void* allocObjMemory(size_t nSize) { std::lock_guard&lt;std::mutex&gt; lg(_mutex); NodeHeader* pReturn = nullptr; //如果对象池已经满了，数量达到上限，需要向系统申请内存 if (nullptr == _pHeader) { //计算对象池大小=对象数量*（一个对象内存大小+对象描述信息内存大小） pReturn = (NodeHeader*)new char[sizeof(Type) + sizeof(NodeHeader)]; pReturn-&gt;bPool = false; pReturn-&gt;nID = -1; pReturn-&gt;nRef = 1; pReturn-&gt;pNext = nullptr; } else { pReturn = _pHeader; _pHeader = _pHeader-&gt;pNext; assert(0 == pReturn-&gt;nRef); pReturn-&gt;nRef = 1; } xPrintf(\"allocObjMemory: %llx, id=%d, size=%d\\n\", pReturn, pReturn-&gt;nID, nSize); return ((char*)pReturn + sizeof(NodeHeader)); }private: //初始化对象池 void initPool() { //断言 assert(nullptr == _pBuf); //对象池不为空（已经初始化过），不初始化直接返回 if (_pBuf) return; //计算对象池大小=对象数量*（一个对象内存大小+对象描述信息内存大小） size_t realSzie = sizeof(Type) + sizeof(NodeHeader); size_t n = nPoolSzie * realSzie; //申请池的内存 _pBuf = new char[n]; //初始化内存池 _pHeader = (NodeHeader*)_pBuf; _pHeader-&gt;bPool = true; _pHeader-&gt;nID = 0; _pHeader-&gt;nRef = 0; _pHeader-&gt;pNext = nullptr; //遍历内存块进行初始化 NodeHeader* pTemp1 = _pHeader; for (size_t n = 1; n &lt; nPoolSzie; n++) { NodeHeader* pTemp2 = (NodeHeader*)(_pBuf + (n* realSzie)); pTemp2-&gt;bPool = true; pTemp2-&gt;nID = n; pTemp2-&gt;nRef = 0; pTemp2-&gt;pNext = nullptr; pTemp1-&gt;pNext = pTemp2; pTemp1 = pTemp2; } }private: //描述信息块地址 NodeHeader* _pHeader; //对象池内存缓存区地址 char* _pBuf; //多线程使用需要加锁 std::mutex _mutex;};//模板类给主函数使用对象池提供接口template&lt;class Type, size_t nPoolSzie&gt;//使用对象池的类class ObjectPoolBase{public: //重载给对象申请内存的new操作 void* operator new(size_t nSize) { return objectPool().allocObjMemory(nSize); } //重载给对象释放内存的delete操作 void operator delete(void* p) { objectPool().freeObjMemory(p); } // template&lt;typename ...Args&gt; static Type* createObject(Args ... args) { //不定参数 可变参数 Type* obj = new Type(args...); //可以做点其它的事情，比如说对象的放逐和驱逐 return obj; } //销毁对象 static void destroyObject(Type* obj) { delete obj; }private: //定义不同类型的对象池 typedef CELLObjectPool&lt;Type, nPoolSzie&gt; ClassTypePool; //单例-饿汉模式，实例化一个对象池 static ClassTypePool&amp; objectPool() { //静态CELLObjectPool对象 static ClassTypePool sPool; return sPool; }};#endif // !_ObjectPoolBase_hpp_#include \"ObjectPoolBase.hpp\" 这样也就能理解为什么从对象池中分配调用的是：Type* obj = new Type(args...)而new的重载只有一个参数nSize，因为nSize就是new运算符的默认参数，分配了内存后再调用构造函数Type(args...)初始化。 参考new: https://blog.csdn.net/ly930156123/article/details/78855379对象池实现：https://www.cnblogs.com/-citywall123/p/12726552.html","link":"/2022/07/19/%E5%AF%B9%E8%B1%A1%E6%B1%A0%E4%B8%8Eoperator%E9%87%8D%E8%BD%BD/"},{"title":"性能分析","text":"利用时间戳、perf工具分析程序性能 时间戳 time gettimeofday clock_gettime rdtsc: https://github.com/MengRao/tscns三者性能差不多，都是走的vdso，time是对gettimeofday的封装，vdso就理解成内核会定期”推送”共享内存区域到用户态，用户在调用这些glibc函数时候，并不真正执行系统调用，直接从用户态拿就可以了。rdtsc最快。 测试代码： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889909192#include &lt;sys/time.h&gt;#include &lt;time.h&gt;#include &lt;iostream&gt;#include \"tscns.h\"using namespace std;uint64_t now() { struct timeval tv; gettimeofday(&amp;tv, NULL); return tv.tv_sec * 1000000 + tv.tv_usec;}void* func_gettimeofday(void* p) { int32_t c = *(int32_t*)p; uint64_t start = now(); uint64_t us = 0; int i = 0; while (i++ &lt; c) { struct timeval tv; gettimeofday(&amp;tv, NULL); us += tv.tv_usec; // avoid optimize } cout &lt;&lt; \"gettimeofday(\" &lt;&lt; us &lt;&lt; \") , times : \" &lt;&lt; c &lt;&lt; endl; cout &lt;&lt; \"thread \" &lt;&lt; pthread_self() &lt;&lt; \" consume \" &lt;&lt; now() - start &lt;&lt; \" us\" &lt;&lt; endl; return 0;}void* func_clockgettime(void* p) { int32_t c = *(int32_t*)p; uint64_t start = now(); uint64_t us = 0; int i = 0; while (i++ &lt; c) { struct timespec tp; clock_gettime(CLOCK_REALTIME, &amp;tp); us += tp.tv_nsec; } cout &lt;&lt; \"clock_gettime(\" &lt;&lt; us &lt;&lt; \") , times : \" &lt;&lt; c &lt;&lt; endl; cout &lt;&lt; \"thread \" &lt;&lt; pthread_self() &lt;&lt; \" consume \" &lt;&lt; now() - start &lt;&lt; \" us\" &lt;&lt; endl; return 0;}void* func_tscns(void* p) { int32_t c = *(int32_t*)p; TSCNS tscns; tscns.init(); uint64_t start = now(); uint64_t temp = 0; int i = 0; while (i++ &lt; c) { int64_t tsc = tscns.rdtsc(); temp += tsc; } cout &lt;&lt; \"tscns(\" &lt;&lt; temp &lt;&lt; \") , times : \" &lt;&lt; c &lt;&lt; endl; cout &lt;&lt; \"thread \" &lt;&lt; pthread_self() &lt;&lt; \" consume \" &lt;&lt; now() - start &lt;&lt; \" us\" &lt;&lt; endl; return 0;}int main(int argc, char** argv) { if (argc != 4) { cout &lt;&lt; \" [gettimeofday/clock_gettime] thread_number loop_count\" &lt;&lt; endl; exit(-1); } string mode = string(argv[1]); int n = atoi(argv[2]); int loop = atoi(argv[3]); pthread_t* ts = new pthread_t[n]; for (int i = 0; i &lt; n; i++) { if (mode == \"gettimeofday\") { pthread_create(ts + i, NULL, func_gettimeofday, &amp;loop); } else if (mode == \"clock_gettime\") { pthread_create(ts + i, NULL, func_clockgettime, &amp;loop); } else if (mode == \"tscns\") { pthread_create(ts + i, NULL, func_tscns, &amp;loop); } } for (int i = 0; i &lt; n; i++) { pthread_join(ts[i], NULL); } delete[] ts; return 0;} 获取时间戳 123456#include &lt;time.h&gt;uint64_t get_system_time_nsec() { struct timespec time = {0, 0}; clock_gettime(CLOCK_REALTIME, &amp;time); return time.tv_sec * 1000000000 + time.tv_nsec;} perf使用按频率采样，会生成一个perf.data文件 123perf record -F 99 -g ./program#-F: 采样频率#-g: 记录调用栈 生成预览报告 1perf record -n 绘制火焰图下载FlameGraph 1https://github.com/brendangregg/FlameGraph.git 将 stackcollapse-perf.pl、flamegraph.pl两个文件拷贝到/usr/local/bin目录。添加文件perf2svg.sh，也放到/usr/local/bin目录下。 使用perf2svg ./a.out绘制svg 12345678910111213141516171819202122232425#!/bin/bashexit_func() { if [ -d $dir_tmp ]; then rm -rf $dir_tmp fi}dir_tmp=./.perf_tmp_if [ ! -d $dir_tmp ]; then mkdir $dir_tmpfiif [ $# -eq 0 ]; then echo \"usage: $0 command\" exit_func exit 1fiperf record -o $dir_tmp/perf.data -F 200 -g $@perf script -i $dir_tmp/perf.data &gt; $dir_tmp/out.perfstackcollapse-perf.pl $dir_tmp/out.perf &gt; $dir_tmp/out.foldedflamegraph.pl $dir_tmp/out.folded &gt; perf.svgexit_func 参考https://blog.csdn.net/weixin_43778179/article/details/104574043?utm_medium=distribute.pc_relevant.none-task-blog-2~default~baidujs_baidulandingword~default-5-104574043-blog-8876283.pc_relevant_aa&amp;spm=1001.2101.3001.4242.4&amp;utm_relevant_index=8","link":"/2022/07/14/%E6%80%A7%E8%83%BD%E5%88%86%E6%9E%90/"},{"title":"排队论","text":"记录了排队论中的一些基本概念。 基本内容 了解排队系统的基本概念 了解生灭过程和状态转移图的推演，状态概率公式的推演 掌握排队系统的主要数量指标和记号 熟练掌握排队模型和求解方法（单服务台排队模型） 排队系统的基本构成 输入过程的三特征 输入过程：顾客源无限有限，顾客到达人数成批到达还是单个到达，到达时间间隔分为确定型和随机型（需知概率分布）。服务过程对顾客到达的影响相互独立到达、非相互独立到达（回头客问题）。 排队规则：损失制、等待制、混合制，队列长，队列数 服务机构：服务方式：单顾客、多顾客，服务时间：确定型和随机型 排队模型的表示方式肯德尔（Kendall）记号: $$输入分布/输出分布/并联的服务站数（X/Y/Z）$$ 扩展表示： $$输入分布/输出分布/并联的服务站数/系统容量（队长）$$ $$/系统状态（顾客源数）/服务规则（X/Y/Z/A/B/C）$$ 分布 泊松分布（最简单流）特点： 平稳性：在一定时间间隔内，来到服务系统的k个顾客的概率仅与这段时间的间隔长短有关，而与这段时间的起始时刻无关 无后效性：在不相交的时间区间内到达的顾客数是相互独立的 稀有性：在足够先得时间区间内只能有一个顾客到达，不可能有两个以上得顾客同时到达。 $$P_{k}(t)=e^{-\\lambda t} \\frac{(\\lambda t)^{k}}{k !} \\quad(k=0,1,2, \\cdots)$$ 在t时间内，有k个顾客来到服务系统得概率。 负指数分布： 排队问题中的常用指标 队长和排队长 逗留时间和等待时间 服务机构的工作强度=用于服务顾客的时间/服务设施的总服务时间 忙期：服务机构连续繁忙的时间长度 生灭过程是用来处理输入为最简单流，服务时间为指数分布这类最简单排队模型得方法。 平衡方程对任意状态，单位时间内进入该状态的平均次数和离开该状态的平均次数应该想到能（输入=输出）。 little公式 参考b站：运筹学 黄丽娟","link":"/2019/08/09/%E6%8E%92%E9%98%9F%E8%AE%BA/"},{"title":"操作系统笔记—内存管理","text":"操作系统之内存管理复习记录。 第三章：内存管理程序的装入与链接（了解）高级语言转化为源代码的步骤 编译 链接 加载（装入）：将可加载模块装入内存、逻辑地址转化为物理地址（地址重定位） 加载方式 绝对加载 （编译时执行，如果将来开始地址发生变化，就必须重新编译代码） 可重定位加载（静态重定位，加载时执行，不允许程序在内存中移动） 运行时加载（动态重定位，执行时执行，支持执行时进程在内存中移动） 链接含义源程序编译得到一组目标模块，链接程序将这组模块连接，形成加载模块。 链接方式 静态链接 加载时动态链接 运行时动态链接 内存管理的需求内容 重定位：逻辑地址转化为物理地址 保护 ：进程对内存的使用权限 共享：多个进程正在执行同一程序时，允许每个进程访问该程序的同一个副本 逻辑组织 物理组织 内存分区 固定分区：分区数量一定，每个分区装入一个进程，但是分区的大小不一定相等。 动态分区：（首次匹配、下次/循环匹配、最佳匹配、最差匹配） 首次匹配：从头开始扫描，选择大小足够的第一个块。 下次匹配/循环匹配：从上一次放置的位置开始扫描内存，找到一个可用的块 最佳匹配：选择大小最相近的块 最坏匹配：选择满足要求的最大块 简单分页 简单分段 虚存分页 虚存分段 固定分区和动态分区的折中方案：伙伴系统 分页页和页框页：进程中的块 页框：内存中的块 进程的页装入内存的页框 一个页框的长度和一个页的长度是一样的 页表 每个进程都由一个页表 含有每个页对应的页框位置 CPU使用页表生成物理地址 存放在内存 PCB中存有页表的起始地址 页表寄存器存有当前运行进程的页表起始地址 分页的逻辑地址到物理地址转换 物理地址 = 页框号拼接页内偏移 分段分段的逻辑地址到物理地址的转换 段长可变 物理地址 = 段基址+偏移量（数值相加） 分页和分段比较 页时物理单位，段时逻辑单位 页大小固定、段不固定 分页的地址空间时一维的，分段的地址空间是二维的，理解参考： https://blog.csdn.net/yangkuiwu/article/details/53493458 就是说编译的时候，虽然分页了但是地址是连续的，而分段情况下，不同的段地址是不连续的。 分页不易实现贡共享和运行时的动态链接，而分段可以。 进程的内存访问都是逻辑地址，会在运行时动态的转换为物理地址 进程分块（页或段）后，不需要连续的位于内存，也不用全部都在内存 分页有内部碎片，分段有外部碎片 虚拟内存管理虚拟存储器相关术语 驻留集：任意时刻，进程驻留在内存的部分。 内存失效：访问不在内存的逻辑地址（会产生中断） 抖动：内存空间几乎占满时，页面被频繁的换入换出 局部性原理：存储器的访问呈簇性，很短时间内，CPU只与固定的簇打交道。说明虚存可行。快表和虚存的依据都是局部性原理。 虚拟分页存在位P：表明对应的页是否在内存页框号：若页在内存，则有对应的页框号修改为M：表明相应页上次装入内存到现在是否修改过（决定换出要不要更新） 虚拟分段每个进程一个段表，每个段表项包括： 存在位P，标识相应的段是否位于内存 修改位M，标识相应的段是否已被修改 其他控制位，如用于保护和共享 段基址：相应段在内存中的起始地址 段长度 多级页表 页表页号（页目录号） 页号 页内偏移地址 倒置页表（倒排页表）使用页框号而非页号来索引表项 转换检测缓冲区TLB（快表）TLB包含了最近用过的页表项，位于高速缓存cache中。 一次内存访问可能产生两次缺页中断：读取所需页表，读取进程页 在快表里一定在内存里 缺页率与页尺寸和分配页框数的关系 段页式用户的地址空间被程序员划分为许多段，每段划分为许多大小的页。 每个进程一个段表 每个段一个页表 为了获得一条指令或数据，最少访问三次内存。段表、页表、相应存储单元。 分段有利于保护和共享保护：每个段都有一个长度和基地址，可以控制非法访问 共享：一个段可以在多个进程的段表中被引用，实现共享 相关算法读取策略决定页何时进入内存：请求调页、预调页 放置策略决定进程驻留在内存中的位置：首次匹配、循环匹配等 置换策略淘汰哪个页面用以置换：最佳、最近最少用、先进先出、时钟 最佳置换：置换下次访问时间最长的页面 LRU最近最少用（Least recent use）：内存中最长时间未引用的页面（难实施，开销大）,建立链表，替换的是链表尾部的数据，命中放到链表头部。所以不用计数。 先进先出：置换驻留时间最长的页面 时钟：首次载入内存或被引用使用位 = 1，产生缺页中断时，如果使用位为0，置换，指针前移；为1，置零，指针前移。命中时指针不移动。(开销小) 改进CLOCK：引入访问位、修改位 评价指标：缺页率，OPT&lt;LRU&lt;CLOCK&lt;FIFO 页缓冲未修改的，替换到空闲页链表；修改的，替换到修改页链表，成批写回磁盘。 抖动系统把即将用到的块换出，又很快要使用，造成页面频繁的换入换出，缺页率增大。 驻留集管理 页框分配：一个活动分配几个页框，可变可固定 置换范围：局部置换（仅产生缺页中断的驻留页）、全局置换 局部置换 全局置换 固定分配 分配给进程的页框数固定、从分配给该进程的页框中选择被置换的页 无此方案 可变分配 为了保存进程的工作集，分配给进程的页框数不时变化、从分配给该进程的页框中选择被置换的页 从内存中所有可用页框中选择被置换的页、这将导致进程驻留集大小不断变化 工作集进程在虚拟时间t的参数为Δ的工作集W（t, Δ ），表示该进程在过去的Δ个虚拟时间单位被访问到的页集合。 清除策略何时将修改过的页写回辅存。结合页缓冲 加载控制决定驻留在内存中的进程数量。 L=S准则发生缺页的平均时间L等于处理缺页故障的平均时间S，此时处理器的利用率最大。 BIOS BIOS：基本IO处理系统，开机后计算机系统开始检测各种外设，然后才能加载相应软件执行，BIOS加载bootloader,bootloader加载os Bootloader:一个程序,放在硬盘第一个扇区，加载OS，从硬盘到内存 系统调用、异常、中断","link":"/2019/11/04/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E7%AC%94%E8%AE%B0/"},{"title":"操作系统笔记—IO管理与磁盘调度","text":"操作系统之I/O管理与磁盘调度复习记录。 I/O设备分类 人可读（打印机、鼠标、键盘） 机器可读（磁盘驱动器、USB密钥、传感器） 通信（网卡、调制解调器） I/O控制方式程序I/O方式cpu代表进程给I/O模块发送I/O命令，程序进入忙等，等待操作完成，才能继续执行。 中断驱动I/O方式CPU代表进程给I/O模块发送I/O命令 如果I/O指令是非阻塞的，则继续执行后续指令 如果I/O指令是阻塞的，当前进程阻塞，调度其他进程。 每次传输一个数据即产生中断 直接存储器访问（DMA）方式 工作流程 DMA与中断驱动I/O方式对比 中断频率： 中断驱动I/O：每次传输一个数据产生中断 DMA：一块数据全部传送结束中断 数据传输： 中断驱动I/O：数据传送在中断处理时由CPU完成 DMA：由DMA控制器完成 应用： 中断驱动I/O：键盘鼠标 DMA：磁盘 小结 I/O设计I/O功能组织模型（层次化设计） I/O软件层次 设备独立性应用程序独立于具体使用的物理设备 逻辑I/O模块允许应用程序使用设备标识符及简单的命令与设备打交道。 逻辑设备表：逻辑设备名、物理设备名、驱动程序入口地址 设备I/O模块将逻辑I/O请求和操作转化为响应的物理设备的I/O访问控制。 I/O缓冲输入请求发出前开始输入传送 输出请求发出后一段时间才输出传送 缓冲区在内存 单缓冲 双缓冲 循环缓冲使用两个或多个缓冲区，构成循环缓冲 缓冲作用 缓解I/O设备速度与CPU速度不匹配的矛盾 多道程序环境中，缓冲可以提高操作系统的效率，提高单个进程的性能。 Spooling技术（磁盘中的缓冲） 在磁盘中建立I/O缓冲区，缓和CPU高速和I/O设备低速间的矛盾。 将一台独占物理I/O设备虚拟化为多台逻辑I/O设备。从而允许多个用户共享一台物理I/O设备。 磁盘调度 磁盘性能参数寻道时间Ts 旋转延迟Tr = 1/2r r为磁盘的转速 传输时间Tt = (b/N)/r 磁盘调度策略 FIFO：先到的请求先访问 优先级PRI LIFO 后进先出 ：优先处理新到请求 最短服务时间优先/最短寻道时间优先SSTF：选择磁道距离最近的 电梯算法（SCAN）：磁头折返移动，满足途中的请求，改进：若前方无请求，可提前掉头。特点：偏爱最里和最外的磁道请求 C-SCAN：限定一个方向扫描 黏着现象进程对同一磁道有较高的访问速度时，磁头臂黏在响应的磁道上不移动。 N-step-SCAN：将请求分为若干子队列，每次使用SCAN处理一个队列，N = 1,FIFO;N很大，SCAN。 FSCAN：使用两个队列，扫描开始前，请求都在一个队列中，扫描过程中，新到的请求加入另一个队列，一个队列处理完才会处理另一个。 磁盘高速缓存位于内存的缓冲区，包含磁盘某些扇区的副本。 置换算法 LRU最近最少用（无计数，常用） LFU最不长使用（有计数，不常用，存在问题，前期频繁访问但后期不在使用的块不会被置换出来）","link":"/2019/12/23/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E7%AC%94%E8%AE%B0%E2%80%94IO%E7%AE%A1%E7%90%86%E4%B8%8E%E7%A3%81%E7%9B%98%E8%B0%83%E5%BA%A6/"},{"title":"操作系统笔记—文件系统","text":"操作系统之文件系统复习记录。 概述术语 域：基本数据单元、包含一个值、定长或变长 记录：一组域的集合，视为应用程序的一个单元、定长或变长 文件：一组相似记录的集合、实体、通过名字访问、访问控制的实施级 数据库：数据的集合、一种多种文件组成、数据元素间关系明确、供不同应用程序使用 文件的逻辑结构堆文件、顺序文件、索引顺序文件、索引文件、HASH文件 堆文件 最简单 按时间先后顺序收集数据 每条记录由一串数据组成 目的是积累大量数据并保存 穷举查找方式检索 变长记录、可变域集 顺序文件 最常见 记录固定格式 记录长度相同，域的位置、长度相同 每个记录一个关键域，唯一标识了记录 记录按照关键域存储排序 用于批处理应用 在磁盘或磁带上易存储 索引顺序文件 利用关键字找到该记录组中第一个记录的表项，然后顺序查找所要求的记录 增加了支持随机访问的索引和移除文件 索引文件 通过索引访问记录 变长记录 完全索引：主文件中每条记录的索引项 部分索引：感兴趣域记录的索引项 用于及时性要求高，对数据处理少的应用程序（订票系统，商品库存控制系统） 直接文件或散列文件（HASH文件） 直接访问磁盘上任意地址已知的数据块 基于关键字的散列 文件目录文件目录是指：为实现“按名存取”，必须建立文件名与辅存空间中物理地址的对应关系，体现这种对应关系的数据结构称为文件目录。 对目录的操作查找、创建、删除、修改、显示 目录单元的内容基本信息、地址信息、访问控制信息、使用信息 基本信息 地址信息 访问控制信息 使用信息 文件名、文件类型、文件组织 卷、起始地址、使用大小、分配大小 所有者、访问信息、权限信息 数据创建时间、创建者、最近访问日期、当前文件活动信息等 目录结构单级结构、两级结构、层次结构（树状结构、无循环图结构） 单级结构整个文件系统建立一张目录表，每个目录项对应一个文件 两级结构主目录：每个用户一个目录项，提供地址和访问控制信息 用户目录：用户文件的简单列表，文件名唯一 树状结构 路径定位、文件可重名，路径唯一 绝对路径：从根目录开始指定的目录 相对路径：从工作目录开始 无循环图结构允许多个目录项指向同一个数据或目录文件，实现目录或数据文件的共享（Unix使用） 目录项的删除：存在多个引用时，只删除引用；所有引用都被删除后才删除文件。 文件共享一份物理存储，多个别名。 在Unix中，通过链接实现文件共享（软链接、硬链接） 硬链接 只允许文件链接，同一文件系统下 维护链接计数，减至0，文件被删除 若有文件链接到此文件，则该文件不能删除 软链接 链接的是目录或文件路径 建立符合链接文件（快捷方式） 可跨文件系统，跨计算机 访问速度相对慢，但灵活性大 辅存管理文件分配辅存中，文件由许多块组成 操作系统或文件管理程序为文件分配块 分配方式 预分配：要求文件创建是声明文件的最大尺寸，但是程序的大仙难以估计，用户或程序往往估大文件的尺寸， 动态分配：只有在需要时才给文件分配空间 分区大小 大小可变的大规模连续分区 块（大小固定） 文件的物理结构（文件的分配方法） 连续结构（连续分配） 采用预分配，在创建文件时，分配一组连续的块。适合顺序文件，检索容易。存在外部碎片。 链式结构（链式分配） 存在问题：多个块离散分配，使得局部性原理不再适用，若要一次读入多个块，要访问磁盘的不同部分。 索引结构（索引分配）基于块的索引分配 索引作为单独的块保存 文件分配表的表项指向索引块 基于长度可变分区的索引分配 每个分区有一个表项，提高局部性，经过整理可以减少索引数量，基于块的索引分配不行 空闲空间管理 位示图：001100111….向量表示磁盘每一个块的使用情况，1表示已用。 链接空闲分区：使用指向每个空闲区的指针和长度值，链接空闲区 索引：将空闲区视为文件，使用索引表，基于大小可变的分区 空闲块列表：每个块指定一个序号，所有空闲块的序号保存下来。 卷逻辑磁盘，一组扇区的集合，物理上可不连续，对OS或应用程序来说连续 UNIX文件管理6种文件类型 普通文件 目录文件：包含文件名列表和指向索引节点的指针 特殊文件：不含数据，提供物理设备映射到文件名的机制 命名管道：进程间通信的基础设施 链接文件：一个文件的别名 符号链接：一个数据文件，包含链接文件的文件名 OS通过索引节点（Inode）管理所有文件 索引节点 文件的分配以块为基础、动态分配，索引节点包含n个直接指针和三个间接指针，每个指针指向一个块，块可能是数据，也可能是一组指针。 补充 源程序、可执行文件、库函数等所采用的都是无结构的文件形式，即流式文件。其文件的长度是以字节为单位的。","link":"/2019/12/24/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E7%AC%94%E8%AE%B0%E2%80%94%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F/"},{"title":"操作系统笔记—概论","text":"操纵系统之概论复习记录。 操纵系统的目标与功能目标 方便：使计算机已于使用 有效：有效管理系统资源 扩展能力：可引入新系统功能 功能 提供用户使用计算机系统的接口 提供资源管理功能（进程管理、存储管理、I/O设备管理、文件管理） 操作系统的发展过程串行处理无操作系统、用户按顺序访问计算机：串行、准备时间（加载保存链接等时间）浪费问题 简单批处理系统 有了用户模式和内核模式：用户模式不允许执行特权指令、内核模式可执行特权指令并访问受保护的内存区域 系统调用时，从用户模式切换到内核模式，调用完成后，返回用户模式。 监控程序：作业续接、内存保护、定时器、特权指令（只能由监控程序执行的指令）、中断 处理器等待I/O指令完成才能继续处理 顺序执行各个作业 多道批处理系统 当作业需要等待I/O时，处理器可切换到另一个作业，多作业并发执行、作业调度程序负责调度、DMA、I/O中断 无用户交互，使用作业提供的命令 充分利用处理器 并发执行各个作业 和简单批处理一样，由监控程序调度 分时系统 采用时间片轮转 共享主机、人机交互 多道程序设计计数 多用户共享处理器 多用户不同终端同时访问系统 减小响应时间 终端键入命令 多路性、独立性、及时性、交互性 实时系统及时响应、规定时间内开始或完成时间处理 可确定性、可响应性、用户控制、可靠性、故障弱化能力 进程进程使正在执行的程序实例，包含程序代码、数据、上下文 引入进程的原因在多道批处理、分时以及实时系统中，系统里随时有许多作业在运行，设计协调不同活动的系统软件非常困难，可能存在： 不正确的同步、失败的互斥、不确定的程序操作、死锁 等若干问题，为此需要设计系统级的机制来监控各个作业的运行，进程由此而生。 进程的组成程序、数据、上下文 上下文：进程状态、OS用来管理进程所需的数据、寄存器内容、进程优先级、在内存种的位置等 现代操作系统的特征微内核体系结构、多线程、对称多处理、分布式操作系统、面向对象设计 微内核只给内核分配一些最基本的功能：地址空间、进程间的通信、基本的调度，其他OS服务由运行在用户模式且与其他应用程序类似的进程提供。 微内核和单体内核的区别：单体内核包含了大多数的操纵系统功能，作为单个进程运行、所有元素共享相同的地址空间 多线程一个应用程序的进程划分为可同时运行的多个线程 线程：可分派的工作单元、包括上下文自身数据、顺序执行且可中断 进程：一个或多个线程和系统资源的集合 对称多处理多个进程或线程可以并行运行、多处理器对用户透明（不可见）、OS在不同处理器上调度不同的进程或线程 并发和并行 并发（逻辑上同时） 并行（物理上同时） 多时间交替执行，单处理器系统 多时间同一时刻发生，多处理器系统 分布式操作系统使用户以为（错觉）：单一内存空间，外存空间、同一的存取措施 面向对象设计用于给小内核增加模块化的扩展，基于对象的结构可使程序员定制操作系统，不破坏系统完整性。","link":"/2019/12/24/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E7%AC%94%E8%AE%B0%E2%80%94%E6%A6%82%E8%AE%BA/"},{"title":"操作系统笔记—进程管理","text":"操作系统之进程管理复习记录。 进程的描述与控制当处理器开始执行一个程序的代码时，我们把这个执行的实体称为进程。进程组成：程序代码、相关数据、PCB 进程是什么进程控制块元素：标识符、状态、优先级、程序计数器、内存指针、上下文数据、I/O状态信息、记账信息 进程与程序进程的基本特征 动态性：本质特征，由生命周期 并发性：重要特性 独立性：进程空间地址相互独立，除非采用进程间通信手段 异步性：按各自独立、不可预知速度推进 进程和程序比较 进程是执行的程序实例 进程 = PCB + 程序 + 数据 引入进程的目的：使多道程序能够正确的并发执行 程序使静态实体，进程具有动态性 进程和程序不存在一一对应的关系 进程状态交换把内存中的一个进程的部分或全部移动到磁盘，进程变为挂起状态。 挂起程序的特征 程序不能立即执行 进程可能在等待一个事件，也可能没有 进程被代理设置为挂起状态，代理可能为进程自己，父进程，OS 需要显示命令状态转换，否则进程将一直处于挂起状态 进程挂起的原因：交换、OS原因、用户请求、定时、父进程请求 进程描述操作系统的控制结构OS使用表来记载各资源的信息 内存表：分配给进程的内存、外存，内存块或外存块的保护属性，外存管理所需信息 I/O表：管理I/O设备 文件表：文件是否存在，位置，状态等属性 进程表：管理进程 进程的控制结构进程映像：程序、数据、栈、属性（PCB） PCB中的信息 进程的标识信息：进程标识符，父进程标识符、用户标识符 处理器状态信息：用户可见寄存器、控制和状态寄存器、栈指针 进程控制信息：调度和状态信息、数据结构、进程间通信、进程特权、存储管理、资源所有权和使用情况 执行模式内核OS中包含重要系统功能的部分，常驻内存 内核功能 资源管理：进程管理、存储管理、I/O设备管理 支撑功能：中断处理、时钟管理、记账功能 处理器的执行模式用户模式具有较少优先权的模式，用户程序在该模式下运行 内核模式与OS相关的处理器模式，具有更多优先权、运行OS内核、部分内存和指令只允许特权模式（内核模式）访问或运行 采用两种模式的原因保护操作系统和重要操作系统表（如pcb）不受程序干扰 模式切换程序状态字寄存器存在执行模式的指示位。 用户调用OS服务或中断触发系统例程，内核模式 系统服务返回用户进程，用户模式 系统调用时，从用户模式切换到内核模式，调用完成后，返回用户模式。（有些系统调用可能会引发调用进程阻塞，此时操作系统会切换进程，调度其他进程运行，阻塞进程被唤醒后，可被再次调度，继续原先的执行，返回用户态。） 系统调用：操作系统提供给用户程序访问系统内核功能的接口。用户程序通过调用系统调用来获取操作系统提供的服务，服务完成后返回应用程序。 进程的创建 给进程分配唯一的进程标识符 给进程分配空间 初始化PCB 建立链接，插入到就绪或就绪/挂起链表 建立或扩充其他数据结构 进程切换保存处理器上下文——更新当前进程PCB——PCB移动到相应队列——执行另一个进程——更新PCB——更新内存管理数据结构——恢复选择进程上下文。 系统中断 普通中断：因外部事件产生（时钟中断、I/O中断、内存失效）、时间片（中断前最大运行时间） 陷阱：进程内部的错误或异常 进程切换的时间进程切换是调度另一个就绪进程占用处理器执行 普通中断 陷阱 系统调用 模式切换用户模式和内核模式间切换 用户—&gt;系统：中断出现、程序计数器设置为中断处理程序的开始地址、用户模式切换到内核模式，以便中断处理能执行特权指令。 进程切换和模式切换对比中断、模式切换不一定导致进程切换（如I/O中断，某些系统调用（getpid）不一定会进程切换） 但是进程切换会伴随模式切换，因为要切换到内核模式下完成调度。 模式切换可在不改变进程状态的情况下出现。 线程调度并分派的单位是线程。 资源所有权的单位是进程。 每个线程有：执行状态、线程上下文、执行栈、用于局部变量的静态存储空间、与进程内其他线程共享的内存和资源访问 线程的优点 创建线程的时间少 终止线程时间少 同一进程的线程切换时间少 提高了不同执行程序间的通信效率 线程分类 用户级线程：管理由应用程序完成，内核意识不到线程存在，切换不需要内核模式特权，但系统调用会引起进程阻塞，不能利用多处理器技术 内核级线程：管理由内核完成；内核可以把多线程调度到多处理器上；一个线程阻塞，内核可以调度同一进程的其他线程；内核例程本身也可以多线程（提高了内核效率）；需要模式的切换 混合方法：线程创建在用户空间完成；线程调度同步由应用程序完成（不需要模式切换，开销小），部分线程映射到内核线程（线程阻塞不引起进程阻塞） 进程调度调度的类型长程调度决定那个程序可以进入系统中处理。从作业队列中选择作业来创建进程。 中程调度交换功能的一部分。 短程调度决定下次执行哪个进程，最频繁，导致进程阻塞或发生抢占（时钟中断、I/O中断、系统调用、信号）时调用短程调度程序。 调度的规则基本概念 响应时间：用户提交请求到接收响应 截止时间：任务必须开始或完成的最迟时间 周转时间（驻留时间）：进程提交到完成 带权周转时间：周转时间/服务时间 平均带权周转时间：带权周转时间的均值 规则分类 面向用户（进程的行为）、面向系统（处理器利用率、进程的完成速度） 与性能相关、与性能无关 优先级使用 调度的决策模式 抢占（剥夺）、非抢占（非剥夺）；抢占是指：进程的执行可能被OS中断，转为就绪态，发生在新进程到达、中断发生、时钟中断。 选择函数：关键的参数有，等待时间w、执行时间e、所需总服务时间s。 调度算法|先到先服务|时间片轮转|短作业优先|剩余时间最短优先|相应比高者优先|反馈| 先到先服务非抢占；对长进程有利，不利于短进程（短进程的带权周转时间大），利于CPU繁忙型进程，不利于I/O繁忙型进程。 时间片轮转抢占式；用于分时系统或事务处理系统；时间片略大于一次典型的交互时间，利于CPU繁忙型进程（可充分利用时间片），不利于I/O繁忙型进程（I/O阻塞后加入就绪队列重新排队）。 抢占发生在：时间片结束 短作业优先前提：执行时间已知（估计执行时间）。非抢占；有利于短进程 剩余时间最短者优先在短作业优先的基础上加入了剥夺机制。抢占发生在：新进程加入就绪队列时。仍会存在长进程饥饿现象。 响应比高者优先非抢占；当前进程执行完毕或者阻塞时发生调度。解决了长进程死等的问题，但是要计算响应比，增加了系统开销。 反馈调度法多级队列，惩罚长进程 队列内按时间片抢占，第$i$级队列时间片为$2^i$，被抢占后进入下一级队列，上级队列空闲才会轮到下级队列调度。 长进程仍可能饥饿。 新进程加入时不会抢占，加入第一个队列尾进行排队。 实时系统和实时调度实时系统及时响应外部事件 实时调度 基于时间片的轮转抢占 基于优先级的非抢占式调度 基于优先级的抢占点抢占调度 立即抢占式调度 实时调度的分类方法 静态表驱动调度法 静态优先级抢占调度法 基于动态规划的调度法 动态尽力调度法 期限调度优先级反转：会发生于任何基于优先级抢占的调度方案，一个 高优先级任务间接被一个低优先级任务所抢先。 进程同步并发的原理相关术语 临界资源：不能同时访问，必须互斥访问的资源，如打印机 临界区：访问临界资源的代码。任意时刻只能由一个进程运行这段代码。 忙等：进程等待进入临界区，会继续消耗处理器时间。 互斥：进程在临界区访问共享资源，其他进程不能进入该临界区。 活锁：（相互谦让）两个或两个以上的进程为响应其他进程而持续改变自己状态，但是不做有用工作的情形 死锁：（都不让，相互僵持）两个或两个以上的进程因等待其他进程做完某些事而不能继续执行的情形。 饥饿：（排很久，还是等不到）一个具备执行条件的进程，被调度程序无限期的忽视而不能调度的情形。 互斥互斥的要求 空闲让进：临界区空闲，有进程申请就立即进入 忙则等待：每次一个进程进入临界区 有限等待：不会死锁或者饥饿 让权等待：进程不能长时间在临界区阻塞等待 互斥的实现软件方法不能解决忙等现象 硬件方法 中断禁用：进入临界区之前，屏蔽中断，出临界区再启用中断。用于单处理器系统 专用机器指令：动作再一个指令周期中执行，不会被打断。 信号量可以基于硬件的方式保证进程互斥使用semWait或semSignal操控信号量。 信号量分类二元信号量（01）、计数信号量 都使用队列来组织等待信号量的进程 强信号量：使用FIFO方式从队列里移除 弱信号量：未规定阻塞进程从队列里移除的顺序。 经典问题生产者/消费者问题理发师问题读/写问题 读者优先：一旦有读者读数据，随后的读者进入读数据 公平优先：写过程中，若其他读者写者到来，按到达顺序处理 写者优先：有一个人想写，就不允许新的读者读数据。 哲学家就餐问题管程一种程序设计语言结构，采用了集中式的进程同步方法，提供了与信号量同样的功能，但更易于控制。 死锁一组相互竞争系统资源或进行通信的进程的永久阻塞 资源的分类 可重用资源：处理器、内存、设备、信号量 可消耗资源：I/O缓冲信息 死锁的条件必要条件 互斥 占用且等待 不可抢占 一次只有一个进程可以使用资源 进程等待其他资源时，继续等待已经占用的资源 不能强行抢占其他进程已经占用的资源 充分条件 循环等待 死锁的解决 预防死锁所施加的限制条件较严格，可能会导致系统资源利用率和系统吞吐量降低。（设置某些条件，去破坏产生死锁的四个必要条件中的一个或几个） 避免死锁所施加限制条件较宽松，可获得较高的资源利用率和系统吞吐量，有利于进程的并发执行。（在资源的动态分配过程中，用某种方法去防止系统进入不安全状态） 死锁的预防防止死锁产生条件的发生。 间接方法：防止三个必要条件中的任何一个 防止互斥：互斥不能禁止 防止占用且等待：一次申请所有资源 防止不可抢占：如果申请资源时被拒绝，就释放原占用资源，或者OS要求释放 直接方法：防止循环等待，定义资源请求序列，进程对资源的请求按资源类型的序号线性提出。 死锁的避免允许必要条件，分配决策保证不产生死锁 银行家算法 安全序列：按照一个资源分配序列不会产生死锁的序列。 安全状态：至少存在一个安全序列是所有进程能运行结束。不安全状态不一定是死锁状态。 实质在于：避免系统进入不安全状态 进程必须事先声明每个进程的请求最大资源 死锁的检测和解除不限制资源访问，不约束进程的行为，检测死锁的存在并尝试解除。 死锁检测算法跟银行家算法一样，不同的是死锁的预防是一种保守的策略，所以如果预分配进入不安全状态，就不分配，虽然不安全状态是可以通过释放资源进入安全状态的。但是对于死锁的检测，如果当前已经是不安全状态了，就是死锁了，需要进行解除。 资源分配图化简 找出全部请求都能满足的进程节点，删除该进程的所有请求边和分配边 重复，如果所有进程都鼓励，则不存在死锁，这种图成为可完全化简图 解除死锁撤销进程、回退、抢占","link":"/2019/12/24/%E6%93%8D%E7%BA%B5%E7%B3%BB%E7%BB%9F%E7%AC%94%E8%AE%B0%E2%80%94%E8%BF%9B%E7%A8%8B%E7%AE%A1%E7%90%86/"},{"title":"模型压缩、裁剪、量化","text":"模型压缩、裁剪、量化 压缩算法将所有权重都表示为2的幂次方形式，参考IQN算法 将IQN所得的训练权重，用4bit形式表示（基于数据码本） IQN算法 量化背景量化一般分两种形式，一种是训练后量化，指的是训练后的模型中的权重从float32量化到int8，并以int8形式保存，实际推理时，还需要反量化为浮点数运算。另一种时训练时量化，前向传播时，采用量化后的权重和激活值，反向传播过程仍对float类型权重梯度下降，推理时全部使用int8计算。 深度神经网络主要计算是浮点数之间的乘加运算，在FPGA程序中可以利用移位计算代替乘法计算，做到用少量的逻辑资源实现，提高FPGA计算能力，降低功耗。 对激活值进行量化，可以将卷积运算通过移位来完成。 将FP32的激活值量化到int8范围内-128~127之间（char类型）。 特征图量化方法 求一组数据最大值 $max_a = max(abs(T_a))$，a表示activations，T表示张量 求量化系数$Q_a = round(log_2(128/max_a))$ 因此量化后的数据可以表示为$a_{int8} = round(2^{Q_a}.a_{fp32})$，这样$a_{int8}$的最大值就是128 则卷积计算可以表示为： $\\left[a_{i n t 8}\\right]{2}=\\sum\\left[a{i n t 8}\\right]{1} * f i l t e r * 2^{-Q{a_{1}}} * 2^{Q_{a_{2}}}$ $\\left[a_{i n t 8}\\right]{2}=\\sum\\left[a{i n t 8}\\right]{1} * 2^{-n} * 2^{-Q{a 1}} * 2^{Q_{a 2}}$ $[a_{int8}]2$是量化后输出层的值，$[a{int8}]_1$是输入层的值 假设压缩后的weights表示为： $weights = (-1)^s*2^m$ 量化后的feature_map表示为： $Qfeature = feature*2^{-Q}$ 假设原来feature map的通道数为n，weight大小为k*k，则卷积可以表示为： $result =\\left(\\sum_{i=1}^{N} \\sum_{j=1}^{k * k}\\right. feature [i][j] * weight \\left.[i][j]\\right)+ bias$ 代入后可表示为：$Qresult * 2^{Q 2}=\\left(\\sum_{i=1}^{N} \\sum_{j=1}^{k * k}\\right.Qfeature \\left.[i][j] * 2^{Q 1} *(-1)^{s} * 2^{m}\\right)+bias $ 因此：$Qresule = \\sum_{i=1}^{N } \\sum_{j=1 }^{k * k} Q \\text { featur } e[i][j] * 2^{Q 1-Q 2} (-1)^{s} * 2^{m} + bias2^{-Q2}$ 上式前面那一部分可以表示成以为运算： $Qresult_part=\\sum_{i=1}^{N} \\sum_{j=1}^{k * k}(Qfeature[i][j] \\ll(Q 1-Q 2+m)) *(-1)^{s}$","link":"/2020/12/28/%E6%A8%A1%E5%9E%8B%E5%8E%8B%E7%BC%A9%E3%80%81%E8%A3%81%E5%89%AA%E3%80%81%E9%87%8F%E5%8C%96/"},{"title":"汇编语言笔记","text":"学oranges时的记录。 org是origin的缩写，告诉汇编程序，在开始执行的时候，将某段机器语言装载到内存中的哪个地址，如：org 07c00h db 声明字节（declare byte）如：BootMessage: db \"Hello, OS world!\" cs代码段寄存器 ds数据段寄存器 es附加段寄存器","link":"/2021/03/29/%E6%B1%87%E7%BC%96%E8%AF%AD%E8%A8%80%E7%AC%94%E8%AE%B0/"},{"title":"熵值法用于特征剔除","text":"熵是对不确定性的一种度量，信息量越大，不确定性越小，熵越小。当用熵值判断某个指标的离散程度，指标的离散程度越大，该指标对综合评价的影响越大。 熵值越小，指标的离散程度越大，该指标对综合评价的影响 (即权重) 越大。 问题背景mcm2012A 葡萄酒评价，给出了葡萄酒的大量指标，希望将影响葡萄酒质量的指标数量减小。 步骤step1:初始数据矩阵$x = (x_{ij}){m \\times n}$，表示第i号葡萄酒的第j项指标的数值，先将各指标归一化处理，然后计算$x{ij}$在第j项指标的比重$p_{ij}$: $$p_{ij} = x_{ij}/\\sum_{i=1}^m x_{ij}$$ step2:计算第j各指标的熵值$e_{j}$: $$e_{j} = -k\\sum_{i=1}^mp_{ij} \\ln p_{ij}$$ 其中 k &gt; 0 , $e_j&gt;=0$,当$x_{ij}$对于给定的$j$全部相等时，$e_{j}$有最大值，此时: $$p_{ij} = \\frac1 m$$ $$e_j(x)|{max}=-k\\sum{i = 1}^m \\frac 1 m \\ln \\frac 1 m=k\\ln m$$ 令 $k = \\frac1 {\\ln m}$,则有$0&lt;=e_{j}&lt;=1$. step3:定义差异性系数： $g_{j} = 1-e_{j}$，该值越大，说明该指标越重要。 熵值越小，指标的离散程度越大，该指标对综合评价的影响 (即权重) 越大。 step4:定义权重：$a_{j} = g_{j}/\\sum_{i = 1}^mg_{j}$ 可用于评价问题的客观赋权。 step5:对权值排序后，从大到小可以进行累加求和，得到前$m$个成分的累计贡献率$G(m) = \\sum_{j=1}^ma_{j}$,取前80%即可反应大部分指标的影响，从而达到指标剔除的效果。 适用范围熵值用于赋权时，一般构建两级评价体系，上层可能需要结合专家经验来构建，而底层的指标分的比较细，权重比较难确定，这种情况下采用熵值法比较合适。 该方法没有考虑指标与指标间的相关性。 确定权重前需要确定指标对目标得分的影响方向，对非线性的指标要进行预处理或者剔除。 参考代码123load shang_datasInd=[1 1 1 1 2]; %指定各指标的正向or负向[S,W]=shang(X,Ind) 12345678910111213141516171819202122232425262728function [s,w]=shang(x,ind)%实现用熵值法求各指标(列）的权重及各数据行的得分%x为原始数据矩阵, 一行代表一个样本, 每列对应一个指标%ind指示向量，指示各列正向指标还是负向指标，1表示正向指标，2表示负向指标%s返回各行（样本）得分，w返回各列权重[n,m]=size(x); % n个样本, m个指标%%数据的归一化处理for i=1:m if ind(i)==1 %正向指标归一化 X(:,i)=guiyi(x(:,i),1,0.002,0.996); %若归一化到[0,1], 0会出问题 else %负向指标归一化 X(:,i)=guiyi(x(:,i),2,0.002,0.996); endend%%计算第j个指标下，第i个样本占该指标的比重p(i,j)for i=1:n for j=1:m p(i,j)=X(i,j)/sum(X(:,j)); endend%%计算第j个指标的熵值e(j)k=1/log(n);for j=1:m e(j)=-k*sum(p(:,j).*log(p(:,j)));endd=ones(1,m)-e; %计算信息熵冗余度w=d./sum(d); %求权值ws=100*w*p'; %求综合得分 12345678910111213141516171819function y=guiyi(x,type,ymin,ymax)%实现正向或负向指标归一化，返回归一化后的数据矩阵%x为原始数据矩阵, 一行代表一个样本, 每列对应一个指标%type设定正向指标1,负向指标2%ymin,ymax为归一化的区间端点[n,m]=size(x);y=zeros(n,m);xmin=min(x);xmax=max(x);switch type case 1 for j=1:m y(:,j)=(ymax-ymin)*(x(:,j)-xmin(j))/(xmax(j)-xmin(j))+ymin; end case 2 for j=1:m y(:,j)=(ymax-ymin)*(xmax(j)-x(:,j))/(xmax(j)-xmin(j))+ymin; endend 参考机器学习中的信息论http://saili.science/2017/09/15/entropy-method/","link":"/2019/08/16/%E7%86%B5%E5%80%BC%E6%B3%95%E7%94%A8%E4%BA%8E%E7%89%B9%E5%BE%81%E5%89%94%E9%99%A4/"},{"title":"目标文件里有什么","text":"目标文件是源码编译后未链接的中间文件，目标文件里面存放的是什么？怎么存储的？实际上目标文件、可执行文件、动态链接库、静态链接库的存储都几乎是一样的。静态链接库是多个目标文件的文件包，加上一些索引。 目标文件的格式可执行文件格式：windows下PE（portable executable），linux下是ELF（executable linkable format），这两种都是COFF(commin file format)的变种。 ELF文件分四类： Linux下可以用file 文件名来查看文件类型 目标文件什么样 文件头、代码段、数据段、bss段 文件头描述文件信息的，是否可执行、是静态链接还是动态链接等等，还有一个段表，描述各个段在文件中的偏移位置。 代码段机器代码 数据段已经初始化的全局变量和局部静态变量 bss段未初始化的全局变量和局部静态变量，但是并不给该段的数据分配空间，只是记录数据所需空间的大小。 因为他们默认值都是0，存放数据0是没有必要的 为什么要分成指令和数据两种段 便于虚存权限的管理，数据可读写，指令只读 局部性原理，提高对指令和数据的缓存命中率 系统中运行多个该程序的副本，可以实现共享，如指令，图标，文本，特别是有动态链接后，可以大大节省内存。","link":"/2021/04/19/%E7%9B%AE%E6%A0%87%E6%96%87%E4%BB%B6%E9%87%8C%E6%9C%89%E4%BB%80%E4%B9%88/"},{"title":"目标跟踪-用高斯混合模型进行前景建模","text":"考虑图像的目标区域和背景区域，背景区域和目标区域存在一定的灰度差异，那么图像的灰度直方图就会呈现 双峰-谷的状态，一个峰对应目标，一个峰对应背景的灰度中心。将直方图看成是多个高斯分布的叠加，这就是高斯混合模型（GMM）。 基本思路目标跟踪分为两步： 检测每一帧运动的obj 实时的将检测到的匹配到一个obj 参考资料https://ww2.mathworks.cn/help/vision/ug/motion-based-multiple-object-tracking.html;jsessionid=ab41315b72c7d8abbb639d91c0c1?s_tid=gn_loc_drop https://blog.csdn.net/SMUEvian/article/details/70216765","link":"/2021/04/07/%E7%9B%AE%E6%A0%87%E8%B7%9F%E8%B8%AA-%E7%94%A8%E9%AB%98%E6%96%AF%E6%B7%B7%E5%90%88%E6%A8%A1%E5%9E%8B%E8%BF%9B%E8%A1%8C%E5%89%8D%E6%99%AF%E5%BB%BA%E6%A8%A1/"},{"title":"算法设计与分析","text":"复习大纲 基础知识引论判断性问题和优化问题NPC问题一般是判定性问题 分治法逆序对一个数的序列中排在前面的数比排在后面的数要大的话则称为一对逆序，即$i &lt; j , a [ i ] &gt; a [ j ]$ 问下面这个序列中存在多少对逆序：5,4,8,10,2 考虑，将序列L拆分成两半A、B，考虑现在逆序对存在与两个，A内部的，B内部的，AB之间的。先假设，可以通过递归的方式找到AB内部的逆序对，然后AB内部如何交换都不会影响AB间逆序对的结果。现在问题就是找AB之间的逆序对。 如果AB是有序的，我们对于所有A中的元素$a_i$求出它在B数组所有插入的位置j，(j前面的就是数组B中比$a_i$小的数，也就是逆序)，然后对j求和即可。这个过程就是归并排序的规程。 12345678910111213141516171819202122232425262728293031#include &lt;bits/stdc++.h&gt;using namespace std;const int maxn = 5e5+10;int a[maxn], temp[maxn];long long res = 0; // 记录逆序对数目void mergeSort(int left, int right) { if(left&lt;right) { int mid = (left+right)/2; mergeSort(left, mid); mergeSort(mid+1, right); int index = 0, i = left, j = mid+1; while(i&lt;=mid &amp;&amp; j&lt;=right) { if(a[i]&lt;=a[j]) temp[index++] = a[i++]; else { temp[index++] = a[j++]; res += mid-i+1; // 当a[i]&gt;a[j]时形成逆序对，数目为左子序列长度减去i再加上1 } } while(i&lt;=mid) temp[index++] = a[i++]; while(j&lt;=right) temp[index++] = a[j++]; for(int i = 0; i &lt; index; i++) a[left+i] = temp[i]; }}int main() { int n; cin &gt;&gt; n; for(int i = 0; i &lt; n; i++) cin &gt;&gt; a[i]; mergeSort(0, n-1); cout &lt;&lt; res &lt;&lt; endl; return 0;} 最近点对给定$n$个二维平面上的点，求一组欧几里得距离最近的点对。 首先暴力就是枚举两两点间的距离，取最小值，复杂度$O(n^2)$ 对点集$S$进行拆分，分两部分求最近点对$L,R$，设L和R中最小点对距离为l,r，LR间最小距离为d,则归并需要求解min(l,r,d) 如何合并两个集合找到最小点对距离 设δ = min(l,r)，则点集合间最小点对只可能存在分界线附近范围内： 对于L范围内的点p，只选取R范围内长为2δ，宽为δ的点进行计算 主方法求解递归关系式 定理4.1（主定理） 令 $a≥1$ 和 $b&gt;1$ 是常数，$f(n)$ 是一个函数，$T(n)$ 是定义在非负整数上的递归式： $T(n) = aT(n/b) + f(n)$ 那么$T(n)$有如下渐进界： 若对某个常数 $ε&gt;0$ 有$ f(n) = O(n^{log_ba}-ε)$，则$ T(n) = Θ(n^{log_ba})$ 。 若 $f(n) = Θ(nlog_ba)$，则$ T(n) = Θ(nlog_ba lgn)$ 。 若对某个常数$ ε&gt;0 $有 $f(n) = Ω(nlog_ba+ε)$，且对某个常数 $c&lt;1$ 和所有足够大的 $n$ 有 $af(n/b) ≤ cf(n)$，则 $T(n) = Θ(f(n))$ 。 动态规划DP适合求解什么问题 DP问题的一般形式是求最值，最长递增子序列，最小编辑距离 可以通过穷举得到结果，但是存在最优子结构，子问题间相互独立 最优子结构作为dp问题的必要条件，遇到最值问题，可以往DP想 最优子结构从子问题的最优结果推出更大规模问题的最优结果 找最优子结果的过程，其实就是证明状态转移方程正确性的过程。 思路 找状态和选择 明确dp数组的含义 根据选择，中出状态转移的逻辑 DP数组的遍历方向 遍历过程中，所需的状态必须是已经计算出来的 遍历的重点是存储结果的位置 带权区间调度问题 一系列工作，每个工作有自己的：开始时间、结束时间、权值，求一组工作子集，使得工作时间不重叠，且总的权值最大。 $dp[i]$代表第i个区间的最大权重和，则$dp[i] = max(dp[i-1], interval[i].w+dp[interval[i].p]);$ 其中 12345struct Interval{ int s, f, w; // 区间开始时间、结束时间和权重 int id, p; // 区间编号和该区间前一个不冲突的区间.是[1,i-1]这i-1个区间内与i不冲突的结束时间最接近i开始时间的区间}interval[maxn]; 最大子数组和给定一个整数数组 nums ，找到一个具有最大和的连续子数组（子数组最少包含一个元素），返回其最大和。 https://leetcode-cn.com/problems/maximum-subarray/$dp[i] = max(nums[i], nums[i] + dp[i - 1])$ $dp[i]$代表以i结尾的最大连续子数组 最后求完dp数组，还需要再遍历一次数组，找到最大值返回 最大子矩阵和01背包找零钱给你一个整数数组 coins 表示不同面额的硬币，另给一个整数 amount 表示总金额。求凑硬币的组合数。 每个物品数量无限，就是完全背包问题 状态、选择状态：背包的容量、可选择的物品 选择：装进背包、不装进背包 dp数组有两个状态，因此需要一个二维的dp数组 定义dp[i][j]：只使用前i个物品，当背包容量为j时，可以装满背包的方法 状态转移逻辑 不把第i个物品装入背包：$dp[i][j] = dp[i-1][j]$ 把第i个物品装入了背包：$dp[i][j] = dp[i][j-coins[i-1]]$ 因为要求方案数：$dp[i][j] = dp[i-1][j] + dp[i][j-coins[i-1]]$ 编辑距离给你两个单词 word1 和 word2，计算出将 word1 转换成 word2 所使用的最少操作数 。(可以用来衡量两个串的相似度) 可以对一个单词进行如下三种操作： 插入一个字符删除一个字符替换一个字符 https://leetcode-cn.com/problems/edit-distance/ 解决两个串的dp问题，一般都是用两个指针$i,j$分别指向两个字符串的最后，一步步往前走，缩小问题的规模。 编辑距离中，不同操作代价可能不同，可以自己定义插入或删除一个字符的代价为$a$，替换一个字符的代价为$b$。 1234567891011121314151617181920212223242526int minDistance(String s1, String s2) { int m = s1.length(), n = s2.length(); int[][] dp = new int[m + 1][n + 1]; // base case for (int i = 1; i &lt;= m; i++) dp[i][0] = i; for (int j = 1; j &lt;= n; j++) dp[0][j] = j; // 自底向上求解 for (int i = 1; i &lt;= m; i++) for (int j = 1; j &lt;= n; j++) if (s1.charAt(i-1) == s2.charAt(j-1)) dp[i][j] = dp[i - 1][j - 1]; else dp[i][j] = min( dp[i - 1][j] + 1,//插入 dp[i][j - 1] + 1,//删除 dp[i-1][j-1] + 1//替换 ); // 储存着整个 s1 和 s2 的最小编辑距离 return dp[m][n];}int min(int a, int b, int c) { return Math.min(a, Math.min(b, c));} 高楼扔鸡蛋时间复杂度动态规划的时间复杂度是伪多项式时间 伪多项式时间：若一个数值算法的时间复杂度可以表示为输入数值N的多项式，则称其时间复杂度为伪多项式时间。 对背包问题来说，假设n为物品数量，W为背包容量，那么算法的时间复杂度并不是O（nW）,因为n是输入规模，而W并不是输入规模，W是背包的容量，他只输入一个值，这个值的规模应该是这个数所占用的二进制位数。 所以背包问题还是NPC的。 贪心贪心的本质是选择每一阶段的局部最优，从而达到全局最优 贪心求解什么问题手动模拟下，感觉局部最优是可以推出全局最优，找不到反例，可以试试贪心 非要证明的话考虑数学归纳法和反证法 找零钱假设硬币有5种面值，$1 , 5 , 10 , 25 , 100 $，每种硬币无限个，如何用最少数量的硬币来凑出给定数值M。这种面值的硬币组合，可以贪心求解。 因为每个面值都能被比他小的面值整除。 分发饼干https://leetcode-cn.com/problems/assign-cookies/ 对每个孩子$ i$，都有一个胃口值 $g[i]$，这是能让孩子们满足胃口的饼干的最小尺寸；并且每块饼干$ j$，都有一个尺寸 $s[j]$ 。如果 $s[j] &gt;= g[i]$，我们可以将这个饼干 $j$ 分配给孩子$ i$ ，这个孩子会得到满足。你的目标是尽可能满足越多数量的孩子，并输出这个最大数值。 摆动序列https://leetcode-cn.com/problems/wiggle-subsequence/ 给一个序列，找出这个序列的最长摆动子序列长度 思路1 贪心贪心策略下，局部最优：删除单调坡度上中间的节点，整体最优：整个序列有最多的局部峰值，从而达到最长摆动序列。 所以统计峰值就可以了，删除都不用做 思路2 DP状态：数组下标，峰谷 选择：当前数作为峰时，以前面哪个作为谷。当前数为谷时，以前面哪个作为峰 1234567891011dp[0][0] = dp[0][1] = 1;for (int i = 1; i &lt; nums.size(); ++i) { dp[i][0] = dp[i][1] = 1; for (int j = 0; j &lt; i; ++j) { if (nums[j] &gt; nums[i]) dp[i][1] = max(dp[i][1], dp[j][0] + 1); } for (int j = 0; j &lt; i; ++j) { if (nums[j] &lt; nums[i]) dp[i][0] = max(dp[i][0], dp[j][1] + 1); }}return max(dp[nums.size() - 1][0], dp[nums.size() - 1][1]); 最大子序和给定一个整数数组 nums ，找到一个具有最大和的连续子数组（子数组最少包含一个元素），返回其最大和。 思路1 贪心局部最优：连续和为负数时就立刻放弃，重新计算连续和 全局最优：选择最大的连续和 思路2 DPdp[i] = max(dp[i - 1] + nums[i], nums[i]) 以i结尾的最大连续子数组的和 result = max(dp) 网络流 最大流问题和最小割问题及其算法，增广链添加的过程 概念最大流源点s，到汇点t的最大流量 最小割割是一种点的划分方式，比如划分为点集S,T，割的容量指，从S到T的边的容量之和，最小割是让这个容量最小，最小割并不唯一。 最大流最小割定理最小割的容量等于最大流的流量 任意流和割对于任意流f，任意割（A,B），流的大小为流出A的流量与流入A的流量之差。 NP完备性理论多项式规约假设已有解决一个问题的子程序，利用他可以在多项式时间内解决另一个问题的规约方法。 问题X可以规约到问题Y： h(X) = g(f(Y))，其中g(.)是多项式的，不考虑f子程序运行所用的时间。 常见规约问题基本概念 多项式时间 多项式是指解决问题的时间随输入规模呈多项式的变化 考虑一个问题，验证一个团是不是最大团是多项式的吗？答案不是 比如，当前团为k，那枚举k+1的团是否存在并不是多项式的，虽然他的复杂度是$O(n^{k})$，但是这里k也是输入的规模 P问题：能在多项式时间内解决的问题 NP问题：能在多项式时间内验证的问题 NPC问题：首先是NP问题，所有NP问题都可以规约到他 假设要证明问题$Y$是一个$NP-completeness$问题 首先证明问题$Y$是一个$NP$问题； 选择一个已知的$NP-completeness$问题$X$； 将问题$X$多项式归约到问题$Y$，即证明。（即说明了求解问题$Y$不比求解问题$X$简单） NP-Hard问题：NP-hard满足NPC问题的第二条定义但不一定满足第一条，np-hard的意思就是所有的np问题都不比它简单 理一下：首先，N，NP，npc都是指判定性问题，NP-hard可能 独立集：图 G 中两两互不相邻的顶点构成的集合 团：是图中顶点的一个子集，这个子集中的点都相互连接（无向图的最大团==该无向图补图的最大独立集） 点覆盖：无向图G的一个点集，使得该图中所有边都至少有一点端点在该集合内 集合覆盖：有n个子集，这几个子集的并集作为全集，找到一个最小的子集组合，使得他们的并集等于全集 规约 A要规约到B 构造图 G ，存在问题 A 的解集； 在图 G 基础上，构造图 G’（常添加边或点），使得问题 A 的解集能反应在 G’ 中问题 B 的解集（注意两个问题解集的规模 k 一定要有确定的联系）； 图 G 中存在问题 A 的解集 S，当且仅当图 G’ 中存在问题 B 的解集 S’ ； 规约的正确性，需双向证明。 独立集到点覆盖S是独立集，则V-S是顶点覆盖 顶点覆盖到集合覆盖构造点覆盖的顶点是集合覆盖问题中的子集和，顶点覆盖的元素相当于集合覆盖中子集和的元素。 3-SAT到独立集 顶点覆盖到支配集有向哈密尔顿到无向哈密尔顿 给定一个有向图G，需构造无向图G’ 有向图中的一个顶点拆成三个，一个接受入度，一个接收出度，则G‘中的哈密顿环按蓝黑白或者白黑蓝的顺序，去掉蓝和白就是有向图中的哈密顿环。 3-sat到有向哈密尔顿环？？？ 子集和到分区问题 给定一个集合 S = {w1 , w2 , … , wn}，子集和为 W，需构造集合 S’，使得集合 S 存在一个子集之和为 W，当且仅当集合 S’ 存在一个 Partition 构造分区问题集合$ S’ = {v1 , v2 , … , vn, vn+1, vn+2}$，其中 $v1 = w1，v2 = w2, … , vn = wn，vn+1 = 2∑wi - W，vn+2 = ∑wi + W$ 子集和到背包问题 给定一个集合 S = {w1 , w2 , … , wn}，子集和为 W，需构造集合S‘，使得子集和问题有解当且仅当S’存在一个背包实例 构造背包实例，第i个物品的重量和价值等于wi，背包的U=V=W 自规约 设该判断算法为 A ，利用算法 A 判断出图中存在…(大小为k的…)； 删除一条边或点(看具体是边集还是点集的问题)，对删除边/点后的图运行判断算法 A ； 若图中还存在…(大小为k的…)，则从图中彻底删除该边/点；若不存在，则把该边/点加入集合 S 中； 对所有的边/点调用算法 A 执行上述操作，最终得到的集合 S 就是求解问题的解。 点覆盖问题哈密顿环问题3-color问题最长路问题近似算法负载均衡带权顶点覆盖问题顶点覆盖要求图中所有边至少有一个端点在集合内，带权顶点每个点有一个权值，要求这个集合的权值之和最小 2倍近似算法-竞价法 二倍近似证明： 引理： 对于一个任意合法的竞价边权的和，都小于等于一个点覆盖的点权和 则， S里的邻边边权和&lt;=所有点的邻边边权和 所有的点邻边边权和=2倍的边权和 整数规划模型参考https://zhuanlan.zhihu.com/p/106624574 https://chengyong.blog.csdn.net/article/details/100806815","link":"/2021/11/29/%E7%AE%97%E6%B3%95%E8%AE%BE%E8%AE%A1%E4%B8%8E%E5%88%86%E6%9E%90/"},{"title":"算法题","text":"刷题 二维数组中的查找在一个 n * m 的二维数组中，每一行都按照从左到右递增的顺序排序，每一列都按照从上到下递增的顺序排序。请完成一个高效的函数，输入这样的一个二维数组和一个整数，判断数组中是否含有该整数。 示例: 现有矩阵 matrix 如下： 1234567[ [1, 4, 7, 11, 15], [2, 5, 8, 12, 19], [3, 6, 9, 16, 22], [10, 13, 14, 17, 24], [18, 21, 23, 26, 30]] 给定 target = 5，返回 true。 给定 target = 20，返回 false。 123//从右上角开始查找，左下角也是可以的。//为什么能这样查？如果当前元素大于目标值，往下是不可能查找到的，只能往左。如果当前元素小于目标值，左边的元素也都小于目标值，只能向下。//时间复杂度O(m+n),空间复杂度O(1) 从头到尾打印链表输入一个链表的头节点，从尾到头反过来返回每个节点的值（用数组返回）。 12输入：head = [1,3,2]输出：[2,3,1] 123//用栈，先压栈，再pop到数组//递归法//也可以先反转过来，再输出 重建二叉树输入某二叉树的前序遍历和中序遍历的结果，请重建该二叉树。假设输入的前序遍历和中序遍历的结果中都不含重复的数字。 12345678910例如，给出前序遍历 preorder =&nbsp;[3,9,20,15,7]中序遍历 inorder = [9,3,15,20,7]返回如下的二叉树： 3 / \\ 9 20 / \\ 15 7 1","link":"/2021/04/01/%E7%AE%97%E6%B3%95%E9%A2%98/"},{"title":"红黑树","text":"红黑树什么用 查找key-value，查找性能快 服务器管理连接socketfd（key）与客户端id（value）的映射关系 内核内存管理 通过中序遍历，得到顺序结果 进程调度，就绪队列 红黑树性质 5条 每个节点是红的或黑的 根节点是黑的 每个叶子节点是黑的 如果一个节点是红的，那他的两个儿子是黑的 对每个节点，从该节点到其子孙节点的所有路径上的包含相同数目的黑节点（黑高相同）","link":"/2020/12/16/%E7%BA%A2%E9%BB%91%E6%A0%91/"},{"title":"线性代数概念复习","text":"复习了一些简单的概念理解 矩阵特征值和特征向量 相似矩阵 同一个线性变换，在不同基下的矩阵，称为相似矩阵。","link":"/2020/06/14/%E7%BA%BF%E6%80%A7%E4%BB%A3%E6%95%B0%E6%A6%82%E5%BF%B5%E5%A4%8D%E4%B9%A0/"},{"title":"编译和链接","text":"参考《程序员的自我修养——链接、装载与库》第二章 gcc hello.c 做了什么预编译（预处理）、编译、汇编、链接 预编译源代码.c文件和相关头文件，被预编译成一个.i文件 预编译要处理以“#”开始的预编译指令 删除#define，展开宏定义 处理条件预编译指令，如#if、#ifdef、#elif、#else、#endif 处理#include，被包含的文件插入到预编译指令的位置，这个过程可能是递归的 删除注释 添加行号和文件名标识，便于调试，编译出错了也能显示行号 保留#pragma编译器指令 编译把预处理玩的文件进行一系列词法分析、语法分析、语义分析、代码优化，得到相应的汇编代码文件hello.s 汇编将汇编码变成机器可以执行的指令，根据汇编指令和机器指令的对照表一一翻译就行 得到.o文件（目标文件） 链接生成.out目标文件 编译器做了什么参考编译原理，这里不多记录 前端（机器无关）词法分析、语法分析、语义分析、中间代码生成 后端（机器相关）目标代码生成、目标代码优化 链接器静态链接每个源代码单独编译，按需组装，这个组装模块（目标文件）的过程就是链接。 链接的主要过程：地址和空间分配、符号决议、重定位 各模块之间的相互引用关系，比如函数、变量地址的修正 可执行文件被execve系统调用使用。用来描述进程状态机重置后的状态。状态：寄存器和内存（地址空间） 寄存器由ABI规定，OS负责设置。地址空间：二进制文件和ABI共同决定。其他调试信息，coredump信息。 Binutils生成可执行文件 ld, as ar, ranlib 分析可执行文件 objcopy/objdump/readelf addr2line, size, nm","link":"/2021/04/14/%E7%BC%96%E8%AF%91%E5%92%8C%E9%93%BE%E6%8E%A5/"},{"title":"网络计划","text":"基本要点 双代号网络图绘制 网络计划图时间参数计算 寻找最短工期和关键路线的方法 网络优化中的时间-费用优化方法，即最低成本 双代号网络计划图 节点：一个事项，指一个或若干个工序的开始和结束，相邻节点之间只能有一条箭头连接，但是可以用虚箭头连 箭头：表示工作，上面是工作名，下面是工作时间，不能形成缺口和回路，终点和起始点都有只有一个 圆圈里的数字是节点编号，编号从左到右，尾小于头 先行工序和后继工序先行工序表示紧排在本工序之前的工序，且开始或者完成后才能开始本工序 后继工序表示紧排在本工序之后的工序，且本工序开始或完成后，才能做的工序。 虚工序不占用时间和不消耗人力资金的资源，只为了表示相邻工序之间的逻辑关系而虚设的工序。 时间参数计算 完成项目所需要的最少时间 每个工序的开始和结束时间 关键路线及其相应的关键工序 非关键工序在不影响工程完成的前提下，其开始与结束时间可以推迟多久。 关键路线完成各个工序所需要时间最长的路线（主要矛盾线），该路线上的工序是关键工序。 就是说在这条路线上，所有的工序是需要时间最多的，这些工序没有结束之前，其他工序是不可能做完的。 求解方法：工序计算法 网络计划优化 工期优化 时间-费用优化 资源优化 资料网络计划的多目标优化 http://tow.cnki.net/kcms/detail/detail.aspx?filename=2001011640.nh&amp;dbcode=CRJT_CMFD&amp;dbname=CMFDTOTAL&amp;v=","link":"/2019/08/01/%E7%BD%91%E7%BB%9C%E8%AE%A1%E5%88%92/"},{"title":"自定义应用层协议如何实现","text":"socket套接字位于应用层和传输层之间，基于socket编程可实现应用层协议为业务实现服务。 协议分类按编码方式 二进制协议，如tcp 明文的文本协议，如http，redis协议 混合协议（二进制+明文） 按协议边界 固定边界协议，能够明确知道协议报文的长度。便于解析，比如tcp 模糊边界协议，如http 要点大小端 大端：从高地址开始存 小端：从低地址开始存 图解 网络传输一般采用大端序，也被称为网络字节序 大小端取决与CPU的体系： 小端：x86、MOS Technology 6502、Z80、VAX、PDP-11 大端：Motorola 6800、Motorola 68000、PowerPC 970、System/370、SPARC（除V9外） 可配置：ARM、PowerPC（除PowerPC 970外）、DEC Alpha、SPARC V9、MIPS、PA-RISC及IA64的字节序是可配置的。 HTTP协议 模糊边界的明文文本协议 报文结构分为请求报文和相应报文，两种结构不一样。http报文本身是由多行数据构成字符串文本（用CR+LF作换行符，就是\\r\\n）。 报文组成：报文首部、报文主体（不一定有主体） 实例 Redis协议请求格式 命令本身也作为一个参数发送，如上图中的set 回复格式 状态回复：\"+\"开始，\"\\r\\n\"结尾的单行字符串，如+OK 错误回复：\"-\"开始，后面是错误类型 整数回复：\":\"开始+整数+\"\\r\\n\"结尾 批量回复：\"&amp;\"开始表示实际回复长度，如\"$6\\r\\nfoobar\\r\\n\" 多条批量回复：*表示回复条数，与请求格式类似。 一个实例用了固定边界+混合编码的策略，协议体用jsoncpp明文存储，引入魔数进行快速校验。 参考链接：https://segmentfault.com/a/1190000008740863 参考https://segmentfault.com/a/1190000008740863 https://zh.wikipedia.org/wiki/%E5%AD%97%E8%8A%82%E5%BA%8F http://redisdoc.com/topic/protocol.html 《图解HTTP》","link":"/2021/07/19/%E8%87%AA%E5%AE%9A%E4%B9%89%E5%BA%94%E7%94%A8%E5%B1%82%E5%8D%8F%E8%AE%AE%E5%A6%82%E4%BD%95%E5%AE%9E%E7%8E%B0/"},{"title":"运输问题","text":"典型背景：单一物资的运输调度问题 $$\\min z=\\sum_{i=1}^{m} \\sum_{j=1}^{n} c_{i j} x_{i j}$$ 所有运价的求和最小（一定有最优解） $\\left{\\begin{array}{c}{\\sum_{j=1}^{n} x_{i}=a_{i}, i=1,2, \\cdots, m} \\ {\\sum_{i=1}^{m} x_{n}=b_{j}, j=1,2, \\cdots, n} \\ {x_{i j} \\geq 0, i=1,2, \\cdots, m} \\ {j=1,2, \\cdots n}\\end{array}\\right.$ 约束： 产地i运到n个销地的运量总和等于产地i的产量 m个产地运到销地j的运量的总和等于销地j的销量","link":"/2019/08/09/%E8%BF%90%E8%BE%93%E9%97%AE%E9%A2%98/"},{"title":"进程与资源管理设计-操作系统实验","text":"UESTC操作系统课程实验：进程与资源管理器设计 实验环境本程序使用python语言实现，在Windows平台进行测试并与相关环境兼容。以下环境和包需要在运行程序前预先安装： Python 3 collections 运行demo 在命令行执行命令： python ./main.py 程序将会模拟shell终端读取输入命令： shell&gt; 可支持命令如下： 1234567891011-init-cr &lt;name&gt; &lt;priority&gt;(=1 or 2) // create process -de &lt;name&gt; // delete process-req &lt;resource name&gt; &lt;# of units&gt; // request resource-rel &lt;resource name&gt; &lt;# of units&gt; // release resource-to // time out查看进程状态和资源状态的命令-list ready //list all processes in the ready queue-list block // list all processes in the block queue-list res //list all available resources-pr &lt;name&gt; //print pcb information about a given process. 首先你需要先使用init命令初始化资源和创建init进程，该命令是必须的。 接下来你可以使用cr de req rel to等命令进行进程或资源的操作，并使用list命令查看就绪队列和阻塞队列的状态，使用pr命令打印指定进程的pcb信息，使用exit()命令退出shell。 enjoy! :happy: 代码简单说明定义PCB和RCB12345678910111213class PCB: def __init__(self,priority): self.res = {'R1': 0, 'R2': 0, 'R3': 0, 'R4': 0}#占用资源情况 self.status = \"ready\"#进程状态 self.parent = None#父进程 self.child = []#子进程 self.priority = priority#进程优先级 self.req = 0class RCB: def __init__(self,total): self.waitList = [] self.total = total#资源总量 self.num = total#当前资源可用量 进程管理函数包含： 创建进程create 进程销毁destroy 1234567891011121314151617181920212223242526272829303132333435363738def create(pid,priority,cPid): #pid为要创建进程的id,priority为要创建进程的优先级 #cPid为当前正在执行进程的id if(cPid!=None):#如果当前存在正在运行的进程 ready[cPid].child.append(pid)#则要创建的进程加入到当前进程的子进程列表里 pcb = PCB(priority)#初始化pcb对象，创建进程 pcb.parent = cPid#新进程的父节点为当前运行的进程 ready[pid] = pcb#将新进程加入到readylist中 scheduler()def destroy(pid):#要撤销的进程号 dict = {} dict.update(ready) dict.update(block)#dict维护了所有的进程记录，包括就绪态进程和阻塞态进程 p = dict[pid]#根据pid找到该pid对应的PCB对象 killTree(p,pid)#进行递归的销毁 scheduler()def killTree(p,pid):#要删除的PCB和pid dict = {} dict.update(ready) dict.update(block)#维护存储所有进程记录 for childPid in p.child:#遍历要删除的进程的子进程 killTree(dict[childPid],childPid)#递归删除 if pid in ready.keys():#如果该进程在readylist里 for rid in ready[pid].res.keys():#释放该进程占用的资源 if ready[pid].res[rid]!=0: release(rid,ready[pid].res[rid],pid) ready.pop(pid)#将该进程从readylist中删除 else:#如果该进程在blocklist中 temp = block[pid].res#找到该进程在blocklist中存储的pcb for rid in temp.keys():#遍历该进程占用的资源进行释放 if pid in block.keys() and temp[rid]!=0: release(rid,block[pid].res[rid],pid)#释放资源 for rid in temp.keys():#在rcb的waitlist中移除该进程 if pid in res[rid].waitList: res[rid].waitList.remove(pid) block.pop(pid)#把该进程从blocklist中删除 资源管理函数包含： 资源的请求函数request 资源释放函数relResource，内部调用函数release 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748def request(cPid,rid,n): #参数含义： #cPid：当前正在执行的进程id #rid：请求资源的id #n:请求资源的数量 if(res[rid].num&gt;=n):#如果当前可用资源数量大于请求量 res[rid].num -=n#则进行资源的分配，更新可用资源数 ready[cPid].res[rid] +=n#p占有的资源数更新 print(\"process \"+cPid+\" requests \"+str(n)+\" \"+rid);#打印提示信息 else:#如果剩余资源数不足以分配 if(n&gt;res[rid].total):#如果大于资源总量，提示error，拒绝分配 print(\"error\") return ready[cPid].status = \"blocked\"#请求量小于总量但大于可分配量，该进程转为阻塞态 block[cPid] = ready[cPid]#将该进程从readylist移动到blocklist block[cPid].req = n#记录阻塞时，请求的资源量 ready.pop(cPid)#将该进程从readylist中移除 res[rid].waitList.append(cPid)#在要请求的资源的waitlist中加入该进程 scheduler() print(\"process \"+cPid+\" is blocked.\")#打印提示信息 def relResource(pid,rid,n): #print(list(ready.keys())[0]) cP = ready[list(ready.keys())[0]]#获取当前正在执行的进程PCB cP.res[rid] = max(cP.res[rid]-n,0)#更新该进程的资源占用情况 release(rid,n)#进行资源的释放 def release(rid,n,pid):#针对一种资源的释放#参数：rid要释放资源的id#n:释放的数量#pid：释放该资源的进程id rcb = res[rid]#获取rid对应的rcb对象 print(\"release \"+rid)#打印提示信息 res[rid].num +=n#资源的可以量增加 pop = []#初始化一个空列表，记录可以从阻塞态转为就绪态的进程号 for id in res[rid].waitList:#检查block_list里的进程能否ready，遍历该资源的waitlist if block[id].req&lt;=res[rid].num and id!=pid:#如果可以转为ready态 res[rid].num -=block[id].req#更新资源的剩余量 pop.append(id)#记录可以转为就绪态的进程号 for id in pop:#遍历刚刚得到的可以转化为就绪态的进程号 block[id].req = 0#请求量更新 ready[id] = block[id]##从blocklist中移动到readylist block.pop(id) res[rid].waitList.remove(id)#将该进程从waitlist中移除 print(\"wake up process \" + id)#打印提示信息 ready[id].status = \"ready\"#更新进程状态 进程调度与时钟中断函数包含： 调度函数scheduler 抢占函数preempt 时钟中断函数timeOut 12345678910111213141516171819202122232425262728293031323334353637383940def scheduler(): i = 0 l2 = [];l1 = [];l0 = []#初始化三个列表，分别记录2 1 0三个优先级的进程id for pid in ready:#遍历readylist if i==0:#获取当前正在执行的进程id和PCB cPid = pid cPCB = ready[pid] i +=1 if(int(ready[pid].priority)==0): l0.append(pid) elif(int(ready[pid].priority)==1): l1.append(pid) elif(int(ready[pid].priority)==2): l2.append(pid) list = l2+l1+l0#将三个列表按优先级顺序拼接，此时list中的第一个进程就是最高优先级且根据RR原则将要调度的进程 if(len(list)==0):#如果列表为空，则结束调度 return hpP = ready[list[0]]#highest priority process获取最高优先级且根据RR原则将要调度的进程 if(int(cPCB.priority)&lt;int(hpP.priority) or cPCB.status!=\"running\" or cPCB==None):#如果满足抢占条件 preempt(cPid,list[0])#则进行抢占 else: print(\"process \"+cPid+\" is running\") def preempt(oldId,newId): #参数： #oldId：原先正在执行的进程id #newId:要抢占cpu的进程id ready.move_to_end(oldId)#将原进程移动到readylist的队尾 ready.move_to_end(newId, last=False)#将要抢占cpu的进程移动到readylist队首 ready[oldId].status = \"ready\"#更新进程的状态 ready[newId].status = \"running\"#更新进程的状态 print(\"process \"+newId+\" is running.\")#打印提示信息 def timeOut(cPid):#传入当前运行的进程名 ready.move_to_end(cPid)#将当前正在执行的进程移动到readylist队尾 ready[cPid].status = \"ready\"#更新进程状态 scheduler() if list(ready.keys())[0]!=cPid:#打印提示信息 print(\"process \"+cPid+\" is ready\") 测试效果","link":"/2019/12/23/%E8%BF%9B%E7%A8%8B%E4%B8%8E%E8%B5%84%E6%BA%90%E7%AE%A1%E7%90%86%E8%AE%BE%E8%AE%A1-%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%AE%9E%E9%AA%8C/"},{"title":"锁和原子操作是怎么实现的","text":"mutex互斥锁是借助与汇编指令cmpxchgl实现的，是汇编级别的CAS，如果swap不成功，则调用__lll_lock_wait让线程调度，让出cpu。 C++ 标准库std::mutex只是pthread_mutex_t的封装，所以看pthread_mutex_t就可以。 如何调试死锁 写多线程malloc不知道为什么死锁了，记录下调试过程 使用gdb调试，在vscode的调试控制台下使用gdb命令需要加上-exec前缀 运行程序，发现不在打印日志，怀疑死锁，SIGTRAP暂停程序 使用info thread查看线程情况 前面带*的是正在运行的线程，不带*的大概率就是阻塞的线程了，观察后面的栈帧情况，发现程序运行在__lll_lock_wait请求获得锁，说明2、3、4、6、9线程都阻塞在这里了。（LWP后面跟的就是线程号）。 使用thread apply all backtrace查看所有线程的栈帧信息 backtrace是打印栈帧的命令，thread apply all 可以对所有线程使用后面跟随的指令，有lock_wait就是发生了死锁的线程 然后使用thread *切换到不同的线程，打印出mutex变量查看owner的线程号： 检查是否有循环持锁的情况，再检查代码逻辑 （最后都是程序逻辑写错了） 参考https://kernel.taobao.org/2020/11/talking_of_atomic_operations/","link":"/2021/09/05/%E9%94%81%E5%92%8C%E5%8E%9F%E5%AD%90%E6%93%8D%E4%BD%9C%E6%98%AF%E6%80%8E%E4%B9%88%E5%AE%9E%E7%8E%B0%E7%9A%84/"},{"title":"UNIX操作系统设计-文件系统的系统调用","text":"《UNIX操作系统设计》第五章 引入了三种内核数据结构：文件表、用户文件描述秒和安装表 文件表：系统每个打开的文件在文件表中占有一项 文件描述分配表：记录进程已知的每个文件描述符 安装表：记录每个活动的文件系统信息 系统调用open算法描述df = open(pathname,flags,modes) pathname是文件名，flags是打开的类型（读写），modes给出文件的许可权，返回一个称为文件描述符的整数。 打开清文件是什么？ 内核先根据文件名找到索引节点，检查文件许可权，在文件表中分配表项，文件表表项中的指针指向索引节点，并设置偏移量，表示读写开始的地方。内核还会在进程的u区的文件描述符表中分配一个表项指向文件表中的表项，如下例子： 每个open调用都会在用户文件描述符表和内核文件表中分配一个唯一的表项，但在索引节点表中，每个文件只有一个表项。 文件表的作用：在若干文件描述符之间能够共享偏移量指针，见下文的dup和fork的实现。 文件描述符0、1、2分别为：标准输入、标准输出、标准错误文件描述符。 系统调用read算法描述number = read(fd,buffer,count) fd是由open返回的文件描述符，buffer是用户进程中的一个数据结构的地址，调用成果结束时在该地址中存放所读的数据，count时要读的字节数，number是实际读的字节数。 根据文件描述符找到文件表项 在u区设置参数 找到索引节点 索引节点上锁 进入循环，直到读完。先读到缓冲区，再拷贝到用户地址空间 系统调用write算法描述number = write(fd,buffer,count) 写和读类似，区别： 若文件中还没有要写的字节偏移量所对应的块，内核要用alloc分配一个块，并将该块号放到索引节点表的正确位置上。 如果字节偏移量是一个间接块中的偏移量，内核可能需要分配几个块 举例 一个进程要写到一个文件的字节号为10240的地方 算法bmap访问该字节，内核将找不到对应的字节块，也没有必要的间接块。 内核分配磁盘块作间接块，并将块号写到内存的索引节点 然后，内核为数据分配磁盘块，并将块号写到新分配的间接块的第一个位置。 文件和记录的上锁文件的加锁：指防止其他进程读或写整个文件的任何一部分的能力 记录的加锁：防止其他进程读或写特定记录的能力 之后将详细讨论实现 文件的输入/输出位置的调整——lseekread和write提供了对文件的顺序访问，lseek可以指定IO的位置，从而实现文件的随机存取，语法格式如下： position=lseek(fd,offset,reference) fd是文件描述符，offset是字节偏移量，reference指出字节偏移量从哪开始：0表示文件头、1文件的当前读/写偏移量位置、2文件尾，position下次开始读/写的字节偏移量。 lseek的实现：系统通过调整文件表中的字节偏移量来实现。 举例 读取每隔1024倍数的那个字节 系统调用close算法描述close(fd) 内核对文件描述符、对应的文件表项、索引节点表项进行相应的处理，来完成关闭文件的操作。 如果因为调用dup或fork使得文件表项的引用数大于1，内核将引用数减1 如果引用数为1，内核将释放表项，并释放在open中分配的内存索引节点（iput） 如果其他进程还引用该索引节点，索引节点的引用数减1 否则索引节点引用数减为0，归还该索引节点 注意：这里的文件表项和索引节点都有一个引用数 进程退出时，内核检查其用户文件描述符，并在内部关闭，因此进程终止后，文件也关闭了。 举例关闭前： 关闭B进程的两个文件后： 文件的创建creat算法描述fd = creat(pathname,modes) 内核首先调用算法namei，作路径名到索引节点的对应 当namei达到路径名的最后一个分量，内核将要创建文件名时，namei记下目录中的第一个空目录槽的字节偏移量，并保存在u区中。 如果内核在目录中没有找到该路径名分量，则会将这个文件名写到刚刚的空槽中，这也是保存字节偏移量的原因。 如果没有空槽，内核记下目录尾的偏移量，并在那里建立一个新槽。 内核还要在u区记下被查找的目录的索引节点，并锁住该索引节点。 该节点将称为新文件的父目录，此时内核还不会把新文件写入该目录，这是为了防止以后发生的错误事件 检查有没有对该目录的写权限 如果给定名字的文件不存在，内核调用ialloc给新文件分配一个索引节点。 内核按照保存在u区中的字节偏移量，把新文件名和新分配的索引节点号写到父目录中。 释放父目录的索引节点。 如果给定的文件已经存在 检查是否有写许可权 用free算法释放所有的数据块 特殊文件的创建算法描述mknod(pathname,type and permissions,dev) type and permissions给出节点的类型（如目录）和要被建立的新文件的访问许可权。dev是块特殊文件和字符特殊文件规定主设备号和次设备号（第10章） mknod用来建立一些特殊文件，包括有名管道、设备文件和目录，同样内核需要分配一个索引节点 改变目录及根 chdir、chrootchdir(pathname) chroot(pathname) 把pathname当作进程的根目录 与chdir基本相同，将新的根索引节点存放在u区中。 改变所有者及许可权方式 chown、chmodchown(pathname,owner,group) 内核先用namei将文件的名字转换成一个索引节点，然后赋予文件新的所有者和用户组，清除文件存取权方式中的setuid位和setgid位，并用iput释放该索引节点。 chmod(pathname,mode) 类似，改变的不是所有者号而是索引节点中的方式标志。 系统调用stat和fstat允许查询文件的状态，他们返回诸如文件类型、文件所有者、存取许可权、文件大小等信息。 stat(pathname,statbufer) 文件名 fstat(fd,statbuffer) 文件描述符 管道管道的传统实现方法是采用文件系统作为数据存储。有两种类型的管道：有名管道和无名管道。 进程调用pipe建立无名管道后，只有他们的后代才能共享这个管道 而对于有名管道，所有进程能够按照文件许可权存取有名管道 无名管道pipepipe(fdptr) fdptr是一个整型数组的指针，整个数组含有读、写管道用的两个文件描述符 有名管道也是文件，但是这个文件有目录项并且可以通过路径名来存取。有名管道在文件系统树钟永久地存在（可用系统调用unlink来清楚），而无名管道是临时性的，进程结束使用无名管道时，内核会回收索引节点。 打开有名管道的算法和打开一个正规文件的算法基本相同，根据进程打开管道的目的，读还是写，内核会唤醒等待的睡眠进程。 管道的读和写管道存取数据按先进先出的方式。 内核存取管道数据的方式和正规文件一样，但是管道只用索引节点的直接块以获得较高的效率。另外，内核将读写偏移量放在索引节点而不是文件表，这样多个进程才能共享偏移量值。 内核将索引节点直接块作为循环队列来管理，内部修改读写指针来保证先进先出的顺序。 写管道12345678910if(管道的空间足够存放要写入的数据){ 写入数据 增加管道大小}else{//管道不能容纳所有的数据 if(要写的数据量大于管道的总容量) 写尽可能多的数据 然后睡眠 else 进程睡眠，等待数据从管道排出} 读管道1234567891011if(管道不为空){ if(要读的数据&gt;管道中的所有数据){ 读出所有数据 结束 }else{ 读出数据 }}else{//管道为空 进程进入睡眠 直到有进程将数据写入管道} 管道的关闭与关闭正规文件的过程一样，只是在释放索引节点前要作特殊的处理：减少读者写者的数目，只要读进程或者写进程数目为0，就唤醒睡眠进程，对于有名进程也是一样的。 例子内核并不关系也不知道读写管道的进程是否是同一进程 dup复制文件描述符，将一个文件描述符拷贝到该用户文件描述符表中的第一个空槽钟，给用户返回一个新的文件描述符 newfd =dup(fd) 因为复制了文件描述符，对应文件表项的引用数+1 举例先打开文件”/etc/passwd”（文件描述符3），再打开一次（文件描述符4），之后打开文件”local”（文件描述符5），再dup文件描述符3，返回6 dup可用于由简单的标准构建程序构造复杂的程序，例如构造shell管道线（第7章） 因为i,j所代表的两个文件描述符指向同一个文件表项，因此使用的是相同的文件偏移量，前两个read读出的数据在buf1和buf2中并不相同。 文件系统的安装和拆卸mount将一个磁盘的指定段的文件系统连到一个已存在的文件系统目录树中，umount将一个文件系统从该文件系统目录树中拆卸下来。 mount(special pathname, directory pathname, options) special pathname是磁盘段的设备特殊文件名，磁盘段含有要安装的文件系统 directory pathname是已存在的文件系统目录树中的目录，即要被安装的地方，安装点 options指出文件系统是否被安装成“只读”。 例如： mount(\"/dev/dsk1\",\"/usr\",0) 内核中有个安装表，每个被安装的文件系统都占有一个表项，每个表项含有： 设备号，表示文件系统，即逻辑文件系统号 指向被安装的文件系统超级块的缓冲区的指针 指向被安装的文件系统的根索引节点的指针（如上例，就是“/”） 指向安装点的目录的索引节点的指针（如上例，就是“usr”） 在文件路径名中跨越安装点如命令： 123mount /dev/dsk1 /usrcd /usr/src/uts cd ../../.. 分别对应从安装点的系统文件跨越到被安装的文件系统的情况 从被安装的文件系统跨越到安装点的文件系统 修改iget从安装点的文件系统跨越到被安装的文件系统。检查是否是安装点，如果是，需要在安装表中查找对应的安装表表项，并记下安装的设备号，然后利用设备号和根的索引节点，存取被安装设备的根索引节点。 例如 cd /usr/src/uts ，内核先找到/usr的索引节点，发现有安装点标志，就在安装表中找到被安装的文件系统的根索引节点。 修改namei从被安装的文件系统跨越到安装点的文件系统。内核要检查路径名分量的索引节点号是否是一个文件系统的根节点，如果是，当前工作的索引节点也是根，路径名分量又是”..”，就能识别出这个节点是安装点。 例如：cd ../../..，当前目录在“/usr/src/uts”，分析两个..后，到达usr,然后分析第三个..，内核发现这个..的索引节点号是根索引节点号，工作的索引节点也是根且分量名为..，内核在安装表中找到usr的表项，令工作索引节点为安装点的索引节点。 文件系统的拆卸umount(special filename) 内核找到要被拆卸的设备的索引节点，查找特殊文件的设备号，释放对应的索引节点（iput）,并在安装表中查找设备号等于该特殊文件的设备号的表项。同时注意，拆卸之前内核会检查该文件系统中有活动的文件，如果有，拆卸失败。 创建硬链接link在文件系统结构中，将一个文件联结到一个新名字，从而为一个已存在的索引节点创建一个新的目录项。 link(source filename, target filename) source filename是源文件名，已经存在的文件的名字 target filename是完成调用后，源文件所具有的新的名字。 内核仅允许超级用户联结一个目录 立刻释放索引节点是为了防止死锁的发生。 举例 进程可以通过任意一个路径名存取文件，内核并不知道哪个名字是最初的文件名。 清除一个硬链接 unlink清除文件的一个目录表项 unlink(pathname) 如果清除的是文件的最后一个链接，内核会释放他的数据块，如果有多个，通过其他路径，仍能访问文件。 拆除.见课后习题 文件系统的一致性内核需要按某种次序进行写磁盘操作 内核也应按特别的次序释放索引节点和磁盘块 竞争条件例如： rmdir清除目录前要先证实一个目录不含任何文件。但是证实目录为空和清除目录的操作不是原子的，证实一个目录为空后，另一进程又在目录中创建文件，就需要上锁。 一个进程利用namei将一个文件的路径名变为一个索引节点，另一个进程正在清除该路径名中的一个目录。 一个进程使一个文件处于打开状态，另一个进程可能在该文件打开期间拆除该文件，第一个进程仍能用他的文件描述符进行所有正常的文件操作，直到他关闭该文件，索引节点的引用数减为0，内核才清除该文件内容，利用这个特点，进程常创建一些临时文件，并立刻拆除他们。 文件系统的抽象允许UNIX系统支持各种文件系统类型？？不太懂 文件系统维护介绍几种由fsck检查的不一致性 一个磁盘块可能属于一个以上的索引界定啊，或者属于自由块链表的一个索引节点 一个块号既不存在块的自由链表上，由不在任何文件中，文件系统则是不一致的 一个索引节点联结数不为0，但是索引节点号却不在文件系统的任何目录 一个索引节点的格式不正确 一个索引节点号出现在目录表项中，但同时又是自由可用的 保存在超级块中的自由块数或自由节点数与磁盘上存在的数目不一致","link":"/2020/10/20/UNIX%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1-%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F%E7%9A%84%E7%B3%BB%E7%BB%9F%E8%B0%83%E7%94%A8/"},{"title":"muduo学习笔记","text":"调用关系分析Muduo自顶向下 自顶向下分析muduo的调用逻辑 创建自己的业务server 创建自己的server类,包含了两个私有成员:EventLoop *loop_,TcpServer server_ 实现on_message和on_connection，在构造函数里设置回调，设置线程数 main函数调用server.start() server.start()会调用内部TcpServer的start,然后调用EventLoop的loop()。12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455class EchoServer{public: EchoServer(EventLoop *loop, InetAddress &amp;addr, string name) : server_(loop, addr, name), loop_(loop) { //注册回调函数 server_.set_connection_callback(bind(&amp;EchoServer::on_connection, this, _1)); server_.set_message_callback(bind(&amp;EchoServer::on_message, this, _1, _2, _3)); //设置线程数量 server_.set_thread_num(3); } void start() { server_.start(); loop_-&gt;loop(); }private: //连接建立或者断开的回调 void on_connection(const TcpConnectionPtr &amp;conn) { if (conn-&gt;connected()) { LOG_INFO(\"conn up: %s\", conn-&gt;get_peeraddr().get_ip_port().c_str()); } else { LOG_INFO(\"conn down: %s\", conn-&gt;get_peeraddr().get_ip_port().c_str()); } } //可读事件回调 void on_message(const TcpConnectionPtr &amp;conn, Buffer *buffer, TimeStamp time) { string msg = buffer-&gt;retrieve_all_asString(); conn-&gt;send(msg); //conn-&gt;shutdown(); }private: EventLoop *loop_; TcpServer server_;};int main(){ EventLoop loop(1); InetAddress addr(8000); EchoServer server(&amp;loop, addr, \"echo 01\"); server.start(); //loop.loop(); //启动main loop的底层poller return 0;} TcpServer的start 业务server调用TcpServer的start TcpServer有一个main Loop,一个线程池，池子里是所有的subReactor，每个线程也有自己的loopTcpServer的start会调用自己的线程池的start，然后在自己的main loop里调用listen 123456789//开启服务器监听void TcpServer::start(){ if (started_++ == 0) //防止被多次启动 { thread_pool_-&gt;start(thread_init_callback_); loop_-&gt;run_in_loop(bind(&amp;Acceptor::listen, acceptor_.get())); }} 线程池的start创建thread_nums个EventLoopThread,每个thread有自己的一个EventLoop，调用start_loop，返回的eventloop地址然后放到线程池的loops_数组中。 1234567891011121314151617181920void EventLoopThreadPool::start(const ThreadInitCallback &amp;callback){ started_ = true; //整个服务端只有baseloop，也就是mainreactor if (thread_nums_ == 0) { callback(baseloop_); } else { for (int i = 0; i &lt; thread_nums_; ++i) { char buffer[name_.size() + 32] = {0}; snprintf(buffer, sizeof(buffer), \"%s %d\", name_.c_str(), i); EventLoopThread *t = new EventLoopThread(callback, buffer); threads_.push_back(unique_ptr&lt;EventLoopThread&gt;(t)); loops_.push_back(t-&gt;start_loop()); //底层开始创建线程，并绑定一个新的eventloop，返回其地址 } }} EventLoopThread的start_loop1234567891011121314151617EventLoop *EventLoopThread::start_loop(){ thread_.start(); //启动线程 EventLoop *loop = nullptr; { unique_lock&lt;mutex&gt; lock(thread_mutex_); while (loop_ == nullptr) { condition_.wait(lock); } loop = loop_; } return loop;} 里面再调用Thread的start 1234567891011121314151617void Thread::start(){ started_ = true; sem_t sem; sem_init(&amp;sem, false, 0); //开启线程 thread_ = shared_ptr&lt;thread&gt;(new thread([&amp;]() { //获取线程tid值 tid_ = Current_thread::tid(); sem_post(&amp;sem); //执行函数 function_(); })); //需要等待新创建的线程，获取其线程的id sem_wait(&amp;sem);} 这里会创建新的线程，然后新的线程里跑function_, function_实际就是初始化EventLoopThread时传入了的thread_function，在里面会创建EventLoop，然后进入EventLoop的while 1循环。 12345678910111213141516171819202122//启动的线程中执行以下方法void EventLoopThread::thread_function(){ EventLoop loop(0); //创建一个独立的EventLoop，和上面的线程是一一对应 one loop per thread if (callback_function_) { callback_function_(&amp;loop); } { unique_lock&lt;mutex&gt; lock(thread_mutex_); loop_ = &amp;loop; condition_.notify_one(); } loop.loop(); //开启事件循环 //结束事件循环 unique_lock&lt;mutex&gt; lock(thread_mutex_); loop_ = nullptr;} 上面说的while 1循环就是调用poller的poll，然后填充active_channel，然后在使用channel来处理不同事件，比如读写的回调函数。 123456789101112131415while (!quit_){ active_channels.clear(); //监听两类fd 一种是client的fd，一种wakeup的fd poll_return_time_ = poller_-&gt;poll(k_poll_timeout, &amp;active_channels); for (Channel *channel : active_channels) { //Poller监听哪些channel发生事件了，然后上报给eventloop，通知channel处理事件 channel-&gt;handle_event(poll_return_time_); } //执行当前EventLoop事件循环需要处理的回调操作 do_pending_functors();} 然后main reactor会调用run_in_loop, 开启acceptor的listen 123456789void Acceptor::listen(){ LOG_INFO(\"Acceptor listen called!\\n\"); listenning_ = true; accept_socket_.listen(); //借助poller进行监听 accept_channel_.enable_reading(); } Acceptoracceptor_是TcpServer类中的一个指针成员。包含两个关键成员：指向mainloop的指针，和用来管理listenfd的channel。 123EventLoop *loop_; //acceptor用的用户定义的那个baseloop，也就是mainloopChannel accept_channel_; 当有新的连接到达时，Acceptor会执行new_connection的回调，里面会选择一个subreactor，创建一个新的connection，放到TcpServer的map里，然后，在这个subreactor里调用establish_connect，establish_connect会像Poller添加关于这个新连接fd的事件监听。 1234567891011121314151617181920212223242526272829303132333435363738void TcpServer::new_connection(int sockfd, const InetAddress &amp;peeraddr){ LOG_INFO(\"new connection callback called\\n\"); //轮询算法，选择一个subloop管理channel EventLoop *ioloop = thread_pool_-&gt;get_nextEventLoop();//连接均匀打到每个eventloop上 char buffer[BUFFER_SIZE64] = {0}; snprintf(buffer, sizeof(buffer), \"-%s#%d\", ip_port_.c_str(), next_conn_id_); ++next_conn_id_; string conn_name = name_ + buffer; LOG_INFO(\"tcp server:: new connection[%s] - new connection[%s] from %s\\n\", name_.c_str(), conn_name.c_str(), peeraddr.get_ip_port().c_str()); //通过sockfd，获取其绑定的端口号和ip信息 sockaddr_in local; bzero(&amp;local, sizeof(local)); socklen_t addrlen = sizeof(local); if (::getsockname(sockfd, (sockaddr *)&amp;local, &amp;addrlen) &lt; 0) { LOG_ERROR(\"new connection get localaddr error\\n\"); } InetAddress localaddr(local); //根据连接成功的sockfd，创建tcpc连接对象 TcpConnectionPtr conn(new TcpConnection(ioloop, conn_name, sockfd, localaddr, peeraddr)); connections_[conn_name] = conn; //下面回调是用户设置给tcpserver-》tcpconn-》channel-》poller-》notify channel conn-&gt;set_connection_callback(connection_callback_); conn-&gt;set_message_callback(message_callback_); conn-&gt;set_write_complete_callback(write_complete_callback_); //设置如何关闭连接的回调 conn-&gt;set_close_callback(bind(&amp;TcpServer::remove_connection, this, _1)); ioloop-&gt;run_in_loop(bind(&amp;TcpConnection::establish_connect, conn));} 看下run_in_loop怎么实现的：如果调用方就是这个loop所属的线程，直接调用否则放到这个eventloop的pending_Functors_里，而eventloop每次poll完，处理完对应channel的handle都会调用do_pending_functors()。 123456789101112void EventLoop::run_in_loop(Functor cb){ //在当前的loop线程中执行回调 if (is_in_loopThread()) { cb(); } else //在其他线程执行cb，唤醒loop所在线程执行cb { queue_in_loop(cb); }} 模块分析Reactor EventLoop12345678910111213141516class EventLoop : boost::noncopyable { public: EventLoop(); ~EventLoop(); void loop(); void assertInLoopThread() { if (!isInLoopThread()) { abortNotInLoopThread(); } } bool isInLoopThread() const { return threadId_ == CurrentThread::tid(); } private: void abortNotInLoopThread(); bool looping_; /* atomic */ const pid_t threadId_; //记录自己所属的线程 }; 构造函数会检查当前线程是否创建了EventLoop对象，如果已经创建了就返回错误。这是one loop per thread的要求，一个IO线程只能有一个EventLoop对象。 Channel用来管理各种callback，比如对于readcallback: TimerQueue用它来读timerfd EventLoop用来读eventfd TcpServer/Acceptor用来读listening socket TcpConnection 用它来读Tcp socket 12345678910111213141516171819202122232425262728293031323334353637class Channel : boost::noncopyable { public: typedef boost::function&lt;void()&gt; EventCallback; Channel(EventLoop *loop, int fd); void handleEvent(); void setReadCallback(const EventCallback &amp;cb) { readCallback_ = cb; } void setWriteCallback(const EventCallback &amp;cb) { writeCallback_ = cb; } void setErrorCallback(const EventCallback &amp;cb) { errorCallback_ = cb; } int fd() const { return fd_; } int events() const { return events_; } void set_revents(int revt) { revents_ = revt; } bool isNoneEvent() const { return events_ == kNoneEvent; } void enableReading() { events_ |= kReadEvent; update(); } // void enableWriting() { events_ |= kWriteEvent; update(); } // void disableWriting() { events_ &amp;= ~kWriteEvent; update(); } // void disableAll() { events_ = kNoneEvent; update(); } // for Poller int index() { return index_; } void set_index(int idx) { index_ = idx; } EventLoop *ownerLoop() { return loop_; } private: void update(); static const int kNoneEvent;//几种事件的定义 static const int kReadEvent; static const int kWriteEvent; EventLoop *loop_; const int fd_; int events_;//关心的IO事件，由用户设置 int revents_;//目前活动的事件，由Event/Poller设置 int index_; // used by Poller. EventCallback readCallback_; EventCallback writeCallback_; EventCallback errorCallback_; }; 每个channel只属于一个EventLoop，因此每个channel只属于一个IO线程，每个Channel对象自始至终只负责一个文件描述符的IO事件分发，Channel把不同的IO线程分发为不同的回调，例如ReadCallback、writeCallback等，回调用boost::function。后面的TcpConnection是对Channel的更上层封装，用户一般不使用channel。 由于channel的成员函数只能在IO线程使用，所以更新成员函数不用加锁。 1234567891011121314151617181920212223242526272829303132const int Channel::kNoneEvent = 0;const int Channel::kReadEvent = POLLIN | POLLPRI;const int Channel::kWriteEvent = POLLOUT;Channel::Channel(EventLoop *loop, int fdArg) : loop_(loop), fd_(fdArg), events_(0), revents_(0), index_(-1) {}void Channel::update() { loop_-&gt;updateChannel(this);}void Channel::handleEvent() { if (revents_ &amp; POLLNVAL) { LOG_WARN &lt;&lt; \"Channel::handle_event() POLLNVAL\"; } if (revents_ &amp; (POLLERR | POLLNVAL)) { if (errorCallback_) errorCallback_(); } if (revents_ &amp; (POLLIN | POLLPRI | POLLRDHUP)) { if (readCallback_) readCallback_(); } if (revents_ &amp; POLLOUT) { if (writeCallback_) writeCallback_(); }} updata()会调用eventloop的updateChannel 1234567891011121314151617181920212223```void Channel::handleEvent() 是Channel的核心，由EventLoop::loop()调用，根据revents_的值分别调用不同的用户回调。```c++void EventLoop::loop() { assert(!looping_); assertInLoopThread(); looping_ = true; quit_ = false; while (!quit_) { activeChannels_.clear(); poller_-&gt;poll(kPollTimeMs, &amp;activeChannels_); for (ChannelList::iterator it = activeChannels_.begin(); it != activeChannels_.end(); ++it) { (*it)-&gt;handleEvent(); } } LOG_TRACE &lt;&lt; \"EventLoop \" &lt;&lt; this &lt;&lt; \" stop looping\"; looping_ = false;} PollerPoller是IO 多路复用的封装。 1234567891011121314151617181920212223242526272829class Poller : boost::noncopyable { public: typedef std::vector&lt;Channel *&gt; ChannelList; Poller(EventLoop *loop); ~Poller(); /// Polls the I/O events. /// Must be called in the loop thread. Timestamp poll(int timeoutMs, ChannelList *activeChannels); //核心 /// Changes the interested I/O events. /// Must be called in the loop thread. void updateChannel(Channel *channel); void assertInLoopThread() { ownerLoop_-&gt;assertInLoopThread(); } private: void fillActiveChannels(int numEvents, ChannelList *activeChannels) const; typedef std::vector&lt;struct pollfd&gt; PollFdList; typedef std::map&lt;int, Channel *&gt; ChannelMap; //fd到Channel*的映射 EventLoop *ownerLoop_; PollFdList pollfds_; ChannelMap channels_;}; Channel提供了fd到Channel*的映射，poll()不会在每次调用前构造pollfd数组，而是把它缓存到follfds_里。 1234567891011121314Timestamp Poller::poll(int timeoutMs, ChannelList *activeChannels) { // XXX pollfds_ shouldn't change int numEvents = ::poll(&amp;*pollfds_.begin(), pollfds_.size(), timeoutMs); Timestamp now(Timestamp::now()); if (numEvents &gt; 0) { LOG_TRACE &lt;&lt; numEvents &lt;&lt; \" events happended\"; fillActiveChannels(numEvents, activeChannels); } else if (numEvents == 0) { LOG_TRACE &lt;&lt; \" nothing happended\"; } else { LOG_SYSERR &lt;&lt; \"Poller::poll()\"; } return now;} poll是Poller的核心功能，调用poll（2）获取当前活动的IO事件，然后放入activeChannels中（fillActiveChannels）。 12345678910111213141516171819202122232425void Poller::fillActiveChannels(int numEvents, ChannelList *activeChannels) const { for (PollFdList::const_iterator pfd = pollfds_.begin(); pfd != pollfds_.end() &amp;&amp; numEvents &gt; 0; ++pfd) { if (pfd-&gt;revents &gt; 0) { //有事件发生 --numEvents; ChannelMap::const_iterator ch = channels_.find(pfd-&gt;fd); assert(ch != channels_.end()); Channel *channel = ch-&gt;second; assert(channel-&gt;fd() == pfd-&gt;fd); channel-&gt;set_revents(pfd-&gt;revents); // pfd-&gt;revents = 0; activeChannels-&gt;push_back(channel); } }}//注pollfd结构struct pollfd { int fd; /* File descriptor to poll. */ short int events; /* Types of events poller cares about. */ short int revents; /* Types of events that actually occurred. */ }; fillActiveChannels() 先遍历了缓存的pollfds_，判断pollfd是否有事件发生，如果有事件，则根据ChannelMap找到该fd对应的Channel，放到activeChannels中。 poll完之后，eventloop会handleEvent。 一个点是，这里不能边遍历pollfds，一边handleEvents，因为handleEvents会添加或删除Channel，从而造成pollfds数组大小改变。另一个原因是Poller的职责是多路复用，并不负责事件分发。 123456789101112131415161718192021222324252627282930void Poller::updateChannel(Channel *channel) { assertInLoopThread(); LOG_TRACE &lt;&lt; \"fd = \" &lt;&lt; channel-&gt;fd() &lt;&lt; \" events = \" &lt;&lt; channel-&gt;events(); if (channel-&gt;index() &lt; 0) { // a new one, add to pollfds_ assert(channels_.find(channel-&gt;fd()) == channels_.end()); struct pollfd pfd; pfd.fd = channel-&gt;fd(); pfd.events = static_cast&lt;short&gt;(channel-&gt;events()); pfd.revents = 0; pollfds_.push_back(pfd); int idx = static_cast&lt;int&gt;(pollfds_.size()) - 1; channel-&gt;set_index(idx); //记住自己在fd数组中的下标 channels_[pfd.fd] = channel; } else { // update existing one assert(channels_.find(channel-&gt;fd()) != channels_.end()); assert(channels_[channel-&gt;fd()] == channel); int idx = channel-&gt;index(); assert(0 &lt;= idx &amp;&amp; idx &lt; static_cast&lt;int&gt;(pollfds_.size())); struct pollfd &amp;pfd = pollfds_[idx]; assert(pfd.fd == channel-&gt;fd() || pfd.fd == -1); pfd.events = static_cast&lt;short&gt;(channel-&gt;events()); pfd.revents = 0; if (channel-&gt;isNoneEvent()) { // ignore this pollfd pfd.fd = -1; } }} updateChannel()负责维护和更新pollfds_数组。为什么说插入删除是logN? 定时器muduo的定时器实现用了三个类，TimerId、Timer、TimerQueue。 TimerQueue有了Reactor的基础，在EventLoop加上定时器功能。现代Linux中有timerfd，可以用和处理IO事件相同的方式来处理定时。传统reactor通过控制select和poll的等待事件来实现定时。 1234567891011121314151617181920212223242526272829303132333435363738class TimerQueue : boost::noncopyable { public: TimerQueue(EventLoop *loop); ~TimerQueue(); /// /// Schedules the callback to be run at given time, /// repeats if @c interval &gt; 0.0. /// /// Must be thread safe. Usually be called from other threads. TimerId addTimer(const TimerCallback &amp;cb, Timestamp when, double interval); // void cancel(TimerId timerId); private: // FIXME: use unique_ptr&lt;Timer&gt; instead of raw pointers. typedef std::pair&lt;Timestamp, Timer *&gt; Entry; typedef std::set&lt;Entry&gt; TimerList; // called when timerfd alarms void handleRead(); // move out all expired timers std::vector&lt;Entry&gt; getExpired(Timestamp now); void reset(const std::vector&lt;Entry&gt; &amp;expired, Timestamp now); bool insert(Timer *timer); EventLoop *loop_; const int timerfd_; Channel timerfdChannel_; //用来观察timerfd_上的readable事件 // Timer list sorted by expiration TimerList timers_;}; TimerQueue提供了两个接口addTimer()和cancel()，只能在它所属的IO线程调用，所以不用加锁。 addTimer()提供给EventLoop使用。EventLoop会把addTimer()封装为更好用的runAt()、runAfter()、runEvery()等函数。 TimerQueue需要管理未到期的Timer，能快速根据当前时间找到已经到期的Timer，同时能高效添加和删除Timer。 EventLoop的改动新增几个调用定时器的接口。 EventLoop::runInLoop()函数在IO线程内执行某个用户任务回调。 TCP网络库Acceptoracceptor用来accept新的TCP连接，并通过回调通知使用者。这个类是TcpServer使用的。 12345678910111213141516171819202122class Acceptor : boost::noncopyable { public: typedef boost::function&lt;void(int sockfd, const InetAddress &amp;)&gt; NewConnectionCallback; Acceptor(EventLoop *loop, const InetAddress &amp;listenAddr);//构造函数则执行TCP服务端的传统步骤，创建socket,bind void setNewConnectionCallback(const NewConnectionCallback &amp;cb) { newConnectionCallback_ = cb; } bool listenning() const { return listenning_; } void listen(); //然后listen private: void handleRead(); //调用accept接受新的连接，并回调用户的callback EventLoop *loop_; Socket acceptSocket_;//封装了socket，利用RAII管理生命期。这里是个listen socket Channel acceptChannel_; NewConnectionCallback newConnectionCallback_; bool listenning_;}; TcpServer管理accept得到的连接，直接给框架的用户使用。用户只需要设置好callback，然后调用start 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960class TcpServer : boost::noncopyable { public: TcpServer(EventLoop *loop, const InetAddress &amp;listenAddr); ~TcpServer(); // force out-line dtor, for scoped_ptr members. /// Set the number of threads for handling input. /// /// Always accepts new connection in loop's thread. /// Must be called before @c start /// @param numThreads /// - 0 means all I/O in loop's thread, no thread will created. /// this is the default value. /// - 1 means all I/O in another thread. /// - N means a thread pool with N threads, new connections /// are assigned on a round-robin basis. void setThreadNum(int numThreads); /// Starts the server if it's not listenning. /// /// It's harmless to call it multiple times. /// Thread safe. void start(); /// Set connection callback. /// Not thread safe. void setConnectionCallback(const ConnectionCallback &amp;cb) { connectionCallback_ = cb; } /// Set message callback. /// Not thread safe. void setMessageCallback(const MessageCallback &amp;cb) { messageCallback_ = cb; } /// Set write complete callback. /// Not thread safe. void setWriteCompleteCallback(const WriteCompleteCallback &amp;cb) { writeCompleteCallback_ = cb; } private: /// Not thread safe, but in loop void newConnection(int sockfd, const InetAddress &amp;peerAddr); /// Thread safe. void removeConnection(const TcpConnectionPtr &amp;conn); /// Not thread safe, but in loop void removeConnectionInLoop(const TcpConnectionPtr &amp;conn); typedef std::map&lt;std::string, TcpConnectionPtr&gt; ConnectionMap; EventLoop *loop_; // the acceptor loop const std::string name_; boost::scoped_ptr&lt;Acceptor&gt; acceptor_; // avoid revealing Acceptor boost::scoped_ptr&lt;EventLoopThreadPool&gt; threadPool_; ConnectionCallback connectionCallback_; MessageCallback messageCallback_; WriteCompleteCallback writeCompleteCallback_; bool started_; int nextConnId_; // always in loop thread ConnectionMap connections_;}; 内部使用acceptor管理新连接的fd。持有目前存活的TcpConnection的shared_ptr。 TcpConnetction包含了这个连接对应的socket，和对应的channel 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081class TcpConnection : boost::noncopyable,public boost::enable_shared_from_this&lt;TcpConnection&gt; { public: /// Constructs a TcpConnection with a connected sockfd /// /// User should not create this object. TcpConnection(EventLoop *loop, const std::string &amp;name, int sockfd, const InetAddress &amp;localAddr, const InetAddress &amp;peerAddr); ~TcpConnection(); EventLoop *getLoop() const { return loop_; } const std::string &amp;name() const { return name_; } const InetAddress &amp;localAddress() { return localAddr_; } const InetAddress &amp;peerAddress() { return peerAddr_; } bool connected() const { return state_ == kConnected; } //void send(const void* message, size_t len); // Thread safe. void send(const std::string &amp;message); // Thread safe. void shutdown(); void setTcpNoDelay(bool on); void setConnectionCallback(const ConnectionCallback &amp;cb) { connectionCallback_ = cb; } void setMessageCallback(const MessageCallback &amp;cb) { messageCallback_ = cb; } void setWriteCompleteCallback(const WriteCompleteCallback &amp;cb) { writeCompleteCallback_ = cb; } /// Internal use only. void setCloseCallback(const CloseCallback &amp;cb) { closeCallback_ = cb; } // called when TcpServer accepts a new connection void connectEstablished(); // should be called only once // called when TcpServer has removed me from its map void connectDestroyed(); // should be called only once private: enum StateE { kConnecting, kConnected, kDisconnecting, kDisconnected, }; void setState(StateE s) { state_ = s; } void handleRead(Timestamp receiveTime); void handleWrite(); void handleClose(); void handleError(); void sendInLoop(const std::string &amp;message); void shutdownInLoop(); EventLoop *loop_; std::string name_; StateE state_; // FIXME: use atomic variable // we don't expose those classes to client. boost::scoped_ptr&lt;Socket&gt; socket_; boost::scoped_ptr&lt;Channel&gt; channel_; InetAddress localAddr_; InetAddress peerAddr_; ConnectionCallback connectionCallback_; MessageCallback messageCallback_; WriteCompleteCallback writeCompleteCallback_; CloseCallback closeCallback_; Buffer inputBuffer_; Buffer outputBuffer_;}; TcpConnection使用Channel来获得socket上的IO事件。 BufferBuffer是非阻塞Tcp网络编程比不可少的东西。在TcpConnection中作为输入输出缓冲。 多线程TcpServerEventLoopThreadPool多线程TcpServer自己的EventLoop只用来接受新连接，而新连接会用其他EventLoop来执行IO。 123456789101112131415161718192021class EventLoopThreadPool : boost::noncopyable { public: EventLoopThreadPool(EventLoop *baseLoop); ~EventLoopThreadPool(); void setThreadNum(int numThreads) { numThreads_ = numThreads; } void start(); EventLoop *getNextLoop(); private: EventLoop *baseLoop_; bool started_; int numThreads_; int next_; // always in loop thread boost::ptr_vector&lt;EventLoopThread&gt; threads_; std::vector&lt;EventLoop *&gt; loops_;}; TcpServer每次新建一个TcpConnection就会调用getNextLoop()来取得一个Event-Loop。 使用io_uring的改写muduo原生支持epoll和poll两种poller，都是为Poller基类派生出来，现在派生出一种新的Poller，叫UringPoller如下，包含了uring需要的资源，如sqe,cqe， 然添加新的接口： add_accept add_socket add_socket_write add_provide_buf 都是向sqe队列中添加读写事件，等待内核完成后返回给cqe队列。 基于iouring实现新的Poller12345678910111213141516171819202122232425262728293031323334class UringPoller : public Poller{public: UringPoller(EventLoop *loop); ~UringPoller() override; TimeStamp poll(int timeout, ChannelList *active_channels) override; void update_channel(Channel *channel); void remove_channel(Channel *channel);private: //填写活跃的链接 void fill_active_channels(int events_num, ChannelList *active_channels) ; //更新channel，调用epoll_ctl //void update(int operation, Channel *channel); void add_accept(Channel* channel, struct sockaddr *client_addr, socklen_t *client_len, unsigned flags); //新链接 void add_socket_read(Channel* channel, unsigned gid, size_t message_size, unsigned flags); void add_socket_write(Channel* channel, unsigned flags, const string &amp;buf); void add_provide_buf(__u16 bid, unsigned gid);private: static const int k_init_eventList_size_ = 16;private: conn_info* conns; char bufs_[BUFFERS_COUNT][MAX_MESSAGE_LEN] = {0}; int group_id_ = 1337; struct io_uring_params params_; struct io_uring ring_; struct io_uring_sqe *sqe_; unsigned count; struct io_uring_cqe *cqes_[BACKLOG];}; 使用UringPoller以add_socket_read为例：当一个新的连接到来，main reactor会用轮询的方式选择一个sub reactor，然后创建TcpConnection，这个新的连接就由选择出来的sub reactor所属的eventloop负责，然后建立连接的回调函数就会在这个eventloop的poller里添加负责管理这个新fd的channel的事件监听。 12345678910void TcpConnection::establish_connect(){ set_state(k_connected); channel_-&gt;tie(shared_from_this()); channel_-&gt;enable_reading(); //向poller注册channel的epollin事件 printf(\"get fd from channel fd = %d\\n\",channel_-&gt;get_fd()); loop_-&gt;poller_-&gt;add_socket_read(channel_.get(), 1337, 0, 0); //新连接建立 connection_callback_(shared_from_this());} 这里自己定义了一个结构体conn_info，把这个结构体放在sqe的user_data域里，等内核处理完成后，返回的cqe队列也会有这个conn_info,这样就能知道那个channel发生了（完成了）事件。 123456typedef struct conn_info { __u32 fd; __u16 event; __u16 bid; Channel* channel;} conn_info; 1234567891011121314void UringPoller::add_socket_read(Channel* channel, unsigned gid, size_t message_size, unsigned flags) { int fd = channel-&gt;get_fd(); conn_info *conn_i = &amp;conns[fd]; printf(\"add_socket_read:fd = %d\\n\",fd); struct io_uring_sqe *sqe = io_uring_get_sqe(&amp;ring_); io_uring_prep_recv(sqe, fd, NULL, 0, 0); //读0长度，只关注事件是否发生。 io_uring_sqe_set_flags(sqe, flags); sqe-&gt;buf_group = gid; conn_i-&gt;fd = fd; conn_i-&gt;event = READ; conn_i-&gt;channel = channel; io_uring_sqe_set_data(sqe, conn_i);} UringPoller的poll实现对于UringPoller，实现poll成员函数： 123456789101112131415161718192021TimeStamp UringPoller::poll(int timeout, ChannelList *active_channels){ count++; int ret = io_uring_submit_and_wait(&amp;ring_, 0); //提交sq的entry if (ret &lt; 0) { printf(\"Returned from io is %d\\n\", errno); perror(\"Error io_uring_submit_and_wait\\n\"); LOG_ERROR(\"%s\", \"io_uring failure\"); exit(1); } //将准备好的队列填充到cqes中，并返回已准备好的数目，收割cqe int cqe_count = io_uring_peek_batch_cqe(&amp;ring_, cqes_, sizeof(cqes_) / sizeof(cqes_[0])); TimeStamp now(TimeStamp::now()); if (cqe_count &gt; 0) { LOG_INFO(\"%d events happened \\n\", cqe_count); fill_active_channels(cqe_count, active_channels); } //返回发生事件时间点 return now;}","link":"/2022/03/25/muduo%20with%20iouring/"},{"title":"storage-network paper read","text":"存储网络论文： From Luna to Solar: The Evolutions of the Compute-to-Storage Networks in Alibaba Cloud When Cloud Storage Meets RDMA X-RDMA: Effective RDMA Middleware in Large-scale Production Environments From Luna to Solar When Cloud Storage Meets RDMA 这篇论文介绍了将RDMA引入盘古存储网络的相关经验。就是存储节点之间的网络通信。（NSDI 2021） pangu 以块存储为例介绍了盘古的框架。 计算节点： client node，将数据组织成固定大小（32GB）的段。 存储节点：BlockServer和ChunkServer 计算节点中的每个段都和BlockServer对齐来进行IO处理。 在BlockServer上，一个segment被分成块并复制到ChunkServer上，ChunkServer负责块的存储和设备管理。 Master节点： BlockMaster：管理元数据，例如段和其所在的BlockServer之间的映射以及BlockServer的状态。 PanguMaster：管理ChunkServer的状态。 Master节点之间通过Raft协议进行同步。 Motivation存储介质的快速发展使得网络成为云存储的瓶颈。具体来说是nvme的快速发展。 Non-Volatile Memory Express (NVMe) ： 延迟：us级 带宽：100Gbps 传统网络协议栈： 延迟：ms级 带宽：几十Gbps RDMA：在主机nic上实现整个协议栈，代替传统网络协议栈。 延迟：us级 带宽：100Gbps 而且cpu开销几乎为0 挑战可用性、SLA（server level agreement）、未知的PFC 风暴源 RDMA部署考虑因素存储容量与需求匹配、控制硬件成本、优化性能、最小化可用性和SLA风险。最终的结果是在所有这些因素之间进行权衡。 盘古的部署可用性优先原则 网络拓扑结构基于Clos的网络拓扑结构，与常见的dual-home做法相一致，署了Mellanox CX系列双端口RNIC，用两个不同的ToR交换机连接主机。 特别是，两个物理端口绑定到一个IP地址。网络连接（例如，RDMA中的QPs）在两个端口上以循环方式进行平衡。当一个端口down时，此端口上的连接可以迁移到另一个端口。 RDMA范围为了最小化故障域，只在每个podset内部和存储节点之间启用RDMA通信。计算节点和存储节点之间的通信通过user space TCP协议。这是由于计算节点的硬件配置复杂，更新速度快。因此，TCP可以有效地作为一种独立于硬件的传输协议来应用。内核TCP由于其通用性而被选择用于跨podset通信。 性能优化优化目标：最大化吞吐量的同时最小化延迟。 目前的障碍存储设计将RDMA协议栈集成在存储后端。 USSOS（用户空间存储操作系统），基于用户空间技术（如DPDK和SPDK），在盘古上使得cpu效率提高了五倍以上。 USSFS是USSOS的核心部分之一，是为ssd设计的高性能用户态文件系统。USSOS将磁盘划分为chunks，ChunkServer有对应的api来管理这些chunks，并通过轮询来感知完成事件。USSFS能比而ext4文件系统调高4-10倍的iops。 run-to-completion模型被认为是RDMA网络堆栈与存储堆栈集成的最佳方法。然而，这些研究是在2017年将RDMA引入盘古之后发表的。Reflex和i10侧重于远程直接I/O，而盘古的ChunkServer则作为本地存储引擎用于分布式存储。 内存瓶颈随着网络速度的提高，内存吞吐量成为系统瓶颈。 使用Intel memory Latency Checker（MLC）工具测试内存吞吐量，在测试中，最大可实现内存带宽为61GB/s，读写比为1:1。但是，盘古的平均内存吞吐量已经是29GB/s + 28GB/s = 57GB/s。这表明内存是瓶颈，而不是网络。 需要优化的是验证和数据复制的过程。目前，RDMA收到的数据分成4KB的块，每个块上会加入4B的crc和44B的间隔。在写磁盘时，还会发生数据复制。 大量QPs 我们曾经在盘古中的运行线程之间采用全网状链接模式，以最大化吞吐量并最小化延迟。假设每个ChunkServer有14个线程，每个BlockServer有8个线程，并且每个节点都包含ChunkServer和BlockServer。对于由100个存储节点组成的集群中的全网格模式，每个节点中可能有14×8×2×99 = 2,2176个QP。由于高速缓存未命中，对于大量QP，RNIC的性能急剧下降。尤其是RX pause（即接收到的PFC暂停帧）的数量非常多。为了解决这个问题，FaSST（一篇文章） 在线程之间共享QP，由于线程之间QP的锁争用，随后降低了CPU效率和性能。另一种启发式方法是包括专用的代理线程，该线程管理所有的接收和发送请求。但是，切换到专用代理线程或从专用代理线程切换会增加延迟。此外，很难用单个线程饱和整个网络带宽。此外，代理解决方案对基础RDMA库不透明。 design最小化性能开销为设计原则。 storge-RDMA unified Run-to-Completion stack存储和网络都采用了Run-to-Completion的线程模型来实现低延迟。下图展示了请求处理的过程： 节点收到写RPC RNIC通过DMA将其发送到用户空间 RPC框架通过轮询获得请求，并将其交给ChunkServer处理。 ChunkServer通知ussfs为请求分配一个chunk资源。 用户空间驱动程序与nvme ssd交互以存储数据。 以上操作在单个服务器线程中执行，无需线程切换。 大的IO请求会被拆分成较小的请求，确保了对IO信号的快速响应。 附属工作，比如formatting和crc计算会交给非IO线程。 数据格式统一为IO vector，不需要序列化，使用scatter-gather DMA通过单个RDMA verb传输I/O vector。 不需要序列化是RDMA的语义决定的。 scatter-gather DMA可以通过单个中断传输不连续的数据。 零拷贝和CRC offloading在盘古，数据必须在I/O路径上复制一次，因为每个4KB数据块都经过验证并附有CRC footer。 利用RNICs的用户模式内存注册（UMR）特性来避免这种数据复制。 UMR可以通过定义适当的内存键（memory keys）将RDMA数据分散到远程端。UMR将来自发送方的连续数据重新映射到接收方的I/O缓冲区，其中每个单元包含4KB数据、4B页脚和44B的间隙。在CRC计算之后，填充的I/O缓冲区可以直接用于磁盘写入。此外，CRC计算能够被卸载到有能力的RNICs。 shared-link mode这是减少盘古QP数量的关键。，shared-link在应用程序中实现，不涉及RDMA库。 可用性保证PFC 风暴之前的研究 以前的一些研究中，PFC风暴来自于NICs，receiving pipeline存在bug，如上图(a)描述： bug减慢了NIC接收，缓冲区很快被填满 为了防止丢包，NIC将PFC pause发送到其ToR交换机 ToR交换机暂停传输 ToR交换机的缓冲区满，并且开始发送PFC pause 受害者的端口暂停，无法传输 盘古中的PFC风暴盘古在使用RDMA时，遇到了不同类型的PFC风暴，根本原因是特定供应商的交换机硬件存在bug，上图（b）中描述： 假设bug发生在ToR交换机的下行端口，the bug reduces the switching rate of the lossless priority queues to a very low rate. 由于传输速率低，交换机的缓冲区已满 交换机将PFC pause发送到连接的端口 附加交换机和NIC停止传输 连接到这个ToR交换机的leaf交换机和NIC收到连续的pause frame，造成了风暴。 之前的解决方案Guo et al.构建了一个基于NIC的看门狗来持续监控传输的暂停帧，必要时禁用PFC机制。该方案不能完全解决开关产生的PFC风暴问题。特别是，网卡上的TX pause看门狗将不工作，因为NIC只接收来自交换机的PFC风暴。 这种新型的PFC风暴使Guo等人的解决方案失效，该方案的重点是隔离PFC暂停源，以防止风暴扩散。当源是ToR交换机时，此方法失败，因为ToR中的所有主机都被风暴暂停。 盘古的解决方案我们处理PFC风暴的设计原则是escape as far as possible。 在盘古，每个网卡监控接收到的PFC暂停帧。对于连续暂停帧，NIC确定是否存在PFC风暴。在PFC风暴的情况下，管理员可以使用两种解决方案。 解决方法1：shutdown。关闭受PFC风暴影响的网卡端口数秒。dual-home拓扑为PFC风暴提供了一个紧急逃生通道，从而QP将断开连接并通过另一个端口再次连接。 此方法与优化一起使用，以减少QP超时的时间。 尽管此解决方案简单有效，但由于带宽损失了一半，因此不够理想。 解决方法2：RDMA/TCP切换。在这个解决方案中，PFC风暴中受影响的RDMA链路被切换到TCP链路。与关机解决方案相比，它会折中了一个更复杂的过程，但它能够保持可用带宽。我们检测PFC风暴中受影响的RDMA链路。在每 T ms，每个工作线程选择一个服务器，并通过RDMA和TCP链接分别ping它的所有线程。如果RDMA ping失败并且TCP ping成功超过F次，则此RDMA链路上的流量将切换到TCP链路。一旦RDMA ping成功超过S次，交换的TCP链路上的流量将切换回RDMA链路。 参考https://blog.csdn.net/Sylvia_Wu51/article/details/117325150 X-RDMA 介绍了X-RDMA中间件，轻量，但功能齐全。RDMA的特点：超低延迟（2us）,高吞吐量，支持零拷贝和kernel bypass，减少传统协议栈的开销，例如上下文切换、协议处理和数据复制。 背景RDMA编程模型RDMA支持两种常用的模式：可靠连接（RC）和不可靠数据报（UD）。 RDMA 有两种通信范式： 内存语义（单向）： Write/Read/Atomic 以访问远程内存而无需对等方 CPU 参与。 类似传统以太网（双向）：Send/Recv 。 RDMA中的抽象结构：Queue Pair (QP) 代表一对完成队列（CQ）：发送队列（SQ）和接收队列（RQ）。 在建立连接之前，节点应该创建一个受保护域（PD），然后使用这个 PD 注册一个或多个内存区域MR（memory region）和一个唯一的远程密（rkey）。 仅当 rkey 正确时，才允许访问受 MR 保护的内存。 每个 RDMA 操作都需要向相应的 CQ 发布工作请求 WR（work request），每个 CQ能容纳的WR有一个深度上限。 在双向模式下，接收方应预先将 WR 发送到其 RQ，然后发送方发送请求并指示有效负载的缓冲区地址。 最后，接收方应轮询此 RQ 以确保数据包到达。 在完成一个 RDMA 操作后，会生成一个完成队列条目 (CQE)。 在单边模式下，只有发送方需要发布一个WR。 单侧 RDMA 操作总是比双侧 RDMA 操作具有更好的性能 RDMA Write 和 Send 都支持额外的即时数据，可以立即用 uint_32 数据通知接收方。 总之：RDMA 程序需要一个复杂的仪式：初始化上下文、注册内存、建立连接、交换元数据、创建 QP、修改 QP 以“准备发送/接收”，最后发送/轮询 WR/CQE。 Alibaba中的网络部署 Top of Rack (ToR) 一个典型的数据中心包含三层： the spine layer, the leaf layer, and the ToR layer。 通常的配置是：四十个节点连接到一个 ToR 交换机。 ToR 交换机连接到leaf交换机，leaf交换机连接到spine交换机。 RDMA use case阿里巴巴数据中心的三个代表应用：增强型固态硬盘 (ESSD)、X-DB 和 PolarDB。 盘古的每台服务器上有两个关键组件：chunkserver和blockserver 每个block server从前端（例如ESSD中的虚拟机）中接收数据，然后通过全网状（full-mesh）RDMA通信将二或三个副本分发到不同的chunkserver上。 目前阿里巴巴有两个核心产品使用了盘古：ESSD和X-DB。 ESSD 的一半 I/O 路径是从具有 QEMU/KVM 虚拟化的虚拟机到盘古。 X-DB 是一个分布式数据库，它为交易系统（例如在线购物网站）提供高可用性、强 ACID 和水平可扩展性。 X-DB的前端是Docker中的MySQL实例，使用RDMA连接盘古。 PolarDB则不同，它的实现有两种模式：一种是针对自己的后端，另一种是针对盘古。 两种模式都使用RDMA。 大规模部署的问题编程模式复杂原生 RDMA 库（即 libverbs）比传统的套接字编程更复杂。 需要对RDMA库API进行适当的简化和分类。 扩展性挑战 RDMA资源占用会随着集群规模的扩大而迅速增加。RDMA最大的优势之一是零拷贝，但单边模式需要按需分配内存，即在每个连接开始任何传输之前就预留更多的内存。 相反，在 TCP/IP 中，内核可以自动管理缓冲区。 大规模 RDMA 网络中普遍存在拥塞和大量 incast 。我们生产服务器中的典型场景是盘古或 ESSD 等分布式存储，并且始终遵循 incast 流量模式 。此外，类似于 Facebook 中的部署 ，网络工作负载总是在饱和和不饱和之间切换，它很容易使 RNIC 因拥塞而过载。另一方面，拥塞也会导致抖动。尽管有微调的 DCQCN，但由于大 - 大小消息阻塞 RNIC 处理 ，在较大的集群中观察到一些严重的抖动情况。在生产环境中，严重的抖动会导致 70% 的吞吐量下降（从 3.4 GBps 到 1.1 GBps）和 2×∼15× 的延迟。 连接建立速度慢会延迟恢复并增加集群返回稳定状态的时间。使用 RDMA_CM的 RDMA 的连接建立时间约为 4 毫秒，而 TCP 几乎为 100 微秒。 鲁棒性低 发送方很难通过RDMA单方面操作了解接收方应用程序的处理进度, 发送方不知道进度并继续发送，导致RNR 错误，增加重传率，从而浪费网络带宽和 CPU 周期。 原生 RDMA 库和 RNIC 无法确保对等端始终处于活动状态。 bug和性能干扰需要做一些运维工具 Conditional Performance Maximization满足需求的同时最大化性能。也是设计X-RDMA的原则 X-RDMA设计overall architecture三层，16个主要组件： 最上层 提供了三个抽象的数据结构：context, channel, and msg. 八个主要api： 中间层 X-RDMA 实现了可靠协议扩展、资源管理、流量控制和性能分析组件。 底层 timer、fd、task这些是X-RDMA的底层。 总的来说，这些组件分为四个独立的系统，为不同的开发者带来了便利，牺牲了不常用的功能，以避免复杂的编程抽象陷阱。 线程模型由于使用现代 RNIC 的延迟可以低至纳秒级，因此即使在最坏的情况下，数据平面上的所有操作也可以在恒定时间 (O(1)) 内完成，以匹配较低的网络延迟。 X-RDMA 采用lock -free、atomic-free 和 no-syscall 策略，以减少用户空间和内核空间之间总线锁定和上下文切换的开销。避免使用任何锁，只允许非关键路径上的原子操作和系统调用。 X-RDMA的线程模型设计原则一般是run-to-complete。高层资源，如context、channel、memCache、QP cache等，都是在per thread级别进行操作，避免线程间同步。这些资源 将在每个上下文中仅初始化一次。X-RDMA 使用混合轮询方式，其中一个线程首先使用 epoll，然后在触发消息或定时器事件时切换到忙轮询，类似于 Linux 内核中的 NAPI。X-RDMA向per-thread timer注册一些事件，包括keepAlive、statistic等。在空闲时间，轮询模式可根据应用程序的方案进行配置。 消息模型多进程之间采用请求-响应的方式进行通信。 X-RDMA 采用混合消息策略，包括两种模式：用于最大化性能的小消息模式和用于减少内存占用的大消息模式。荷载有个阈值S（默认4KB），小于S视为小消息。 区分两种模式的原因：buffer预分配阶段带来的较大的开销。 Small Messages v.s.Large Messages 对于小消息，发送方直接向接收方发送数据，从而触发接收WR。每次数据传输只需要一次RDMA操作。但是，接收方需要预先分配足够的缓冲区。 因此，小消息的payload size不能太大，否则会消耗更多的缓冲区，从而导致内存消耗高。 对于大消息，发送方会先发送一个RDMA Send WR来唤醒接收方。接收方准备 RDMA enabled buffers on demand。我们称这个阶段为buffer preparation phase。之后，实际的数据传输依赖于发送端的RDMA写/读。在这种模式下，每次数据传输至少需要两次RDMA操作。 在生产环境中，小消息比通常传输时间较长的大消息对高延迟更敏感。在某种程度上，大消息可以通过准备好的缓冲区来容忍延迟的一点点降低。 Read Replace Write X-RDMA 支持内置 RPC。在大多数 RPC 实现中，接收方将响应发回给发送方。大尺寸响应是禁止处理的。由于发送方不知道响应的有效负载大小，发送方 端应该为接收端保留“超大”缓冲区，以便通过 RDMA Write 将响应写回。更糟糕的是，在 RPC 场景中，RDMA 出站操作（Write）总是比入站操作（Read）慢 接收方。为了解决这个问题，X-RDMA 允许发送方直接处理响应。接收方应该让发送方知道响应的大小和地址，发送方将通过 RDMA Read 被动获取响应 。 Work Flow","link":"/2023/05/08/storage-network-paper-read/"},{"title":"内核开发","text":"基本特点Linux是单内核的（也叫宏内核），较少了消息传递的开销（函数调用形式），性能会更好，但是可扩展性就会比较差。为了改善单内核的可维护性，Linux提出了内核模块机制，用户可以在不对内核重新编译的情况下，动态向内核装入和移除模块。 微内核和宏内核的根本区别是，微内核是进程间通信，宏内核走函数调用。 模块的本质是一种目标对象文件，不能独立运行，但是其代码可以在运行时连接到系统中作为内核的一部分运行，从而动态扩展内核的功能。 对比应用程序和内核模块 C语言应用程序 内核模块程序 使用函数 Libc库 内核函数 运行空间 用户空间 内核空间 运行权限 普通用户 超级用户 入口函数 main() module_init() 出口函数 exit() module_exit() 编译 Gcc –c Makefile 连接 Gcc insmod 运行 直接运行 insmod 调试 Gdb kdbug, kdb,kgdb等 内核开发中没有libc，标准头文件。考虑大小，内核页禁止患处，常驻内存，不能太大。 应使用GNU C，不完全符合ANSI C标准 关注的语法特性 inline c99标准引用 内联汇编：asm volatile(……) 分支优化预测，likely、unlikely给编译器提示，这是kernel代码中定义的宏，c++20才作为关键字 没有内存保护机制 不要轻易在内核中使用浮点数 内核态进程使用浮点操作时，内核会完成从整数模式到浮点操作模式转换 通常时通过捕获陷阱进行转换 内核本身不能陷入，需要人工保存、恢复浮点寄存器。 函数调用栈很小，所以别用局部大数组 默认情况下，64位栈大小为8kb 不要使用局部数组、不要使用递归调用 非要递归，写尾递归 尾递归 f(int n) { if(n==1) return 1; return n*f(n-1); } 改写 f(int res, int n) { if(n==0) return res; return f(res*n,n-1); }//编译器会自动展开成循环 &lt;!--code￼0--&gt; 12345678910111213141516171819202122232425262728293031323334(gdb) disass func1Dump of assembler code for function func1: 0x00000000000001e5 &lt;+0&gt;: callq 0x1ea &lt;func1+5&gt; 0x00000000000001ea &lt;+5&gt;: push %rbp 0x00000000000001eb &lt;+6&gt;: mov %rsp,%rbp 0x00000000000001ee &lt;+9&gt;: cmp $0x8,%edi //8和edi比较 0x00000000000001f1 &lt;+12&gt;: jle 0x206 &lt;func1+33&gt; //小于等于（小概率）发生跳转 0x00000000000001f3 &lt;+14&gt;: mov $0xa,%esi 0x00000000000001f8 &lt;+19&gt;: mov $0x0,%rdi 0x00000000000001ff &lt;+26&gt;: callq 0x204 &lt;func1+31&gt; 0x0000000000000204 &lt;+31&gt;: jmp 0x217 &lt;func1+50&gt; 0x0000000000000206 &lt;+33&gt;: mov $0x2,%esi 0x000000000000020b &lt;+38&gt;: mov $0x0,%rdi 0x0000000000000212 &lt;+45&gt;: callq 0x217 &lt;func1+50&gt; 0x0000000000000217 &lt;+50&gt;: pop %rbp 0x0000000000000218 &lt;+51&gt;: retq End of assembler dump.(gdb) disass func2Dump of assembler code for function func2: 0x0000000000000219 &lt;+0&gt;: callq 0x21e &lt;func2+5&gt; 0x000000000000021e &lt;+5&gt;: push %rbp 0x000000000000021f &lt;+6&gt;: mov %rsp,%rbp 0x0000000000000222 &lt;+9&gt;: cmp $0x8,%edi //8和edi比较 0x0000000000000225 &lt;+12&gt;: jle 0x23a &lt;func2+33&gt; //编译器问题没起作用，以前的编译器是jg,所以现在编译器大概不支持了。一般默认if里面直接跟的是小概率事件 0x0000000000000227 &lt;+14&gt;: mov $0xa,%esi 0x000000000000022c &lt;+19&gt;: mov $0x0,%rdi 0x0000000000000233 &lt;+26&gt;: callq 0x238 &lt;func2+31&gt; 0x0000000000000238 &lt;+31&gt;: jmp 0x24b &lt;func2+50&gt; 0x000000000000023a &lt;+33&gt;: mov $0x2,%esi 0x000000000000023f &lt;+38&gt;: mov $0x0,%rdi 0x0000000000000246 &lt;+45&gt;: callq 0x24b &lt;func2+50&gt; 0x000000000000024b &lt;+50&gt;: pop %rbp 0x000000000000024c &lt;+51&gt;: retq End of assembler dump. 内核模块机制： 首先需要了解内核符号表的概念，内核符号表存放了所有模块可以访问的符号及相应的地址，模块声明的任何全局符号都成为内核符号表的一部分。 内核符号表处于内核代码段的_ksymtab部分，其开始地址和结束地址是由C编译器所产生的两个符号来指定：__start_ksymtab和_stop_ksymtab。 内核模块没有main函数，通过回调方式运行 回调：向内核注册函数，然后应用程序触发函数的执行，比如驱动程序在初始化时，向内核注册处理某个设备写操作的函数，当应用程序使用write系统调用写该设备时，内核就会调用注册的回调函数。 内核模块makefile编写1234567891011121314151617181920212223242526272829303132ifneq ($(KERNELRELEASE),)#检查KERNELRELEASE是否已经被定义 obj-m := PrintModule.o #说明有一个模块需要从PrintModule.o中构造，而该模块名为PrintModule.ko PrintModule-objs := DriverMain.o DriverFileOperations.o #说明PrintModule由多个目标文件构成，一个.o文件就是一个编译单元,一个.c生成一个.oEXTRA_CFLAGS := -DTEST_DEBUG -ggdb -O0#DTEST_DEBUG 是代码中定义的debug宏#-ggdb 加入调试信息#-O0 优化级别，没有优化#-O1 基本优化级别#-o2 主要优化时间效率，不考虑生成的目标文件大小#-O3 最高优化级别，一般不用#-Os 优化生成的目标文件大小，并且激活-O2中不增加代码大小的优化选项#-Og gcc4.8中引入的优化级别。编译快，同时合理提供运行效率。else KERNELDIR ?= /lib/modules/$(shell uname -r)/build #?=表示如果KERNELDIR还没赋值，则赋值 #$(shell uname -r) 获取当前内核版本号 #/lib/modules/$(shell uname -r)存放编译好的内核模块符号信息 #build是一个符号连接，指向了/usr/src/linux-headers-xxxxx-generic，里面包含了内核头文件，用于编译内核模块的各个Makefile PWD := $(shell pwd) # 保存当前路径default: #default都会执行 $(MAKE) -C $(KERNELDIR) M=$(PWD) modules #MAKE：就是执行make #-C:切换目录到$(KERNELDIR)，因为这里有顶层makefile文件，编译内核模块之前需要对这个顶层的内核模块进行处理 #在顶层makefile文件中，就定义了KERNELRELEASE #KERNELRELEASE = $(shell cat include/config/kernel.release 2&gt; /dev/null) #M表示在构造内核模块之前，回到目录PWD，再次执行当前目录下的Makefile rm *.order *.symvers *.mod.c *.o .*.o.cmd .*.cmd .tmp_versions -rfendif 优化和调试级别优化 -O0 优化级别，没有优化 -O1 基本优化级别 -O2 主要优化时间效率，不考虑生成的目标文件大小 -O3 最高优化级别，一般不用 -Os 优化生成的目标文件大小，并且激活-O2中不增加代码大小的优化选项 -Og gcc4.8中引入的优化级别。编译快，同时合理提供运行效率。 调试级别 -g 利用操作系统native format生成调试信息，调试器可以直接使用，默认是-g2 -g2 包含扩展的符号表，行号，局部或外部变量信息 -g3包含2中的所有调试信息，外加源码中定义的宏 -ggdb 是gcc为gdb专门生成的调试信息，只能用gdb调，默认是-ggdb2 -ggdbx，x跟在-gx的解释一样 -g0其实是不包含调试信息，等于不使用-g -g1不包含局部变量和行号有关的调试信息，因此只能用于回溯跟踪（函数调用历史）和堆栈转储 内核源码各目录功能du -sh 源码大概800mb arch是体系结构相关的代码 arm/boot是启动相关的代码 mach-xxx开头是不同公司针对硬件平台增加的代码，比如三星的飞思卡尔的，不同的硬件平台配置不同。 /Documentaion 是内核说明 /firmware 固件芯片相关 /init 内核初始化代码，汇编代码会调用start_kernel函数，do_mount挂载文件系统 /usr是测试代码，不用看了 /block 块设备相关代码 /drivers 是驱动代码，占据了内核代码的一半以上。 /fs文件系统代码 /ipc 进程通信相关代码 /kernel 内核核心通用代码，比如进程 /arch/arm/kernel 是体系结构相关的内核代码，kernel里的代码会调用这里面的 /net 网络子系统相关代码 /crypto 加密相关 /sound 声卡相关 /include 内核头文件相关 /lib 通用库，给内核各个模块使用 /mm 内存管理，页表页表管理等等 /scripts 编译内核的脚本 编译内核顶根目录下有一个makefile文件，各个子目录下也有makefile文件。 顶层makefile通过include子目录下的makefile文件。 顶层makefile首先会include体系结构相关的makefile文件 123SRCARCH := $(ARCH)...include arch/$(SRCARCH)/Makefile 子目录，顶层makefile会调用这些子目录的makefie： 123456init-y := init/drivers-y := drivers/ sound/ firmware/net-y := net/libs-y := lib/core-y := usr/virt-y := virt/ 比如drivers/tty里的，Kconfig文件是make menuconfigkey看见的配置文件，makefile里面就是那些文件应该编译成ko或者哪些不需要编译。 里面都是obj打头的变量。-y表示编译到内核里，-m表示编译成驱动的形式 123456789101112```Kconfig支持编译到内核里还是编译成内核模块还是不编译。-y表示编译到内核里，-m表示编译成驱动的形式obj-y += 目录 意思是到下级目录继续编译build-in.o是这个目录下所有.o文件的链接文件然后顶层makefile再把所有build-in.o链接成内核镜像定义lds一个链接文件，位于arch/$(SRCARCH)/kernel下。 export KBUILD_LDS := arch/$(SRCARCH)/kernel/vmlinux.lds 12345678910111213141516```makefilevmlinux-dirs := $(patsubst %/,%,$(filter %/, $(init-y) $(init-m) \\ $(core-y) $(core-m) $(drivers-y) $(drivers-m) \\ $(net-y) $(net-m) $(libs-y) $(libs-m) $(virt-y)))vmlinux-alldirs := $(sort $(vmlinux-dirs) $(patsubst %/,%,$(filter %/, \\ $(init-) $(core-) $(drivers-) $(net-) $(libs-) $(virt-))))init-y := $(patsubst %/, %/built-in.a, $(init-y)) #内置函数core-y := $(patsubst %/, %/built-in.a, $(core-y))drivers-y := $(patsubst %/, %/built-in.a, $(drivers-y))net-y := $(patsubst %/, %/built-in.a, $(net-y))libs-y1 := $(patsubst %/, %/lib.a, $(libs-y))libs-y2 := $(patsubst %/, %/built-in.a, $(filter-out %.a, $(libs-y)))virt-y := $(patsubst %/, %/built-in.a, $(virt-y)) KBUILD_CFLAGS += -I/root/kernel-ml/include这样可以添加头文件 为了方便，下载与当前系统相同的内核版本进行修改，这样编译不容易出错。然后用当前系统的config文件基础上进行。编译内核的时候为了方便调试尽量不要优化。-02改成-O1。-O0会编不过 12345678cp /boot/config-xxxx-generic /pwd/.configmake oldconfigmake-kpkg cleanmake-kpkg --initrd kernel-headers kernel_image#记得安装apt install kernel-package, libncurses6-dev等#然后会生成headers.deb和image.deb,在内核源码的上层目录下。dpkg -i *.debreboot 编译成功后的效果： 安装了linux-headers文件 ls /usr/src/ #里面会有对应版本的headers文件夹 #里面存放了用来编译内核模块的内核makefile，包括顶层makefile,用来编译内核模块 #include里面就是头文件 12345678910111213141516171819202122232425* `/lib/modules`新增了对应版本的文件夹，里边的build、source指向了刚刚编译内核的目录* `/boot`目录下增加了config-xxxx，inintrd.img，符号表信息System.map-xxx，内核映像vmlinuz-xx（理解成内核的可执行文件）* 启动项里也有增加，`vi /boot/grub/grub.cfg`什么是initrd系统启动的过程中，一个重要的任务就是mount根文件系统，里面存放了大部分系统程序而要mount根文件系统，必须有磁盘的驱动程序和文件系统驱动程序由于硬件和兼容性的限制。内核影响的大小不能太大Linux需要尽可能的支持多的硬件设备，但是由于内核映像大小的的限制，不能随便把硬件设备驱动程序放入内核映像中。于是将各种硬件设备、文件系统的驱动程序模块化。发行商提供内核映像、系统安装程序，系统安装过程中，会跟根据当前硬件设备情况，选出系统启动需要的驱动程序，并据此制作成initrdinitrd相当于一个临时的根文件系统，其中存放了系统启动必须的各种驱动程序### 修改grub启动项```shellgrep menuentry /boot/grub/grub.cfg 1vim /etc/default/grub 修改GRUB_DEFAULT，submenu之间用&gt;连接 kgdb原理 一台目标机，target、服务器，运行kgdb，需要调试时。目标机启动kgdb，控制权就移交给kgdb。等待连接gdb连接 一台开发机，host，客户端，运行gdb，调试命令发送给目标机。使用gdb连接目标机的kgdb。发起连接 调试器基本原理断点如何实现设置断点，调试器会将断点处的内存修改为0xcc，也就是int3 运行到断点，相当于执行int3的处理函数，就是调试器的主要工作环境 然后调试器再把断点处的0xcc修改为原值 环境搭建 step1：编译内核 尽量不要优化编译，去优化。makefile文件里的-O2改成-O1。 不要设置优化大小CONFIG-CC_OPTIMIZE_FOR_SIZE 设置CONFIG_DEBUG_SECTION_MISMATCH,相当于-fno-inline-functions-called-once,避免inline优化 step2：利用VMWare clone虚拟机 step3：为两个系统配置串口 目标机：cat /dev/ttyS1 开发机：echo \"test\" &gt; /dev/ttyS1 step4：配置grub.cfg，禁止内核地址随机化（nokaslr），不要直接改.cfg 修改/etc/default/grub文件，增加：GRUB_CMDLINE_LINUX=”nokaslr rootdelay=90quiet splash text kgdboc=ttyS1,115200” 坑：增加后实验2.4会死机？，不知道为什么 执行#update-grub 内核源码调试目标机：echo g &gt; /proc/sysrq-trigger 开发机： 12345678910gdb ./vmlinuxset serial baud 115200target remote /dev/ttyS1b do_init_module#获取模块段地址p mod-&gt;sect_attrs-&gt;nsections#找到内核模块各个段的名字p mod-&gt;sect_attrs-&gt;attrs[2]-&gt;battr-&gt;attr-&gt;name#找到模块段的地址p mod-&gt;sect_attrs-&gt;attrs[2]-&gt;address 找出代码段、数据段、bss段地址： 然后设置各段地址： add-symbol-file /mnt/hgfs/lilin-linux/homework/1/driver/AddModule.ko 0xffffffffc0680000 -s .data 0xffffffffc0682000 -s .bss 0xffffffffc06824c0 然后就可以对模块进行打断点调试等等。 进程的用户栈和内核栈用户栈： 基于进程的虚拟地址空间的管理机制实，以VMA的形式实现 内核栈： 每个进程都有自己的内核栈，一般是4k，一个page。作为task_struct的一部分。每个进程可能通过系统调用进入内核，内核会代表进程执行一些代码，会保存一些私有的数据，这时候就要用内核站。 task_struct描述了linux进程的通用部分 里面的一个结构体thread_info 描述了特定体系结构的汇编代码段需要访问的那部分进程的数据。定义在arch/arm/include/asm/thread_info.h 是不同体系下进程的描述。 内核同步场景源码相关GDT表管理代码管理GDTR必须要专门的指令，lgdt和sgdt 内核一定会使用lgdt指令把GDT表的及地址写入GDTR寄存器 所以在源码文件中搜索出现了lgdt指令的地方 方法是利用源码搜索网站结合观察源码一层层找 最后找到内核用gdt_page管理GDT表 1234567891011121314151617181920212223242526272829303132333435363738struct pv_cpu_ops { ... void (*load_gdt)(const struct desc_ptr *); ...}//间接层，类似于vfs的接口static inline void load_gdt(const struct desc_ptr *dtr){ PVOP_VCALL1(cpu.load_gdt, dtr);}//x86平台的load_gdt实现void load_direct_gdt(int cpu){ struct desc_ptr gdt_descr; gdt_descr.address = (long)get_cpu_gdt_rw(cpu);//返回了gdt表的地址 gdt_descr.size = GDT_SIZE - 1; load_gdt(&amp;gdt_descr);}//调用了load_gdt的地方EXPORT_SYMBOL_GPL(load_direct_gdt);static inline struct desc_struct *get_cpu_gdt_rw(unsigned int cpu){ return per_cpu(gdt_page, cpu).gdt;}//get_cpu_gdt_rw做了什么struct gdt_page{ struct desc_struct gdt[GDT_ENTRIES];}//真正的GDT表struct desc_struct { u16 limit0; u16 base0; u16 base1:8, type: 4, s: 1, dpl: , p:1; ...}//这里就是Intel手册中的段描述符，就是GDT表的表项。 GDT全局描述符表位于内存中，每个CPU对应一个GDT __thread和PerCPUPerCPU假设有一个per cpu变量int x, x存在于内核映像文件.data..percpu段内。当系统初始化时，内核会为每个cpu都分配per cpu内存空间，并向其中复制一份.data..percpu段内的所有内容。 pvopspvops接口来源于Xen项目，初衷是建立一个类虚拟化(para-virtualized）内核来适应于不同的hypervisor(虚拟层)，当然也包括适应于非虚拟化平台。 pvops将类虚拟化操作分成一系列结构：pv_time_ops,pv_cpu_ops,pv_mmu_ops,pv_lock_ops和pv_irq_ops。 举个例子，x86系统中利用MOV CR3指令来加载页表。pvops将其替换为一个间接跳转到pv_mmu_ops -&gt; write_cr3函数。 每种虚拟化平台，对这些函数都有自己的实现。上面是load_gdt在x86的实现。 https://diting0x.github.io/20170101/pvops/ 问题：gdt表是一个cpu一个吗？ page fault两个例子：mmap，fork的写时复制 堆栈地址范围 内核编了，kgdb调 kpti","link":"/2022/03/01/%E5%86%85%E6%A0%B8%E5%BC%80%E5%8F%91/"},{"title":"编译原理复习","text":"编译基本过程：词法分析、语法分析、语义分析、中间代码生成、编译优化、目标代码生成 数据类型对存储器中存储数据的抽象，包括一组值和一组操作 分类 内部数据：语言自己定义的数据 用户定义数据：运行程序员利用数据的聚合机制，定义复杂的数据对象 笛卡尔积：例如 正多边形的 边数X边长 有限映像：通过下标变量对应的函数 序列：任意多个数据项，但类型相同 递归：通过指针构建 判定或：union，c语言中union使用同一段内存 幂集：类型T的元素所有子集的集合 抽象数据类型 C语言中的数据类型 类型检查对语言按照数据类型分类： 无类型语言 强类型语言：所有类型检查要在编译时完成（C） 弱类型语言：类型检查要全部或部分要在运行时完成（PASCAL） 类型转换类型转换分为： 扩展：整型—&gt;实型 收缩：实型—&gt;整型 语言应该提供的类型转换机制： 隐式转换（自动） 显示转换（强制） 类型等价T1和T2是两个类型T1的任何值都可以赋给T2的变量，反之亦然T1实参可对应T2形参，反之亦然则T1和T2类型等价（相容） 实现模型数据类型的实现模型，用描述符和数据对象表示 描述符：描述数据对象的属性数据 数据对象：存储区及其内容 绑定：一个对象与其某种属性建立起某种联系的过程。 内部类型描述符一般由类型和一个指针组成： 用户定义类型 笛卡尔积： 各成分顺序排列，每个成分占整数个可编址存储单元 描述符包含：类型名，构造符，若干三元式（选择符名、域类型、指针），每个域对应一个三元式 有限映像： 每个成分分配整数个可编址的存储单元 描述符包含：类型名、构造符、定义域的基类型、下界、上界、成分类型、（每个成分占有的）单元个数、首地址 序列 静态描述符+动态描述符+堆 判定或： 对判定或类型变量分配的空间要足够容纳需要最大空间的变体的值 PASCAL的变体记录包括：描述符、数据对象、case表、若干变体描述符 幂集 控制结构语句级控制结构分为：顺序、选择、重复 重复的两种控制方式：计数器制导（for循环知道循环次数）、条件制导（while循环） 单元级控制结构：显示调用、异常处理、协同程序、并发单元 区分协同程序和并发单元：协同程序是伪并行的，是交错执行。 异常处理：被调用单元是隐含的 程序语言设计语言的定义、语义描述、语法描述语言 = 语法 + 语义 可以从生成（文法）和识别（语法图）的角度描述语法。 文法和语法图是语法的等价表示。 语义尚无描述工具，一般用自然语言。可以用操作语义学的抽象机行为来描述语法单位的作用和意义。 抽象机GAM： 存储器、控制器、处理器、指令指针ip 存储器分为代码区和数据区 GAM启动后，将依次完成以下工作： 形式语言与文法文法的形式定义：G = （VT,VN,S,P） 终结符集、非终结符集、文法开始符号、产生式集。 a-&gt;b 产生式箭头后面的叫候选式 文法分类https://blog.csdn.net/whuexe/article/details/8710723 0型文法 1型文法：上下文有关文法 2型文法：上下文无关文法 3型文法：正规文法 推导推导就是用产生式的右边代替产生式的左边 推导的逆过程——归约 最左推导：替换最左边的非终结符 最右推导（规范推导）：替换最右边的非终结符 直接推导：推导一次 广义推导：推零次或若干次 句型和句子： 句型是推导过程中生成的产生式 句子是只有终结符的句型 语言的定义 一个文法只能产生一个语言，一个语言可以由多个不同的文法产生。若L(G) = L(G‘)，则称G和G’是等价文法。 语法树（推导树）非终结符—&gt;终结符 推导树不是唯一的，语言二义性，一个句子可能有两颗不同的推到树。 推导树的边缘：所有叶节点从左到右的连接 编译概述一些基本概念： 翻译：一种语言编写的程序转换成另一种语言编写的程序，实现翻译的程序叫翻译程序 从高级语言到低级语言的翻译叫做编译从汇编语言到机器语言的翻译叫做汇编 编译程序：高级语言—&gt;低级语言 汇编程序：汇编语言—&gt;机器语言 宿主语言：编写编译程序的语言 宿主机：运行翻译程序的机器 自驻留：宿主语言编写的编译程序能生成其宿主机上执行的机器代码 交叉编译：编译程序生成的不是宿主机的机器代码 自编译：编译程序是用源语言写的 编译和解释编译执行先将源程序翻译成目标程序，再执行目标程序得到结果 解释执行直接由解释程序对源程序进行分析、执行并得到结果 解释执行无需生成目标代码、易于实现、易于移植，需要边翻译边执行，优化难，执行效率低 如何区分看进程：是目标程序还是解释程序 如c语言程序的进程就是 程序.exe，而python是python解释器pyhon.exe 词法分析输入源程序的符号串，输出单词流 工具：状态转换图 语法分析对经过词法分析的符号串，按照文法判断，看是否构成正确的句子，给出语法树和错误信息。 自上而下前提条件：消除左递归和无公共左因子 递归下降分析 预测分析 递归下降分析 消除左递归：目的是避免产生无限推导，而不能匹配任何字符 https://blog.csdn.net/liyun123gx/article/details/19924993 P→Pα1 / Pα2 /…/ Pαn / β1 / β2 /…/βm 改为： P→β1 P’ / β2 P’ /…/βm P’ P’ →α1P’ / α2 P’ /…/ αn P’ /ε 提取公共左因子：目的是消除回溯，拥有唯一的推导过程 预测分析法表驱动，由 下推栈、预测分析表、控制程序 组成 first(α)集：α（任意符号串）所有可能推导出的首终结符（或ε）的集合，首符集 follow(A)集：所有句型中紧跟在A后面出现的终结符的集合，跟随符集 first集构造 终结符的first集是它本身 非终结符的first集是这个字符可能能推导出的第一个非终结符，包括直接推导出的、间接推导出的 4那里应该是1&lt;=j&lt;=i吧？注： *表示大于1 +表示大于等于1 follow集构造找产生式右边的这个字符B，这个字符后面符号的first集加入。推导符号的follow集加入(推导结果能以B结束) 预测分析表构造 严谨的说 First集是针对候选式而说的，所以用了α区分A。求候选式First集的算法： 输入：文法G = (V,P,T,S)，α = (v ∪ T)*，α = X1…..Xn 输出：First(α) 步骤： 1、计算First(X1); 2、First(α) = First(X1) - {ε} 3、k = 1 4、while(ε ∈ First(Xk) and k &lt; n) do begin ​ First(α) = First(α) ∪ (First(Xk+1) - {ε}) ​ k = k +1 end 5、if(k = n and ε ∈ First(Xk)) then First(α) = First(α) ∪ {ε} 思路：看前一个字符的first集中是否有ε，有的话，下一个字符的 first集-ε 也要加进去。 自下而上采用栈，移进过程中观察栈顶是否形成了某个产生式的一个候选，若是，则规约，直到只剩下开始符号。 算符优先分析法 LR分析法 算符优先分析法使用分析栈，当其栈顶形成最左素短语时，进行归约。 FIRSTVT集和LASTVT集 FIRSTVT(P)集：P所可能推导的第一个终结符的集合 LASTVT(P)集：P所可能推导的最后一个终结符的集合 用矩阵求不容易遗漏 优先关系表构造这个优先关系是单方面的，也就是说这里的 “a&lt;b” 并不意味着 “b&gt;a”，同样的，“a=b” 也不意味着 “b=a”。 都是集合里的优先级高，终结符前面的看lastvt，后面的看firstvt “终结符&lt;firstVT()”或“lastVT()&gt;终结符” 左边对应行，右边对应列 想象一个句型…aQ…..,在这个句型中只有等Q的短语规约为Q了，才有可能将…aQ….再次向上规约，因此a的优先级要小于Q产生式的firstVT(Q)集，因为我们可以断定a必定是比Q中第一个出现的终结符优先级低的，也就是说优先级a&lt;优先级firstVT(Q) 同理，对于lastVT()，让我们想一下这种情况…..Qa…..,对于这个句型我们知道只有当Q的短语归约成了Q，我们才敢将….Qa……向上归约。这样的话就是说Q的产生式中最后出现的一个终结符的优先级必定是比a的优先级高的，也就是优先级lastVT(Q)&gt;优先级a LR分析法LR(0)https://blog.csdn.net/m0_37154839/article/details/80316089 SLR(1) 语义分析和中间代码生成语义分析 语义检查：类型检查、控制流检查（break出现位置）、一致性检查（数组维数、变量重名、变量定义）、越界检查 语义处理：说明语句翻译（对说明语句的信息登记到符号表中），执行语句翻译（生成中间代码） 中间代码生成语义子程序是某种中间代码生成程序，随着语法分析的进行，中间代码也逐步生成。 为什么要生成中间代码：不同的机器有不同的机器码，所以编译器会把高级语言翻译到一个低层，而这个低层又没有低到机器码这个层级。这就是中间代码（intermediate representation，IR）。编译器的前端把高级语言翻译到 IR，编译器的后端把 IR 翻译成目标机器的汇编代码。 中间代码的形式多样：三地址代码、后缀式、语法树。通常使用三地址代码(或称为四元式)。 语法制导翻译在语法分析的过程中，产生式对应的语义子程序对源代码进行翻译，生成中间代码。 赋值语句翻译变量说明语句翻译控制语句翻译布尔表达式 if语句 s1.chain错了 ,应该是s2.chain 例题： while语句翻译chain记录的是要回填的那条指令的地址，code记录回填的内容 for循环语句翻译 编译优化等价、有效 不改变程序运行结果，提高程序的时间效率和空间的效率。 中间代码优化分为：局部优化和全局优化（基本块内和基本块外） 基本块：一段语句序列，有为一的入口语句和唯一的出口语句。所有语句的执行次数相同。 入口语句：能由转移语句转移到的语句，紧跟在条件转移后的语句 出口语句：转移语句，停止语句 局部优化是基本块内的优化，常见的方法包括： 合并已知量 删除死代码：永远不会执行的分支的代码，可以删除 删除公共子表达式：a = bc ; d = bc 改为 a = b*c ; d = a 删除无用赋值：a = 1; a = 2 改为 a = 2 全局优化循环定义：循环是程序流图中有唯一入口节点的强连通子图 如何查找循环 基本块之间的优化，这里只讨论循环优化，常见的方法包括： 代码外提：循环不变运算，提到循环入口节点之前所增设的节点 强度削弱：加法代替乘法 删除归纳变量 目标代码生成将中间代码翻译成等价的目标代码（机器代码、汇编码） 输入：中间代码（三地址码） 输出：目标代码（汇编代码） 目标代码的生成需要考虑：目标计算机的指令系统、寄存器分配、存储空间分配 循环中的寄存器分配存储空间分配 代码空间 数据空间 静态数据空间 动态数据空间 堆空间 栈空间 活动记录又叫栈帧。每个函数拥有自己的局部数据空间，就叫活动记录。一个函数的数据信息、管理信息都是通过活动记录存放的。通过栈式分配在栈空间种进行。 活动记录是在函数调用时动态建立，函数退出时动态撤销的。 动态连接：被调函数的活动记录中保存主调函数的活动记录的首地址，用来被调函数退出时，回复主调函数的活动记录。 非局部变量指全局变量和其他函数中定义的变量。访问方式取决于变量的作用域 静态连接：指向直接嵌套外层的最新活动记录的指针。 参数传递引址调用将实参的地址传给形参，表达式将创建新的临时单元 值调用 传值：将实参的计算值传给形参，作为局部变量使用 传结果：实参地址传给形参，另外还有一个局部变量空间 （通常不采用） 传值得结果：编译程序为每个形参分配两个单元；一个用来存放实参地址，一个用来作为被调用单元的局部变量，用来存放实参传递的值；实参将值传递给形参，被调用单元结束后，将形参的值再传递回实参 静态作用域和动态作用域词法作用域的函数中遇到既不是形参也不是函数内部定义的局部变量的变量时，去函数定义时的环境中查询。 动态域的函数中遇到既不是形参也不是函数内部定义的局部变量的变量时，到函数调用时的环境中查。","link":"/2020/07/25/%E7%BC%96%E8%AF%91%E5%8E%9F%E7%90%86%E5%A4%8D%E4%B9%A0/"},{"title":"计算机系统结构复习","text":"计算机系统结构考试复习 量化设计与分析基础Flynn’s分类 SISD：串行计算机，最老的计算机类型 SI：一个时钟周期只有单个指令流在CPU执行 SD：一个时钟周期只有单个数据流用作输入 SIMD：数据级并行，处理高度规整操作问题，如图像处理。每个处理器执行的指令一样，但是数据不一样 SI：一个时钟周期，所有处理单元执行相同的指令 MD：每个处理单元能对不同的数据元素进行操作 MISD：不存在 MIMD：并行计算机，线程级或任务级并行 MI：每个处理器执行不同的指令流 MD：每个处理器可以对不同的数据流进行操作 市场分类 个人移动设备 桌面计算机：个人计算机和工作站 服务器：特征：可靠性、可扩展性、吞吐量。 按是否通用开放分：通用开放系统、非开放系统 集群/仓库级计算机 嵌入式计算机：区别嵌入式和非嵌入式，能否运行第三方软件 计算机系统结构定义 经典的计算机系统结构：机器语言程序员能看到的传统机器所具有的属性。软件、硬件界面的确定。指令系统 计算机系统结构现代定义：在满足功能、性能和价格目标的条件下，设计、选择和互连硬件部件构成计算机。 计算机组成：逻辑实现，五大功能部件的联系。着眼于机器级内各事件的排序方式与控制方式。 计算机实现：物理实现，物理结构，器件的集成度和速度功耗 三者关系相同系统结构的计算机，因速度要求不同等因素可以采用不同的计算机组成，如5段步骤可以顺序执行，也可以采用流水线。 相同的计算机组成也可以有不同的计算机实现。如主存可以用SRAM也可以用DRAM。 系列机：由一个制造上生成的具有相同的系统结构，但具有不同组成和实现的一系列不同型号的计算机。他们系统结构相同，有同样的指令系统，从机器程序设计者所看到的机器属性是相同的。但是他们采用不同的组成和实现技术，在低挡机上可以采用指令串行执行的方式，高档机采用重叠、流水和其他并行方式。 系列机的缺点：为了保证软件的向后兼容，要求体系结构基本不变，阻碍了发展。 1.指令系统 指令系统的确定——————————–计算机系统结构 指令的实现————————————–计算机组成 具体电路、器件设计及装配技术———–计算机实现 2.乘法指令 是否设乘法指令——————————–计算机系统结构 用高速乘法器还是加法器移位器实现—–计算机组成 器件的类型、数量及组装技术的确定—–计算机实现 3.主存系统 主存容量与编址方式的确定—————–计算机系统结构 主存速度的确定、逻辑结构的模式——–计算机组成 器件的选定、电路的设计、组装技术—–计算机实现 4.什么样的系列机属系统结构，系列内的不同型号计算机的组织属组成 透明性: 本来存在的事务或属性，从某个角度上看不到，则为透明。反之，不透明。比如：对计算机系统结构来说，存储器采用交叉存取还是并行存取、CPU内部的数据通路的宽度是8位还是16位，这些都是透明的，而对计算机组成来说这些不是透明的。指令执行采用串行、重叠还是流水控制方式，对系统结构来说是透明的，但对计算机组成来说不是透明的。乘法指令采用专用乘法器实现。对系统结构来说是透明的，而对计算机组成来说不是透明的。存储器采用哪种芯片，对计算机系统结构和组成来说是透明的，而对计算机实现来说不是透明的。 性能评价 响应时间 CPU时间计算：指令数 * CPI * 时钟周期 吞吐量：单位时间内完成的工作总量。在系统中增加额外的处理器可以改善吞吐量但是不会改善响应时间。但是改善响应时间可以改善吞吐量，如换用更快的处理器。 MIPS SPEC率：参考计算机执行时间/机器执行时间 （越高越好） SM（spec mark）：$SM = \\sqrt{\\prod SPECRation_i}$ 设计的量化原则 利用并行性：系统级、指令级、操作级 局部性原理：时间、空间 Amdahl`s定律：执行优化后性能的提高，跟这种执行的使用频率有关 加速比：优化后性能/未优化性能 （时间取倒数） Fe：改进比例 Se：改进加速比 改进加速比Sn计算：改进后执行时间为Tn，改进前的执行时间为To $(1-Fe)T_0+Fe*T_0/Se = T_n$ Amdahl定律公式 指令系统原理与实例指令集系统结构分类处理器内部数据的存储结构不同：堆栈、累加器、寄存器，操作数可以显式或隐式指定。 堆栈系统结构：操作数隐含位于栈顶 累加器系统结构：一个隐含操作数 通用寄存器系统结构：需要明确指定操作数、不是寄存器就是存储器地址 reg-mem系统结构：一般指令都能访问内存 reg-reg 或者 load-store系统结构：只有load和store能访问内存 存储器寻址 基本单位：字节寻址，都提供了字节、半字（16位）、字寻址（32位），大多数还有双字（64位）寻址。 大端、小端模式：小端低地址存低字节，大端低地址存高字节 对齐访问：一个S字节数据的地址是A，A mod S = 0。简化硬件实现，减少存储器访问 常见寻址方式： 操作数类型如何指定：操作码编码（最常见），操作数中用硬件解释的字段 指令操作主要有：算数和逻辑运算、数据传输（load-store）、控制（条件转移、跳转、过程调用返回、陷阱） 控制流指令 PC相对寻址，优点 减少指令长度（因为偏移值小），相对地址的程序可以载入到主存的任何位置，与位置无关 寄存器间接跳转：给出包含目标地址的寄存器名称，用来实现返回和间接跳转，还支持case、switch 指令系统编码方式指令编码包括：操作、寄存器地址、寻址方式编码 变长编码：允许所有寻址方式、适合寻址方式和操作多、不适合流水线。关注代码里大小 定长编码：适合寻址方式和操作少的情况。译码简单，适合流水线、代码量大。关注程序的执行性能。 混合方法：折中 MIPS系统结构的指令格式、寻址方式的特点 64位load-store系统结构 定长编码，有利于高效流水线 指令格式：32位，6位是基本操作码 32个64位通用寄存器R0-R31、32个浮点寄存器F0-F31，R0永远是0，R0载入无效 数据类型：定点：字节、半字、字、双字，浮点：32位单精度，64位双精度 寻址方式：16位立即数、16位位偏移量（基址寻址）、位移量0（寄存器间接寻址）、R0作为基址寄存器（16位绝对寻址） RISC指令系统的关键特点： 所有运算的数据来自寄存器，结果也写入寄存器。 访存只有load和store指令 指令的数量少，所有指令长度相同 CISC的8086指令系统 RISC的MIPS或ARM指令系统 ISA分类 R-M型 R-R型 指令长度 变长 定长 寻址方式 有寻址字段（立即数、寄存器、直接寻址、寄存器间接寻址、基址寻址、变址寻址、基址变址寻址、串操作寻址、相对寻址、I/O寻址） 无专门寻址字段（立即数、寄存器寻址、位移量寻址、相对寻址），寻址方式被编码到了操作码中 操作数类型 定点数据类型有字节、16位字、双字、4字，字符串、近指针、压缩/非压缩BCD码 定点数据类型有8位字节、16位半字、32位字和64位双字。浮点数有32位单精度和64位双精度浮点数 指令操作类型 传送类、算术运算类、逻辑类、串操作类、程序转移类、处理器控制类 LOAD/STORE类、ALU操作类、分支与跳转类、浮点运算类 指令操作码编码 1-2个字节编码 6位操作码加辅助操作码 转移控制类指令 无条件转移指令直接或间接寻址、条件转移指令和循环控制指令相对寻址、子程序调用与返回指令 跳转指令拼接地址、分支指令相对寻址、跳转与链接、寄存器跳转与链接、等于零时转换 流水线技术流水线是利用执行指令操作之间的并行性，实现多条指令重叠执行的技术。 流水线分类 各段用时：均匀流水线、非均匀流水线 处理的数据类型：标量流水处理机、向量流水处理机 流水线规模：操作流水线、指令流水线、宏流水线 按功能分类：单功能流水线、多功能流水线 按工作方式分类：静态流水线、动态流水线（是在多功能流水线基础上划分的） 静态流水线：在同一时间内，各段只能做同一种功能的工作 动态流水线：同时时间内，各段可以按照不同的方式链接，同时执行多种功能。 按连接方式分类（有无反馈回路，有反馈的是非线性）：线性流水线、非线性流水线 时空图例子：四段指令流水线、六个任务 流水线性能分析 吞吐率：在单位时间内流水线所完成的任务数量或输出结果的数量。$TP=n/T_k$ n是任务数，Tk是处理完成n个任务所用的时间（第一个开始到最后一个结束k+n-1）。 效率：$E=\\frac{n个任务占用的时空区}{k个流水线的总的时空区}$ 面积之比 knt/k(k+n-1)t=n/(k+n-1) 加速比：顺序执行任务所用时间/流水线所用时间 解决流水线问题的常用方法：细分瓶颈段、重复设置瓶颈段 衡量流水线性能得主要指标有：吞吐率、加速比、效率 流水线定义：利用执行指令操作之间的并行性，实现多条指令重叠执行的技术。 三种相关（冒险）及解决办法相关分类： 结构相关：硬件资源的冲突 数据相关：后面的指令依赖前面指令的计算结果，还没算好 控制相关：转移指令的转移条件和目标地址没准备好 相关总是可以用停顿解决 结构相关 多重访问寄存器堆：一个时钟周期内，WB先写，ID后读 多重访问存储器 硬件插入停顿stall 提供另一个存储器端口 分开指令存储器和数据存储器 使用指令缓冲器 没有或者没有充分流水功能部件？ 数据相关WB级写寄存器堆的操作提前半个周期，在时钟下降沿打入。 由编译器插入nop指令（软件方法），还是有指令进入流水线的，只是这个指令无效 互锁：插入stall（硬件方法1） 增加硬件互锁 流水线异常和浮点流水线异常原因：I/O外设请求、用户OS服务请求、断点、整数算术运算溢出、浮点算数异常、缺页…… 中断：用户敲击键盘、网络包到达 异常：除0、溢出、缺页 异常是一种控制冒险，操作非法、除0、结果溢出等，或者用户程序试图执行去处理异特权指令。 流水线中的异常： IF：取指令发生缺页、存储器访问边界未对齐、违反了存储器访问权限 ID：未定义的或非法操作码 EX：运算异常 MEM：存取数据缺页、存储器访问边界未对齐、违反存储器访问权限 WB：无 使用流水线寄存器。把PC逐级的保存下来。 精确异常：流水线停下来使异常指令前的指令能正常结束，异常指令后的指令能重新启动 非精确异常：反之，一条指令完成的时间不一定相同，指令可能乱序完成。 一般来说，整数操作异常时精确的，浮点操作异常不精确。 存储器层次结构Cache基本单位：块 cache是按照块进行管理的，cache和主存都被分割成大小相同的块，对内存和cache的访问以块为单位。 Cache存储器的三种映像方式 直接映像：块只能放在cache中唯一的位置,实现最简单。虚拟地址3部分组成 全相联：块可以放在cache中的任意位置,虚拟地址2部分组成 组相联：块能放在cache中一组中的任一位置，如果一个组有n个块，叫n路组相联。 例子：主存中编号12的块要放在cache中，cache有8个块 直接映像：主存中的块12能进入cache中的块4（12 mod 8），其中8是cache的块数，所以又是一路组相联 全相联：块12可以进入任意位置，全路组相联 组相联：块12可以进入第0组中的任意位置（12 mod 4）其中4是组数，即有4组 块替换策略 随机替换 最近最少使用（LRU） 先进先出 写策略回答数据在写进cache的时候，是否写入主存 写直达(写入)：数据写cache时也写主存，cache控制位只需要valid bit（是否有效），不按写分配（写失效时，直接写入下一级存储器，read的时候才会调入cache） 写回（不写入）：写cache时不写主存，需要valid位和dirty位（是否被修改），写缺失（要写的块不在cache内）的时候采用写分配策略（把缺失块调入cache再写）。采用的是写分配 写停顿 对cache写的时候，要写的块不在cache内： 写分配：调入cache，再写 不按写分配：直接写入内存 性能 CPU执行时间 CPU性能取决与三个因素：IC * CPI * 时钟周期时间 平均每条指令的存储器停顿： =每条指令的缺失次数L1*每条指令的缺失代价 =每条指令的缺失次数L1*（命中时间L2+每条指令缺失次数L2 * 缺失代价） =每条指令缺失次数L1*命中时间L2+每条指令缺失次数G2 * 缺失代价L2 L是local，G是global 平均存储器访问时间 = 命中时间+缺失率*缺失代价 从平均访存时间改善cache性能 减少缺失率：增加块大小、增大cache容量、更高相联度、编译优化 编译优化：指令优化（预测转移发生），数据优化（合并数组、循环交换、循环融合、分块） 减少缺失代价：多级caches、关键字优先、提前重启动、读缺失优于写缺失、合并写缓冲、牺牲缓冲 关键字优先：CPU只要块中的一个字，从存储器将缺失的字尽可能快的送到CPU，CPU继续执行同时填方块中的其他字。 提前重启动，只要块中请求的字到达，就送到CPU。 通过并行减少缺失代价和缺失率：非阻塞caches、硬件预取、编译预取 减少cache的命中时间：使用小的和简单的caches、避免地址转换、流水线cache访问、路预测、踪迹caches 缺失分类 强制缺失：首次访问缺失，与cache大小无关，更大的块可以较少强制缺失率（空间局部性） 容量缺失：cache容纳不了一个程序的所有块。通过增大cache容量减小 冲突缺失：块被映射到了同一组，相联度越高，cache容量越大，冲突失效就越少。 一致性缺失 缺失增大块容量：减少冲突缺失、增加缺失代价、增加冲突缺失（块少了） 增大cache容量：减小容量缺失、减少冲突缺失 更大的相联度：较小了冲突缺失 2：1经验法则 一个容量为N的直接映射cache的缺失率 = 一个容量为N/2的2路组相联cache的缺失率。 改善主存储器组织的性能 延迟：很难减小 带宽：采用新的组织 增加主存储器带宽 简单交叉存储器 增加主存带宽虚拟存储器 段式：可变大小的块 页式：固定大小的块 映像策略：采用全相联策略，因为访问磁盘太慢了，要尽可能降低缺失率。 根据局部性原理，大多OS采用LRU替换策略。 写策略采用写回方式，因为访问磁盘很慢。 快表：一个特殊的cache，TLB，存放最近用过的页表项。组成：标识、数据。标识中存放的是虚地址的一部分，而数据部分中存放物理页号（组成物理地址）、存储保护信息以及其他一些辅助信息 例子：TLB采用直接映射 因为页大小是8KB，所以虚拟地址的0-12bit作为页内地址偏移。TLB表有64项，所以虚拟地址的13-18bit作为TLB表项的索引。假如虚拟地址的13-18bit是1，那么就会查询TLB的第1项，从中取出标识，与虚拟地址的19-31位作比较，如果相等，表示TLB命中，反之，表示TLB失靶。TLB失靶时，可以由硬件将需要的页表项加载入TLB，也可由软件加载，具体取决于处理器设计。 例：TLB采用全相联映射 https://www.nowcoder.com/questionTerminal/c6fd7f1a40d14350bd976d951384b335 区分全相联和直接映像 全相联可以放在任何一个位置，直接判断标记，虚拟地址只需要分两部分 直接映像通过唯一的序号确定位置，但是可能有冲突，所以还是需要标识位，虚拟地址需要分三部分 多线程和多处理器ILP和TLPILP指令级并行：instruction level parallelism 隐式并行 局限性： 各种相关限制了每个始终周期能发射的指令数 分支预测的准确性 寄存器重命名的能力 TLP线程级并行：thread level parallelism 显式并行 一个线程是有自己的指令代码和数据的过程。每个线程都有用于执行的必要的状态（包括指令代码、数据、PC、寄存器状态） 超标量、粗粒度、细粒度和SMT粗粒度：仅在长空闲周期时才切换线程。 细粒度：可在每个时钟周期切换线程，使得线程交替执行。 SMT：同时多线程 simultaneous multi-threading，结合了多发射、在ILP和TLP上动态调度指令的功能，可在一个始终周期发射不同线程的指令。 超标量（superscalar）CPU架构是指在一颗处理器内核中实行了指令级并行的一类并行运算。这种技术能够在相同的CPU主频下实现更高的CPU吞吐率（throughput）。 多处理器（MIMD）的两种分类结构集中共享存储器架构：也成为均匀存储器访问UMA结构，也可成为对称型多处理机SMP，一个存储系统为每个处理机提供相同的访问时间。 分布式存储器架构：多存储系统，多IO，非均匀存储器访问NUMA结构 同构多核与异构多核芯片级并行","link":"/2020/07/30/%E8%AE%A1%E7%AE%97%E6%9C%BA%E4%BD%93%E7%B3%BB%E7%BB%93%E6%9E%84%E5%A4%8D%E4%B9%A0/"}],"tags":[{"name":"数据结构","slug":"数据结构","link":"/tags/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/"},{"name":"matlab","slug":"matlab","link":"/tags/matlab/"},{"name":"算法","slug":"算法","link":"/tags/%E7%AE%97%E6%B3%95/"},{"name":"kernel","slug":"kernel","link":"/tags/kernel/"},{"name":"机器学习","slug":"机器学习","link":"/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"},{"name":"矩阵分析","slug":"矩阵分析","link":"/tags/%E7%9F%A9%E9%98%B5%E5%88%86%E6%9E%90/"},{"name":"UNIX","slug":"UNIX","link":"/tags/UNIX/"},{"name":"git","slug":"git","link":"/tags/git/"},{"name":"hexo","slug":"hexo","link":"/tags/hexo/"},{"name":"markdown","slug":"markdown","link":"/tags/markdown/"},{"name":"数学建模","slug":"数学建模","link":"/tags/%E6%95%B0%E5%AD%A6%E5%BB%BA%E6%A8%A1/"},{"name":"python","slug":"python","link":"/tags/python/"},{"name":"rust","slug":"rust","link":"/tags/rust/"},{"name":"环境配置","slug":"环境配置","link":"/tags/%E7%8E%AF%E5%A2%83%E9%85%8D%E7%BD%AE/"},{"name":"windows","slug":"windows","link":"/tags/windows/"},{"name":"操作系统","slug":"操作系统","link":"/tags/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/"},{"name":"运筹学","slug":"运筹学","link":"/tags/%E8%BF%90%E7%AD%B9%E5%AD%A6/"},{"name":"web","slug":"web","link":"/tags/web/"},{"name":"开源项目","slug":"开源项目","link":"/tags/%E5%BC%80%E6%BA%90%E9%A1%B9%E7%9B%AE/"},{"name":"深度学习","slug":"深度学习","link":"/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"},{"name":"网络","slug":"网络","link":"/tags/%E7%BD%91%E7%BB%9C/"},{"name":"编译原理","slug":"编译原理","link":"/tags/%E7%BC%96%E8%AF%91%E5%8E%9F%E7%90%86/"},{"name":"体系结构","slug":"体系结构","link":"/tags/%E4%BD%93%E7%B3%BB%E7%BB%93%E6%9E%84/"}],"categories":[{"name":"数据结构","slug":"数据结构","link":"/categories/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/"},{"name":"机器学习","slug":"机器学习","link":"/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"},{"name":"网络","slug":"网络","link":"/categories/%E7%BD%91%E7%BB%9C/"},{"name":"kernel","slug":"kernel","link":"/categories/kernel/"},{"name":"UNIX","slug":"UNIX","link":"/categories/UNIX/"},{"name":"算法","slug":"算法","link":"/categories/%E7%AE%97%E6%B3%95/"},{"name":"编程语言","slug":"编程语言","link":"/categories/%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80/"},{"name":"python","slug":"编程语言/python","link":"/categories/%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80/python/"},{"name":"环境配置","slug":"环境配置","link":"/categories/%E7%8E%AF%E5%A2%83%E9%85%8D%E7%BD%AE/"},{"name":"rust","slug":"编程语言/rust","link":"/categories/%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80/rust/"},{"name":"课程学习","slug":"课程学习","link":"/categories/%E8%AF%BE%E7%A8%8B%E5%AD%A6%E4%B9%A0/"},{"name":"运筹学","slug":"运筹学","link":"/categories/%E8%BF%90%E7%AD%B9%E5%AD%A6/"},{"name":"操作系统","slug":"课程学习/操作系统","link":"/categories/%E8%AF%BE%E7%A8%8B%E5%AD%A6%E4%B9%A0/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/"},{"name":"web开发","slug":"web开发","link":"/categories/web%E5%BC%80%E5%8F%91/"},{"name":"项目学习","slug":"项目学习","link":"/categories/%E9%A1%B9%E7%9B%AE%E5%AD%A6%E4%B9%A0/"},{"name":"深度学习","slug":"深度学习","link":"/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"},{"name":"算法题","slug":"算法题","link":"/categories/%E7%AE%97%E6%B3%95%E9%A2%98/"},{"name":"编译原理","slug":"课程学习/编译原理","link":"/categories/%E8%AF%BE%E7%A8%8B%E5%AD%A6%E4%B9%A0/%E7%BC%96%E8%AF%91%E5%8E%9F%E7%90%86/"},{"name":"计算机体系结构","slug":"课程学习/计算机体系结构","link":"/categories/%E8%AF%BE%E7%A8%8B%E5%AD%A6%E4%B9%A0/%E8%AE%A1%E7%AE%97%E6%9C%BA%E4%BD%93%E7%B3%BB%E7%BB%93%E6%9E%84/"}]}