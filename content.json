{"pages":[],"posts":[{"title":"BP神经网络算法 matlab实现","text":"根据西瓜书5.3编写。 搭建$4 \\times 10\\times3$的全连接神经网络。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263clear all;clc;data = load(&apos;Iris-train.txt&apos;);testD = load(&apos;Iris-test.txt&apos;)x2 = testD(:,1:end-1);y2 = testD(:,end);x = data(:,1:end-1);temp = data(:,end);y = zeros(3,75);for i = 1:75 y(temp(i)+1,i) =1;end%sigmoid functionf = @(x) 1/(1+exp(-x))delta = 0.1;V= randn(4,10);W = randn(10,3);gamma = randn(10,1);theta = randn(3,1);hTrain = []; hTest = [];flag = 1;while 1 accTrain = 0; for k = 1:75 % for all samples b = arrayfun(f,V&apos;*x(k,:)&apos;-gamma);%隐含层的激活值 (10*1) y_bar = arrayfun(f,W&apos;*b-theta);%输出层 (3*1) %输出层梯度 g = y_bar.*(1-y_bar).*(y(:,k)-y_bar); %(3*1) %隐含层梯度 e = b.*(1-b).*(W*g);%(10*1) %权重和偏置更新 W = W + delta*b*g&apos;; %10*3 theta = theta - delta*g;%3*1 V = V + delta*x(k,:)&apos;*e&apos;;%4*10 gamma = gamma - delta*e; [maxL,label] = max(y_bar); accTrain = accTrain + (label==(temp(k)+1)); end %计算测试集准确率 b = arrayfun(f,V&apos;*x2&apos;-repmat(gamma,1,75));%隐含层的激活值 (10*75) y_bar = arrayfun(f,W&apos;*b-repmat(theta,1,75));%输出层 (3*75) [maxL,label] = max(y_bar); hTrain = [hTrain accTrain/75]; hTest = [hTest sum(label == (y2+1)&apos;)/75]; plot(hTrain,&apos;blue&apos;) hold on plot(hTest,&apos;red&apos;) if flag == 1 legend(&apos;训练集acc&apos;,&apos;测试集acc&apos;); flag = 0; end if sum(label == (y2+1)&apos;)/75&gt;0.98 break end pause(0.000001);end","link":"/2019/10/27/BP神经网络算法-matlab实现/"},{"title":"SVD奇异值分解及应用","text":"特点 优点：简化数据，去除噪声，提高算法结果 缺点：数据的转换可能难以解释 适用于数值型数据 原理$M_{m\\times n} = U_{m\\times n}D_{n\\times n}V_{n\\times n}^T\\approx U_{m\\times k}D_{k\\times k}V_{k\\times n}^T$ 对于矩阵$U$可表示为： $U = (u_1,u_2,…,u_n)$ 对于$V$： $V =(v_1,v_2,…,v_n)$ 则有： $M=d_{1} u_{1} v_{1}^{T}+d_{2} u_{2} v_{2}^{T}+\\cdots+d_{n} u_{n} v_{n}^{T}=\\sum_{i=1}^{n} d_{i} u_{i} v_{i}^{T}=\\sum_{i=1}^{n} A_{i}$ $M_n \\approx M_{k}=\\sum_{i=1}^{k} A_{i}$ 应用图像压缩存储一张 1000×622 大小的图片，实际上就是存储一个 1000×622 的矩阵，共 622000 个元素。这个矩阵用 SVD 可以分解为 622 个矩阵之和，如果我们选取其中的前 100 个之和作为对图像数据的近似，那么只需要存储 100 个奇异值 $d_i$，100 个 $u_i$ 向量和 100 个 $v_i$ 向量，共100×(1+1000+622)=162300 个 元素，大约只有原始的 26% 大小。","link":"/2019/07/27/SVD奇异值分解/"},{"title":"markdown常用公式符号","text":"123456789101112131415161718192021222324252627282930311. 上标$$x^2$$2. 下标$$x_i$$3. 累加$$\\sum$$4. 分数$$\\frac{1}{3}$$5. 开方$$\\sqrt{2}$$6. 矢量$$\\vec{x}$$7. 积分$$\\int$$ $$\\int_0^1x^2$$8. 常见希腊字母 $\\alpha$,$\\beta$,$\\gamma$,$\\delta$,$\\theta$9. 叉乘$$\\times$$10. 点乘$$\\cdot$$11. 除$$\\div$$12. 矩阵$$\\begin{matrix}1 &amp; 2 &amp; 3 \\\\4 &amp; 5 &amp; 6 \\\\7 &amp; 8 &amp; 9 \\end{matrix} \\tag{1}$$13. 带括号的矩阵$$\\left[\\begin{matrix}1 &amp; 2 &amp; 3 \\\\4 &amp; 5 &amp; 6 \\\\7 &amp; 8 &amp; 9 \\end{matrix} \\right]\\tag{2}$$14. 约等于$\\approx$ 上标$$x^2$$ 下标$$x_i$$ 累加$$\\sum$$ 分数$$\\frac{1}{3}$$ 开方$$\\sqrt{2}$$ 矢量$$\\vec{x}$$ 积分$$\\int$$ $$\\int_0^1x^2$$ 常见希腊字母$\\alpha$,$\\beta$,$\\gamma$,$\\delta$,$\\theta$ 叉乘$$\\times$$ 点乘$$\\cdot$$ 除$$\\div$$ 矩阵$$\\begin{matrix}1 &amp; 2 &amp; 3 \\4 &amp; 5 &amp; 6 \\7 &amp; 8 &amp; 9\\end{matrix} \\tag{1}$$ 带括号的矩阵 $$\\left[\\begin{matrix}1 &amp; 2 &amp; 3 \\4 &amp; 5 &amp; 6 \\7 &amp; 8 &amp; 9\\end{matrix} \\right]\\tag{2}$$ 约等于$\\approx$","link":"/2019/07/27/markdown常用公式符号/"},{"title":"Hello World","text":"Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub. Quick StartCreate a new post1$ hexo new &quot;My New Post&quot; More info: Writing Run server1$ hexo server More info: Server Generate static files1$ hexo generate More info: Generating Deploy to remote sites1$ hexo deploy More info: Deployment","link":"/2019/07/27/hello-world/"},{"title":"hexo图片插入","text":"配置Typora文件 $\\longrightarrow$ 偏好设置 安装hexo-asset-image安装0.0.1版，1.0.0会出现.com问题 打开博客根目录下的package.json文件，如下修改： 1&quot;hexo-asset-image&quot;: &quot;0.0.1&quot;, 然后在博客根目录下 1npm install 使用以下格式在md文件中即可插入图片： 1![](xxxx/example.jpg) 参考资料：https://alreadyright.github.io/2019/06/16/aboutHexo/","link":"/2019/07/27/hexo图片插入/"},{"title":"公式无法渲染问题","text":"错误情况部分公式无法渲染，显示为源码 环境 解决修改marked\\lib\\marked.js以下语句： 12escape: /^\\\\([!&quot;#$%&amp;&apos;()*+,\\-./:;&lt;=&gt;?@\\[\\]^_`|~])/,em:/^\\*((?:\\*\\*|[\\s\\S])+?)\\*(?!\\*)/,","link":"/2019/08/10/公式无法渲染问题/"},{"title":"matlab模拟退火工具箱satools","text":"​ 记录了模拟退火的原理和matlab第三方工具箱satools的使用。 算法原理 SATOOLS使用模拟退火主函数anneal调用格式：1234567891011function [W,Ew,Wbsf,Ebsf,Tt,Et,Etarget,ert,Kt,Ebsft,Eh,M,rho,Ebin] = anneal( ... verbose, ... newstate, X, ... cost, moveclass, ... walkers, ... acceptrule, q, ... schedule, P, ... equilibrate, C, maxsteps, ... Tinit, r, ... Tfinal, f, maxtemps, ... v, bins, e) 参数说明输入参数 verbose：flag变量，为1时打印状态变量 newstate：用户自定义函数,产生初始解 X：问题的domain(解空间?)，常量 cost：用户自定义函数，最优化的目标函数 moveclass：用户自定义函数，用来产生新解 walkers：正整数 acceptrule：用户自定义函数，接受规则，工具箱也提供了几个，经常用metropolis准则 q：acceptrule所需要的参数 schedule：温度更新函数，可自定义 P：schedule所需参数 equilibrate：(平衡)可传入函数句柄或其他。当传入函数时，表示温度是否改变的判断函数 C：equilibrate所需参数 maxsteps：同一温度下的迭代最大次数 Tinit：初始化函数，可自定义可使用工具箱提供函数。 r：Tinit所需参数 Tfinal：终止温度，可以是自定义函数，工具箱也提供，或者是数（-INF ok） f：参数 maxtemps：最大温度迭代次数 v：温度变化的快慢$[0,1]$ bins： e： 输出参数 W：每个walker的最终状态 Ew：W对应的最终能量 Wbsf：每个walker的best so far状态 Ebsf：每个walker的best so far能量 Tt(i)：每次温度步的温度记录 Et(i)：Tt(i)对应的平均能量 Etarget（i）：Tt(i)对应的目标平均能量，根据v计算 ert(i)： kt(i)：Tt(i)对应的热平衡步数 Ebsft(i)：Tt(i)对应的best so far能量 Eh：能量和温度的历史记录 i = 1,1 + (steps*walkers) Eh(i,1)：温度步的下标t Eh(i,2)：t对应的温度T Eh(i,3)：在温度T时的达到热平衡步数的编号j Eh(i,4)：walker的编号k Eh(i,5)：在T温度下,第j步，walker k对应的能量 Eh(i,6)：在T温度下,第j步，energy E&apos; attempted from E M： rho： Ebin： 自定义函数编写 newstate产生初始解， 12345678910111213function W = PROBLEMNAME_new(X)% W = PROBLEMNAME_new(X)% See http://www.frostconcepts.com/software for information on SA Tools.%% W = PROBLEMNAME_new(X) ;%% X = behaviorally constant application data%% W = specific data about current state%% Instantiates a new state.%W = [] ; % a typical application will put state specific data here cost最优化目标 12345678910function Ew = PROBLEMNAME_cost(X,W)% Ew = PROBLEMNAME_cost(X,W)%% X = behaviorally constant application data%% W = specific data about current state%% Ew = energy corresponding to W%Ew = rand ; % a typical application will use information from W and X to compute Ew. moveclass产生新解 123456789function W = PROBLEMNAME_perturb(X,W,Ea,T)% W = PROBLEMNAME_perturb(X,W,Ea,T)%% X = behaviorally constant application data%% W = (on input) current state, (on output) next state.%% Ea = current average energy% T = current temperature 产生解空间 123456function X = PROBLEMNAME_init()% X = PROBLEMNAME_init()%% X = behaviorally constant application data%X = [] ; % a typical application will put problem domain data here","link":"/2019/08/11/matlab模拟退火工具箱satools/"},{"title":"决策树ID3算法Python实现","text":"参考西瓜书第4章编写，并用graphviz实现可视化。 代码123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146import numpy as npfrom collections import Counterfrom graphviz import Digraphimport osos.environ[&quot;PATH&quot;] += os.pathsep + &apos;D:/Graphviz2.39/bin&apos;def loadData(filename): with open(filename) as f: line = f.readline() res = [] while line: c = line.split() content = [float(x) for x in c] res.append(content) line = f.readline() #print(res) return resdef getEnt(data): num = len(data) labelCount = {} for feature in data: label = feature[-1] if label not in labelCount.keys(): labelCount[label] = 0 labelCount[label] += 1 Ent = 0 for key, p in labelCount.items(): p = p / num Ent -= p*np.log2(p) return Entdef splitDate(data,feature,point):#整体数据集、特征编号、分割点 data1 = [x for x in data if x[feature]&lt;point] data2 = [x for x in data if x[feature]&gt;point] return data1,data2def chooseBF(data):#选择最佳的划分属性 featureValue = [] num = len(data) Ent = getEnt(data) numFeature = len(data[0])-1#获取属性的个数 maxGain = float(&apos;-inf&apos;) for i in range(numFeature):#对每个属性，统计出现的值 featureList = [feature[i] for feature in data]#统计该属性出现的可能值 featureList = sorted(list(set(featureList))) for j in range(len(featureList)-1): data1,data2 = splitDate(data,i,(featureList[j]+featureList[j+1])/2) Ent1 = getEnt(data1) Ent2 = getEnt(data2) Gain = Ent - (len(data1)/num)*Ent1 - (len(data2)/num)*Ent2 if Gain&gt;maxGain: feature = i point = (featureList[j]+featureList[j+1])/2 dataLeft = data1 dataRight = data2 maxGain = Gain return feature,point,dataLeft,dataRight#返回分割的属性和分裂点def creatTree(data): node = {} label = [sample[-1] for sample in data] if len(set(label))==1: node[&apos;label&apos;] = label[0] return node unique = [] for i in range(len(data[0])-1): unique.append(len(set([sample[i] for sample in data]))) tot = sum([1 for x in unique if (x == 1)]) dataCount = Counter([sample[-1] for sample in data]) if (tot == 4): node[&apos;label&apos;] = list(dataCount.most_common(1)[0])[0] return node featureIndex,point,dataLeft,dataRight = chooseBF(data)#分裂属性编号，分裂值 node[&apos;value&apos;] = point node[&apos;feature&apos;] = featureIndex node[&apos;leftChild&apos;] = creatTree(dataLeft) node[&apos;rightChild&apos;] = creatTree(dataRight) return nodedef predict(sample,node): if &apos;feature&apos; in node: if sample[node[&apos;feature&apos;]]&gt;node[&apos;value&apos;]: label = predict(sample,node[&apos;rightChild&apos;]) else: label = predict(sample,node[&apos;leftChild&apos;]) else: return node[&apos;label&apos;] return labeldef test(data,tree): num = len(data) ans = [] for i in range(num): ans.append(predict(data[i],tree)) return ansdef plot_model(tree, name): g = Digraph(&quot;G&quot;, filename=name, format=&apos;png&apos;, strict=False) g.node(&quot;0&quot;, str(tree[&apos;feature&apos;]))#根节点的feature _sub_plot(g, tree, &quot;0&quot;) return g g.view()root = &quot;0&quot;def _sub_plot(g, tree, inc): global root ts = tree for i in ts.keys():#i是字典的key 根节点的key if i == &apos;leftChild&apos;: # 上次的节点指向刚刚画的节点 root = str(int(root) + 1) if &apos;feature&apos; in tree[i]: g.node(root,str(tree[i][&apos;feature&apos;]))#新生成的子节点root else: g.node(root, str(tree[i][&apos;label&apos;])) # 新生成的子节点root g.edge(inc, root, &apos;&lt;&apos; + str(tree[&apos;value&apos;])) _sub_plot(g, tree[i], root) if i == &apos;rightChild&apos;: root = str(int(root) + 1) if &apos;feature&apos; in tree[i]: g.node(root, str(tree[i][&apos;feature&apos;])) # 新生成的子节点root else: g.node(root, str(tree[i][&apos;label&apos;])) # 新生成的子节点root g.edge(inc, root, &apos;&gt;&apos; + str(tree[&apos;value&apos;])) _sub_plot(g, tree[i], root) if i == &apos;label&apos;: g.node(root, &apos;label:&apos; + str(tree[&apos;label&apos;])) # 画出儿子节点if __name__ == &apos;__main__&apos;: trainData = loadData(&apos;traindata.txt&apos;) testData = loadData(&apos;testdata.txt&apos;) tree = creatTree(trainData) ans = test(testData,tree) trueLabel = [sample[-1] for sample in testData] rightCount = 0 for i in range(len(ans)): if ans[i]==trueLabel[i]: rightCount = rightCount + 1 g = plot_model(tree, &quot;决策树&quot;) g.view() print(rightCount/len(ans)) 结果及可视化acc = 96% 实验数据每行一个样本，前三列为属性，最后一列为label 训练集1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374755 3 1.6 0.2 15 3.4 1.6 0.4 15.2 3.5 1.5 0.2 15.2 3.4 1.4 0.2 14.7 3.2 1.6 0.2 14.8 3.1 1.6 0.2 15.4 3.4 1.5 0.4 15.2 4.1 1.5 0.1 15.5 4.2 1.4 0.2 14.9 3.1 1.5 0.2 15 3.2 1.2 0.2 15.5 3.5 1.3 0.2 14.9 3.6 1.4 0.1 14.4 3 1.3 0.2 15.1 3.4 1.5 0.2 15 3.5 1.3 0.3 14.5 2.3 1.3 0.3 14.4 3.2 1.3 0.2 15 3.5 1.6 0.6 15.1 3.8 1.9 0.4 14.8 3 1.4 0.3 15.1 3.8 1.6 0.2 14.6 3.2 1.4 0.2 15.3 3.7 1.5 0.2 15 3.3 1.4 0.2 16.6 3 4.4 1.4 26.8 2.8 4.8 1.4 26.7 3 5 1.7 26 2.9 4.5 1.5 25.7 2.6 3.5 1 25.5 2.4 3.8 1.1 25.5 2.4 3.7 1 25.8 2.7 3.9 1.2 26 2.7 5.1 1.6 25.4 3 4.5 1.5 26 3.4 4.5 1.6 26.7 3.1 4.7 1.5 26.3 2.3 4.4 1.3 25.6 3 4.1 1.3 25.5 2.5 4 1.3 25.5 2.6 4.4 1.2 26.1 3 4.6 1.4 25.8 2.6 4 1.2 25 2.3 3.3 1 25.6 2.7 4.2 1.3 25.7 3 4.2 1.2 25.7 2.9 4.2 1.3 26.2 2.9 4.3 1.3 25.1 2.5 3 1.1 25.7 2.8 4.1 1.3 27.2 3.2 6 1.8 36.2 2.8 4.8 1.8 36.1 3 4.9 1.8 36.4 2.8 5.6 2.1 37.2 3 5.8 1.6 37.4 2.8 6.1 1.9 37.9 3.8 6.4 2 36.4 2.8 5.6 2.2 36.3 2.8 5.1 1.5 36.1 2.6 5.6 1.4 37.7 3 6.1 2.3 36.3 3.4 5.6 2.4 36.4 3.1 5.5 1.8 36 3 4.8 1.8 36.9 3.1 5.4 2.1 36.7 3.1 5.6 2.4 36.9 3.1 5.1 2.3 35.8 2.7 5.1 1.9 36.8 3.2 5.9 2.3 36.7 3.3 5.7 2.5 36.7 3 5.2 2.3 36.3 2.5 5 1.9 36.5 3 5.2 2 36.2 3.4 5.4 2.3 35.9 3 5.1 1.8 3 测试集1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374755.1 3.5 1.4 0.2 14.9 3 1.4 0.2 14.7 3.2 1.3 0.2 14.6 3.1 1.5 0.2 15 3.6 1.4 0.2 15.4 3.9 1.7 0.4 14.6 3.4 1.4 0.3 15 3.4 1.5 0.2 14.4 2.9 1.4 0.2 14.9 3.1 1.5 0.1 15.4 3.7 1.5 0.2 14.8 3.4 1.6 0.2 14.8 3 1.4 0.1 14.3 3 1.1 0.1 15.8 4 1.2 0.2 15.7 4.4 1.5 0.4 15.4 3.9 1.3 0.4 15.1 3.5 1.4 0.3 15.7 3.8 1.7 0.3 15.1 3.8 1.5 0.3 15.4 3.4 1.7 0.2 15.1 3.7 1.5 0.4 14.6 3.6 1 0.2 15.1 3.3 1.7 0.5 14.8 3.4 1.9 0.2 17 3.2 4.7 1.4 26.4 3.2 4.5 1.5 26.9 3.1 4.9 1.5 25.5 2.3 4 1.3 26.5 2.8 4.6 1.5 25.7 2.8 4.5 1.3 26.3 3.3 4.7 1.6 24.9 2.4 3.3 1 26.6 2.9 4.6 1.3 25.2 2.7 3.9 1.4 25 2 3.5 1 25.9 3 4.2 1.5 26 2.2 4 1 26.1 2.9 4.7 1.4 25.6 2.9 3.6 1.3 26.7 3.1 4.4 1.4 25.6 3 4.5 1.5 25.8 2.7 4.1 1 26.2 2.2 4.5 1.5 25.6 2.5 3.9 1.1 25.9 3.2 4.8 1.8 26.1 2.8 4 1.3 26.3 2.5 4.9 1.5 26.1 2.8 4.7 1.2 26.4 2.9 4.3 1.3 26.3 3.3 6 2.5 35.8 2.7 5.1 1.9 37.1 3 5.9 2.1 36.3 2.9 5.6 1.8 36.5 3 5.8 2.2 37.6 3 6.6 2.1 34.9 2.5 4.5 1.7 37.3 2.9 6.3 1.8 36.7 2.5 5.8 1.8 37.2 3.6 6.1 2.5 36.5 3.2 5.1 2 36.4 2.7 5.3 1.9 36.8 3 5.5 2.1 35.7 2.5 5 2 35.8 2.8 5.1 2.4 36.4 3.2 5.3 2.3 36.5 3 5.5 1.8 37.7 3.8 6.7 2.2 37.7 2.6 6.9 2.3 36 2.2 5 1.5 36.9 3.2 5.7 2.3 35.6 2.8 4.9 2 37.7 2.8 6.7 2 36.3 2.7 4.9 1.8 36.7 3.3 5.7 2.1 3 graphviz安装先pip install praphviz windows端需要去官网下载msi文件进行安装 然后将D:\\Graphviz2.39\\bin添加到环境变量","link":"/2019/11/02/决策树ID3算法Python实现/"},{"title":"决策论","text":"决策论中的一些基本概念。 基本内容 不确定型决策的几种准则：悲观准则、乐观准则、最小后悔准则、等可能性准则与乐观系数法 风险型决策的最大期望收益值法（EMV）、贝叶斯决策准则及信息价值（EVPI）、决策树法 不确定型决策决策基本要素 状态空间：$S=\\left{S_{1}, S_{2}, S_{3} \\cdots, S_{m}\\right}=\\left{S_{i}\\right} \\quad i=1, \\cdots m$ 策略空间：$A=\\left{A_{1}, A_{2}, \\cdots, A_{n}\\right}=\\left{A_{j}\\right} \\quad j=1, \\cdots, n$ 损益函数：$U_{i j}=u\\left(S_{i}, A_{j}\\right) \\quad i=1,2, \\cdots m ; j=1,2, \\cdots n$ 所以决策系统可以表示为三个主要素的函数： $$D=D(S, U, V)$$ 不确定决策例子公司决策生产那种新商品 悲观主义准则（小中取大） 乐观主义准则（大中取大） 最小后悔值准则：编制机会损失表$r_{i j }=\\left{\\max {j}\\left{a{i j }\\right}-a_{i j}\\right}$,找出每个方案的最大机会损失$Z_{i}=\\max {i}\\left{r{i j}\\right}$,选择最小的机会损失值$Z_{l}^{*}=\\min {i}\\left{Z{i}\\right}$ 等可能型决策：不同状态等可能，计算平均收益 乐观系数法：给出乐观系数$\\alpha \\in[0,1]$ 风险型决策对发生各事件的概率已知，一般采用期望值作为决策准则。 贝叶斯决策准则及信息价值（EVPI）已知先验概率，可以通过增加花费（信息费用）修正概率，修正概率通过贝叶斯公式得到。","link":"/2019/08/09/决策论/"},{"title":"mcm离散型题目及思路记录","text":"简单记录了题目和思路。 2017B ”拍照赚钱“的任务定价问题描述在拍照赚钱APP中，用户可以领取拍照任务，完成任务后可以获得酬金，不同的任务又不同的定价。 附件一给了任务的位置（经纬度），定价，完成情况，需要分析任务未完成的原因。 制定新的定价方案，并和原方案比较。 考虑任务联合打包发布规则下的定价模型，并分析对最终任务完成情况的影响。 对附件三种的新项目给出定价方案。 思路问题一：从定性和定量角度分析，先使用cftool工具箱绘制定价和经纬度坐标的三维拟合图，观察结果定性得出结论。然后利用kmeans聚类，将地图划分为网格区域，每个网格内定义四个指标，然后利用灰色关联矩阵定量分析定义的指标和定价的相关程度，然后通过对比未完成任务和已完成任务的相关度矩阵得出最显著的影响因素。 问题二：将定价方案看作优化问题，总成本最小化，完成率最大化：$\\left{ \\begin{array} { l } { \\min \\sum _ { i = 1 } ^ { 835 } p _ { i } } \\ { \\max \\sum _ { i = 1 } ^ { 835 } C _ { i } } \\end{array} \\right.$，定义了吸引度矩阵： 定义阈值，$w _ { i } = \\left{ \\begin{array} { l } { \\min \\left{ w _ { i j } \\right} , C _ { i } = 1 } \\ { \\max \\left{ w _ { i j } \\right} , C _ { i } = 0 } \\end{array} \\right.$当第i 个任务被完成时，其阈值至少低于其对一个会员的吸引度；当第i 个任务未被完成时，其阈值不低于任何其对一个会员的吸引度。 问题三：修改优化模型，通过聚类分析打包任务，修改吸引力矩阵，重新进行搜索。 问题四：聚类分析将任务打包，然后用第三问的任务数据和最优定价作为训练数据训练神经网络，再带入附件三的数据得到定价。 2016B 小区开放对道路通行的影响问题描述 建立评价指标体系，评价小区开放对周边道路通行的影响。 建立车辆通行的数学模型，用以研究小区开放对周边道路通行的影响。 小区开放产生的效果，可能会与小区结构及周边道路结构、车流量有关。请选取或构建不同类型的小区，应用你们建立的模型，定量比较各类型小区开放前后对道路通行的影响。 思路问题一:找指标，先找了多个指标，利用聚类分析把影响因素进行归类，然后利用层次分析法构建评价体系。 问题二：利用元胞自动机模拟道路情况，车辆变量更新规则有NS模型， 然后考虑道路通行能力，安全性，便捷度，建立模糊综合评价模型。通行能力利用层次分析法评定，安全性自己定义公式，便携度求最短路径。 问题三：针对不同小区，确定问题二模型中的参数，相当于模型求解。 2015B “互联网+”时代的出租车资源配置问题描述请你们搜集相关数据，建立数学模型研究如下问题： (1) 试建立合理的指标，并分析不同时空出租车资源的“供求匹配”程度。 (2) 分析各公司的出租车补贴方案是否对“缓解打车难”有帮助？ (3) 如果要创建一个新的打车软件服务平台，你们将设计什么样的补贴方案，并论证其合理性。 思路问题一：还是找指标，里程利用率，供求比率 里程利用率 K =载客里程（公里）/行驶里程（公里）*100% 然后确定这两个指标在供求平衡下的理想值（不是1） 然后再对不同时段（高峰，常规），不同空间（市区，郊区）进行模拟。 问题二： 软件使用比例计算： 意愿半径计算：即司机为接单愿意行驶的最大距离。也是用函数拟合的思路，定义一个函数形式，带入已知求出参数。 不同的时间段有不同的补贴金额，缓解率也随时间变化，可以绘制变化曲线。 第三问：开放问题，示例论文中采用了分区域动态实时补贴的方法，自己值定了一些规则，根据规则列出方程，解方程得到的结果。 也可以采用最优化问题的求解思路，站在平台的角度，补贴最少，效益最高。 2014B 创意平板折叠桌做过，不写了，模拟动态变化的过程就是推导桌子角度变量间的一些关系式，加工参数确定看成最优化问题。 2013B 碎纸片拼接复原做过，不写了，有点难。 2012B 太阳能小屋的设计问题描述：问题1：请根据山西省大同市的气象数据，仅考虑贴附安装方式，选定光伏电池组件，对小屋（见附件2）的部分外表面进行铺设，并根据电池组件分组数量和容量，选配相应的逆变器的容量和数量。 问题2：电池板的朝向与倾角均会影响到光伏电池的工作效率，请选择架空方式安装光伏电池，重新考虑问题1。 问题3：根据附件7给出的小屋建筑要求，请为大同市重新设计一个小屋，要求画出小屋的外形图，并对所设计小屋的外表面优化铺设光伏电池，给出铺设及分组连接方式，选配逆变器，计算相应结果。 思路第一问：电池板有三种串并联方式，不同的串并联方式还可以连接不同的逆变器，针对每种串并联方式，设置最优化目标: 全年功率最大化：$\\max W_{jmA}$，逆变器和电池总价最小化：$\\min p_{jmA}$，j表示墙免编号，m表示逆变器型号，A表示不同的电池连接方式。 针对该多目标优化问题，分别先做单目标规划下的最优值，求解出$W’{jmA}$和$p’{jmA}$ 然后再构造单目标规划： $f = (W_{jmA}-W’{jmA})^2+(p{jmA}-p’_{jmA})^2$ 根据此形式构造出优先级函数，得到不同型号逆变器的最佳组合方式定义优先级： $f’ = (\\frac{W_{jmA}-W_{max}}{W_{max}})^2+(\\frac{p_{jmA}-p_{min}}{p_{min}})^2 $ 采用贪心的方法根据优先级进行安装。 第二问：最优化，找到全年辐射强度最大的角度。 然后需要研究电池板的投影情况，阴影情况限制了电池的铺设。 第三问：根据房屋建设的标准制定约束，以全年接受光强之和为优化目标。 2012A 葡萄酒评价问题描述 分析附件1中两组评酒员的评价结果有无显著性差异，哪一组结果更可信？ 根据酿酒葡萄的理化指标和葡萄酒的质量对这些酿酒葡萄进行分级。 分析酿酒葡萄与葡萄酒的理化指标之间的联系。 分析酿酒葡萄和葡萄酒的理化指标对葡萄酒质量的影响，并论证能否用葡萄和葡萄酒的理化指标来评价葡萄酒的质量？ 方法记录熵值法用于特征剔除","link":"/2019/08/15/mcm离散型题目记录/"},{"title":"操作系统笔记","text":"杂 BIOS：基本IO处理系统，开机后计算机系统开始检测各种外设，然后才能加载相应软件执行，BIOS加载bootloader,bootloader加载os Bootloader:一个程序,放在硬盘第一个扇区，加载OS，从硬盘到内存 系统调用、异常、中断","link":"/2019/11/04/操作系统笔记/"},{"title":"排队论","text":"记录了排队论中的一些基本概念。 基本内容 了解排队系统的基本概念 了解生灭过程和状态转移图的推演，状态概率公式的推演 掌握排队系统的主要数量指标和记号 熟练掌握排队模型和求解方法（单服务台排队模型） 排队系统的基本构成 输入过程的三特征 输入过程：顾客源无限有限，顾客到达人数成批到达还是单个到达，到达时间间隔分为确定型和随机型（需知概率分布）。服务过程对顾客到达的影响相互独立到达、非相互独立到达（回头客问题）。 排队规则：损失制、等待制、混合制，队列长，队列数 服务机构：服务方式：单顾客、多顾客，服务时间：确定型和随机型 排队模型的表示方式肯德尔（Kendall）记号: $$输入分布/输出分布/并联的服务站数（X/Y/Z）$$ 扩展表示： $$输入分布/输出分布/并联的服务站数/系统容量（队长）$$ $$/系统状态（顾客源数）/服务规则（X/Y/Z/A/B/C）$$ 分布 泊松分布（最简单流）特点： 平稳性：在一定时间间隔内，来到服务系统的k个顾客的概率仅与这段时间的间隔长短有关，而与这段时间的起始时刻无关 无后效性：在不相交的时间区间内到达的顾客数是相互独立的 稀有性：在足够先得时间区间内只能有一个顾客到达，不可能有两个以上得顾客同时到达。 $$P_{k}(t)=e^{-\\lambda t} \\frac{(\\lambda t)^{k}}{k !} \\quad(k=0,1,2, \\cdots)$$ 在t时间内，有k个顾客来到服务系统得概率。 负指数分布： 排队问题中的常用指标 队长和排队长 逗留时间和等待时间 服务机构的工作强度=用于服务顾客的时间/服务设施的总服务时间 忙期：服务机构连续繁忙的时间长度 生灭过程是用来处理输入为最简单流，服务时间为指数分布这类最简单排队模型得方法。 平衡方程对任意状态，单位时间内进入该状态的平均次数和离开该状态的平均次数应该想到能（输入=输出）。 little公式 参考b站：运筹学 黄丽娟","link":"/2019/08/09/排队论/"},{"title":"网络计划","text":"基本要点 双代号网络图绘制 网络计划图时间参数计算 寻找最短工期和关键路线的方法 网络优化中的时间-费用优化方法，即最低成本 双代号网络计划图 节点：一个事项，指一个或若干个工序的开始和结束，相邻节点之间只能有一条箭头连接，但是可以用虚箭头连 箭头：表示工作，上面是工作名，下面是工作时间，不能形成缺口和回路，终点和起始点都有只有一个 圆圈里的数字是节点编号，编号从左到右，尾小于头 先行工序和后继工序先行工序表示紧排在本工序之前的工序，且开始或者完成后才能开始本工序 后继工序表示紧排在本工序之后的工序，且本工序开始或完成后，才能做的工序。 虚工序不占用时间和不消耗人力资金的资源，只为了表示相邻工序之间的逻辑关系而虚设的工序。 时间参数计算 完成项目所需要的最少时间 每个工序的开始和结束时间 关键路线及其相应的关键工序 非关键工序在不影响工程完成的前提下，其开始与结束时间可以推迟多久。 关键路线完成各个工序所需要时间最长的路线（主要矛盾线），该路线上的工序是关键工序。 就是说在这条路线上，所有的工序是需要时间最多的，这些工序没有结束之前，其他工序是不可能做完的。 求解方法：工序计算法 网络计划优化 工期优化 时间-费用优化 资源优化 资料网络计划的多目标优化 http://tow.cnki.net/kcms/detail/detail.aspx?filename=2001011640.nh&amp;dbcode=CRJT_CMFD&amp;dbname=CMFDTOTAL&amp;v=","link":"/2019/08/01/网络计划/"},{"title":"前端传参到后台中文乱码问题解决","text":"前端传参到后台中文乱码问题解决 在项目的web.xml文件中使用字符编码过滤器： 1234567891011121314151617&lt;filter&gt; &lt;filter-name&gt;CharacterEncodingFilter&lt;/filter-name&gt; &lt;filter-class&gt;org.springframework.web.filter.CharacterEncodingFilter&lt;/filter-class&gt; &lt;init-param&gt; &lt;param-name&gt;encoding&lt;/param-name&gt; &lt;param-value&gt;UTF-8&lt;/param-value&gt; &lt;/init-param&gt; &lt;init-param&gt; &lt;param-name&gt;forceEncoding&lt;/param-name&gt; &lt;param-value&gt;true&lt;/param-value&gt; &lt;/init-param&gt; &lt;/filter&gt;&lt;filter-mapping&gt; &lt;filter-name&gt;CharacterEncodingFilter&lt;/filter-name&gt; &lt;url-pattern&gt;/*&lt;/url-pattern&gt;&lt;/filter-mapping&gt;","link":"/2019/10/21/前端传参到后台中文乱码问题解决/"},{"title":"运输问题","text":"典型背景：单一物资的运输调度问题 $$\\min z=\\sum_{i=1}^{m} \\sum_{j=1}^{n} c_{i j} x_{i j}$$ 所有运价的求和最小（一定有最优解） $\\left{\\begin{array}{c}{\\sum_{j=1}^{n} x_{i}=a_{i}, i=1,2, \\cdots, m} \\ {\\sum_{i=1}^{m} x_{n}=b_{j}, j=1,2, \\cdots, n} \\ {x_{i j} \\geq 0, i=1,2, \\cdots, m} \\ {j=1,2, \\cdots n}\\end{array}\\right.$ 约束： 产地i运到n个销地的运量总和等于产地i的产量 m个产地运到销地j的运量的总和等于销地j的销量","link":"/2019/08/09/运输问题/"},{"title":"右键添加管理员取得所有权","text":"12345678910111213141516171819Windows Registry Editor Version 5.00　　 [HKEY_CLASSES_ROOT\\*\\shell\\runas] @=&quot;管理员取得所有权&quot; &quot;NoWorkingDirectory&quot;=&quot;&quot;　　 [HKEY_CLASSES_ROOT\\*\\shell\\runas\\command] @=&quot;cmd.exe /c takeown /f \\&quot;%1\\&quot; &amp;&amp; icacls \\&quot;%1\\&quot; /grant administrators:F&quot; &quot;IsolatedCommand&quot;=&quot;cmd.exe /c takeown /f \\&quot;%1\\&quot; &amp;&amp; icacls \\&quot;%1\\&quot; /grant administrators:F&quot;　　 [HKEY_CLASSES_ROOT\\exefile\\shell\\runas2] @=&quot;管理员取得所有权&quot; &quot;NoWorkingDirectory&quot;=&quot;&quot;　　 [HKEY_CLASSES_ROOT\\exefile\\shell\\runas2\\command] @=&quot;cmd.exe /c takeown /f \\&quot;%1\\&quot; &amp;&amp; icacls \\&quot;%1\\&quot; /grant administrators:F&quot; &quot;IsolatedCommand&quot;=&quot;cmd.exe /c takeown /f \\&quot;%1\\&quot; &amp;&amp; icacls \\&quot;%1\\&quot; /grant administrators:F&quot;　　 [HKEY_CLASSES_ROOT\\Directory\\shell\\runas] @=&quot;管理员取得所有权&quot; &quot;NoWorkingDirectory&quot;=&quot;&quot;　　 [HKEY_CLASSES_ROOT\\Directory\\shell\\runas\\command] @=&quot;cmd.exe /c takeown /f \\&quot;%1\\&quot; /r /d y &amp;&amp; icacls \\&quot;%1\\&quot; /grant administrators:F /t&quot; &quot;IsolatedCommand&quot;=&quot;cmd.exe /c takeown /f \\&quot;%1\\&quot; /r /d y &amp;&amp; icacls \\&quot;%1\\&quot; /grant administrators:F /t&quot; 在txt文件中写入，使用ANSI编码，重命名为.reg文件，双击","link":"/2019/07/29/右键添加管理员取得所有权/"},{"title":"熵值法用于特征剔除","text":"熵是对不确定性的一种度量，信息量越大，不确定性越小，熵越小。当用熵值判断某个指标的离散程度，指标的离散程度越大，该指标对综合评价的影响越大。 熵值越小，指标的离散程度越大，该指标对综合评价的影响 (即权重) 越大。 问题背景mcm2012A 葡萄酒评价，给出了葡萄酒的大量指标，希望将影响葡萄酒质量的指标数量减小。 步骤step1:初始数据矩阵$x = (x_{ij}){m \\times n}$，表示第i号葡萄酒的第j项指标的数值，先将各指标归一化处理，然后计算$x{ij}$在第j项指标的比重$p_{ij}$: $$p_{ij} = x_{ij}/\\sum_{i=1}^m x_{ij}$$ step2:计算第j各指标的熵值$e_{j}$: $$e_{j} = -k\\sum_{i=1}^mp_{ij} \\ln p_{ij}$$ 其中 k &gt; 0 , $e_j&gt;=0$,当$x_{ij}$对于给定的$j$全部相等时，$e_{j}$有最大值，此时: $$p_{ij} = \\frac1 m$$ $$e_j(x)|{max}=-k\\sum{i = 1}^m \\frac 1 m \\ln \\frac 1 m=k\\ln m$$ 令 $k = \\frac1 {\\ln m}$,则有$0&lt;=e_{j}&lt;=1$. step3:定义差异性系数： $g_{j} = 1-e_{j}$，该值越大，说明该指标越重要。 熵值越小，指标的离散程度越大，该指标对综合评价的影响 (即权重) 越大。 step4:定义权重：$a_{j} = g_{j}/\\sum_{i = 1}^mg_{j}$ 可用于评价问题的客观赋权。 step5:对权值排序后，从大到小可以进行累加求和，得到前$m$个成分的累计贡献率$G(m) = \\sum_{j=1}^ma_{j}$,取前80%即可反应大部分指标的影响，从而达到指标剔除的效果。 适用范围熵值用于赋权时，一般构建两级评价体系，上层可能需要结合专家经验来构建，而底层的指标分的比较细，权重比较难确定，这种情况下采用熵值法比较合适。 该方法没有考虑指标与指标间的相关性。 确定权重前需要确定指标对目标得分的影响方向，对非线性的指标要进行预处理或者剔除。 参考代码123load shang_datasInd=[1 1 1 1 2]; %指定各指标的正向or负向[S,W]=shang(X,Ind) 12345678910111213141516171819202122232425262728function [s,w]=shang(x,ind)%实现用熵值法求各指标(列）的权重及各数据行的得分%x为原始数据矩阵, 一行代表一个样本, 每列对应一个指标%ind指示向量，指示各列正向指标还是负向指标，1表示正向指标，2表示负向指标%s返回各行（样本）得分，w返回各列权重[n,m]=size(x); % n个样本, m个指标%%数据的归一化处理for i=1:m if ind(i)==1 %正向指标归一化 X(:,i)=guiyi(x(:,i),1,0.002,0.996); %若归一化到[0,1], 0会出问题 else %负向指标归一化 X(:,i)=guiyi(x(:,i),2,0.002,0.996); endend%%计算第j个指标下，第i个样本占该指标的比重p(i,j)for i=1:n for j=1:m p(i,j)=X(i,j)/sum(X(:,j)); endend%%计算第j个指标的熵值e(j)k=1/log(n);for j=1:m e(j)=-k*sum(p(:,j).*log(p(:,j)));endd=ones(1,m)-e; %计算信息熵冗余度w=d./sum(d); %求权值ws=100*w*p&apos;; %求综合得分 12345678910111213141516171819function y=guiyi(x,type,ymin,ymax)%实现正向或负向指标归一化，返回归一化后的数据矩阵%x为原始数据矩阵, 一行代表一个样本, 每列对应一个指标%type设定正向指标1,负向指标2%ymin,ymax为归一化的区间端点[n,m]=size(x);y=zeros(n,m);xmin=min(x);xmax=max(x);switch type case 1 for j=1:m y(:,j)=(ymax-ymin)*(x(:,j)-xmin(j))/(xmax(j)-xmin(j))+ymin; end case 2 for j=1:m y(:,j)=(ymax-ymin)*(xmax(j)-x(:,j))/(xmax(j)-xmin(j))+ymin; endend 参考机器学习中的信息论http://saili.science/2017/09/15/entropy-method/","link":"/2019/08/16/熵值法用于特征剔除/"},{"title":"python学习","text":"资料来自网络。 OS模块 os.sep:取代操作系统特定的路径分隔符 os.name:指示你正在使用的工作平台。比如对于Windows，它是’nt’，而对于Linux/Unix用户，它是’posix’。 os.getcwd:得到当前工作目录，即当前python脚本工作的目录路径。 os.getenv()和os.putenv:分别用来读取和设置环境变量 os.listdir():返回指定目录下的所有文件和目录名 os.remove(file):删除一个文件 os.stat（file）:获得文件属性 os.chmod(file):修改文件权限和时间戳 os.mkdir(name):创建目录 os.rmdir(name):删除目录 os.removedirs（r“c：\\python”）:删除多个目录 os.system():运行shell命令 os.exit():终止当前进程 os.linesep:给出当前平台的行终止符。例如，Windows使用’\\r\\n’，Linux使用’\\n’而Mac使用’\\r’ os.path.split():返回一个路径的目录名和文件名 os.path.isfile()和os.path.isdir()分别检验给出的路径是一个目录还是文件 os.path.existe():检验给出的路径是否真的存在 os.listdir(dirname):列出dirname下的目录和文件 os.getcwd():获得当前工作目录 os.curdir:返回当前目录（’.’） os.chdir(dirname):改变工作目录到dirname os.path.isdir(name):判断name是不是目录，不是目录就返回false os.path.isfile(name):判断name这个文件是否存在，不存在返回false os.path.exists(name):判断是否存在文件或目录name os.path.getsize(name):或得文件大小，如果name是目录返回0L os.path.abspath(name):获得绝对路径 os.path.isabs():判断是否为绝对路径 os.path.normpath(path):规范path字符串形式 os.path.split(name):分割文件名与目录（事实上，如果你完全使用目录，它也会将最后一个目录作为文件名而分离，同时它不会判断文件或目录是否存在） os.path.splitext():分离文件名和扩展名 os.path.join(path,name):连接目录与文件名或目录 os.path.basename(path):返回文件名 os.path.dirname(path):返回文件路径 文件操作os.mknod(&quot;text.txt&quot;)：创建空文件fp = open(&quot;text.txt&quot;,w):直接打开一个文件，如果文件不存在就创建文件 关于open的模式w 写方式a 追加模式打开（从EOF开始，必要时创建新文件）r+ 以读写模式打开w+ 以读写模式打开a+ 以读写模式打开rb 以二进制读模式打开wb 以二进制写模式打开 (参见 w )ab 以二进制追加模式打开 (参见 a )rb+ 以二进制读写模式打开 (参见 r+ )wb+ 以二进制读写模式打开 (参见 w+ )ab+ 以二进制读写模式打开 (参见 a+ ) 关于文件的函数1fp.read([size]) size为读取的长度，以byte为单位 1fp.readline([size]) 读一行，如果定义了size，有可能返回的只是一行的一部分 1fp.readlines([size]) 把文件每一行作为一个list的一个成员，并返回这个list。其实它的内部是通过循环调用readline()来实现的。如果提供size参数，size是表示读取内容的总长，也就是说可能只读到文件的一部分。 1fp.write(str) 把str写到文件中，write()并不会在str后加上一个换行符 1fp.writelines(seq) 把seq的内容全部写到文件中(多行一次性写入)。这个函数也只是忠实地写入，不会在每行后面加上任何东西。 1fp.close() 关闭文件。python会在一个文件不用后自动关闭文件，不过这一功能没有保证，最好还是养成自己关闭的习惯。 如果一个文件在关闭后还对其进行操作会产生ValueError 1fp.flush() 把缓冲区的内容写入硬盘 1fp.fileno() 返回一个长整型的”文件标签“ 1fp.isatty() 文件是否是一个终端设备文件（unix系统中的） 1fp.tell() 返回文件操作标记的当前位置，以文件的开头为原点 1fp.next() 返回下一行，并将文件操作标记位移到下一行。把一个file用于for … in file这样的语句时，就是调用next()函数来实现遍历的。 1fp.seek(offset[,whence]) 将文件打操作标记移到offset的位置。这个offset一般是相对于文件的开头来计算的，一般为正数。但如果提供了whence参数就不一定了，whence可以为0表示从头开始计算，1表示以当前位置为原点计算。2表示以文件末尾为原点进行计算。需要注意，如果文件以a或a+的模式打开，每次进行写操作时，文件操作标记会自动返回到文件末尾。 1fp.truncate([size]) 把文件裁成规定的大小，默认的是裁到当前文件操作标记的位置。如果size比文件的大小还要大，依据系统的不同可能是不改变文件，也可能是用0把文件补到相应的大小，也可能是以一些随机的内容加上去。 目录操作1os.mkdir(&quot;file&quot;) 创建目录 复制文件: 1shutil.copyfile(&quot;oldfile&quot;,&quot;newfile&quot;) oldfile和newfile都只能是文件 1shutil.copy(&quot;oldfile&quot;,&quot;newfile&quot;) oldfile只能是文件夹，newfile可以是文件，也可以是目标目录 1shutil.copytree(&quot;olddir&quot;,&quot;newdir&quot;) 复制文件夹.olddir和newdir都只能是目录，且newdir必须不存在 1os.rename(&quot;oldname&quot;,&quot;newname&quot;) 重命名文件（目录）.文件或目录都是使用这条命令 1shutil.move(&quot;oldpos&quot;,&quot;newpos&quot;) 移动文件（目录） 1os.rmdir(&quot;dir&quot;) 只能删除空目录 1shutil.rmtree(&quot;dir&quot;) 空目录、有内容的目录都可以删 1os.chdir(&quot;path&quot;) 转换目录，换路径 属性操作：hasattr()、getattr()、setattr()函数的使用 hasattr(object, name)判断一个对象里面是否有name属性或者name方法，返回BOOL值，有name特性返回True， 否则返回False。需要注意的是name要用括号括起来 1234567891011&gt;&gt;&gt; class test():... name=&quot;xiaohua&quot;... def run(self):... return &quot;HelloWord&quot;...&gt;&gt;&gt; t=test()&gt;&gt;&gt; hasattr(t, &quot;name&quot;) #判断对象有name属性True&gt;&gt;&gt; hasattr(t, &quot;run&quot;) #判断对象有run方法True&gt;&gt;&gt; getattr(object, name[,default]) 获取对象object的属性或者方法，如果存在打印出来，如果不存在，打印出默认值，默认值可选。需要注意的是，如果是返回的对象的方法，返回的是方法的内存地址，如果需要运行这个方法，可以在后面添加一对括号。 12345678910111213141516171819&gt;&gt;&gt; class test():... name=&quot;xiaohua&quot;... def run(self):... return &quot;HelloWord&quot;...&gt;&gt;&gt; t=test()&gt;&gt;&gt; getattr(t, &quot;name&quot;) #获取name属性，存在就打印出来。&apos;xiaohua&apos;&gt;&gt;&gt; getattr(t, &quot;run&quot;) #获取run方法，存在就打印出方法的内存地址。&lt;bound method test.run of &lt;__main__.test instance at 0x0269C878&gt;&gt;&gt;&gt;&gt; getattr(t, &quot;run&quot;)() #获取run方法，后面加括号可以将这个方法运行。&apos;HelloWord&apos;&gt;&gt;&gt; getattr(t, &quot;age&quot;) #获取一个不存在的属性。Traceback (most recent call last): File &quot;&lt;stdin&gt;&quot;, line 1, in &lt;module&gt;AttributeError: test instance has no attribute &apos;age&apos;&gt;&gt;&gt; getattr(t, &quot;age&quot;,&quot;18&quot;) #若属性不存在，返回一个默认值。&apos;18&apos;&gt;&gt;&gt; setattr(object, name, values) 给对象的属性赋值，若属性不存在，先创建再赋值。 123456789101112&gt;&gt;&gt; class test():... name=&quot;xiaohua&quot;... def run(self):... return &quot;HelloWord&quot;...&gt;&gt;&gt; t=test()&gt;&gt;&gt; hasattr(t, &quot;age&quot;) #判断属性是否存在False&gt;&gt;&gt; setattr(t, &quot;age&quot;, &quot;18&quot;) #为属相赋值，并没有返回值&gt;&gt;&gt; hasattr(t, &quot;age&quot;) #属性存在了True&gt;&gt;&gt; 一种综合的用法是：判断一个对象的属性是否存在，若不存在就添加该属性。 123456789101112131415&gt;&gt;&gt; class test():... name=&quot;xiaohua&quot;... def run(self):... return &quot;HelloWord&quot;...&gt;&gt;&gt; t=test()&gt;&gt;&gt; getattr(t, &quot;age&quot;) #age属性不存在Traceback (most recent call last): File &quot;&lt;stdin&gt;&quot;, line 1, in &lt;module&gt;AttributeError: test instance has no attribute &apos;age&apos;&gt;&gt;&gt; getattr(t, &quot;age&quot;, setattr(t, &quot;age&quot;, &quot;18&quot;)) #age属性不存在时，设置该属性&apos;18&apos;&gt;&gt;&gt; getattr(t, &quot;age&quot;) #可检测设置成功&apos;18&apos;&gt;&gt;&gt;","link":"/2019/10/26/python学习/"},{"title":"卷积网络中的一些操作","text":"参考：https://zhuanlan.zhihu.com/p/28749411记录了一些卷积神经网络种的操作。 Group convolution（分组卷积） 卷积核的总数不变，通道数变为原来的$1/G$,故参数量也变为原来的$1/G$,减少了参数（G为分组数）。 1nn.functional.conv2d(x,self.convWeight2,bias = self.mybias,stride=1, padding=1, dilation=1, groups=1) groups参数就表示分组卷积的组数，传统卷积下groups=1。 3*3卷积核之前人们的观念是，卷积核越大，receptive field（感受野）越大，看到的图片信息越多，因此获得的特征越好。虽说如此，但是大的卷积核会导致计算量的暴增，不利于模型深度的增加，计算性能也会降低。于是在VGG（最早使用）、Inception网络中，利用2个3×3卷积核的组合比1个5×5卷积核的效果更佳，同时参数量（3×3×2+1 VS 5×5×1+1）被降低，因此后来3×3卷积核被广泛应用在各种模型中。 Inception结构 一个输入的feature map分别同时经过1×1、3×3、5×5的卷积核的处理，得出的特征再组合起来，获得更佳的特征。 Bottleneck为了解决Inception带来的参数变多的问题，引入$1 \\times 1$的卷积核。 对比两种结构： 输入为256通道的feature map，$3 \\times 3 \\times 256$ 表示256个3*3卷积核，通常省略通道数，那么参数量为：256×3×3×256 = 589,824 若先通过1×1×64的卷积层，维度变为64通道，再经过一个3×3×64的卷积层，最后经过一个1×1×256的卷积层，输出256维，参数量为：256×1×1×64 + 64×3×3×64 + 64×1×1×256 = 69,632。 Resnet残差网络解决网络退化问题：随着深度增加，网络表现变差，很大程度上的原因是因为当层数加深时，梯度消散得越来越严重，以至于反向传播很难训练到浅层的网络。 1234567891011121314151617181920212223# Residual block定义残差块class ResidualBlock(nn.Module): def __init__(self, in_channels, out_channels, stride=1, downsample=None): super(ResidualBlock, self).__init__() self.conv1 = conv3x3(in_channels, out_channels, stride) self.bn1 = nn.BatchNorm2d(out_channels) self.relu = nn.ReLU(inplace=True) self.conv2 = conv3x3(out_channels, out_channels) self.bn2 = nn.BatchNorm2d(out_channels) self.downsample = downsample def forward(self, x): residual = x out = self.conv1(x) out = self.bn1(out) out = self.relu(out) out = self.conv2(out) out = self.bn2(out) if self.downsample: residual = self.downsample(x) out += residual out = self.relu(out) return out DepthWise操作 假设输入通道数为3，要求输出通道数为256，两种做法： 1.直接接一个3×3×256的卷积核，参数量为：3×3×3×256 = 6,912 2.DW操作，分两步完成，参数量为：3×3×3 + 3×1×1×256 = 795 ShuffleNet对通道进行随机分组，传统Group Convolution只能在最后时刻才融合不同组之间的特征，对模型的泛化性是相当不利。 ShuffleNet在每一次层叠这种Group conv层前，都进行一次channel shuffle，shuffle过的通道被分配到不同组当中。进行完一次group conv之后，再一次channel shuffle，然后分到下一层组卷积当中，以此循环。 SEnet通道间的特征可以加入权重，第一条直接通过，第二条首先进行Squeeze操作（Global Average Pooling），把每个通道2维的特征压缩成一个1维，从而得到一个特征通道向量（每个数字代表对应通道的特征），把这一列特征通道向量输入两个全连接层和sigmoid，建模出特征通道间的相关性，得到的输出其实就是每个通道对应的权重，把这些权重通过Scale乘法通道加权到原来的特征上（第一条路），这样就完成了特征通道的权重分配。 Dilated convolution（空洞卷积）1nn.functional.conv2d(x,self.convWeight2,bias = self.mybias,stride=1, padding=1, dilation=1, groups=1) dilation=1就是空洞的大小。 这样即使卷积核大小不变，但它看到的区域变得更大了。 Deformable convolution 可变形卷积核直接在原来的过滤器前面再加一层过滤器，这层过滤器学习的是下一层卷积核的位置偏移量（offset），这样只是增加了一层过滤器，或者直接把原网络中的某一层过滤器当成学习offset的过滤器，这样实际增加的计算量是相当少的，但能实现可变形卷积核，识别特征的效果更好。 参考资料分组卷积：https://www.cnblogs.com/shine-lee/p/10243114.html 残差网络demo：https://shenxiaohai.me/2018/10/19/pytorch_tutorial_intermediate_02/","link":"/2019/11/10/卷积网络中的一些操作/"}],"tags":[{"name":"matlab","slug":"matlab","link":"/tags/matlab/"},{"name":"机器学习","slug":"机器学习","link":"/tags/机器学习/"},{"name":"矩阵分析","slug":"矩阵分析","link":"/tags/矩阵分析/"},{"name":"markdown","slug":"markdown","link":"/tags/markdown/"},{"name":"hexo","slug":"hexo","link":"/tags/hexo/"},{"name":"python","slug":"python","link":"/tags/python/"},{"name":"运筹学","slug":"运筹学","link":"/tags/运筹学/"},{"name":"数学建模","slug":"数学建模","link":"/tags/数学建模/"},{"name":"web","slug":"web","link":"/tags/web/"},{"name":"windows","slug":"windows","link":"/tags/windows/"},{"name":"深度学习","slug":"深度学习","link":"/tags/深度学习/"}],"categories":[{"name":"机器学习","slug":"机器学习","link":"/categories/机器学习/"},{"name":"算法","slug":"算法","link":"/categories/算法/"},{"name":"运筹学","slug":"运筹学","link":"/categories/运筹学/"},{"name":"web开发","slug":"web开发","link":"/categories/web开发/"},{"name":"编程语言","slug":"编程语言","link":"/categories/编程语言/"},{"name":"python","slug":"编程语言/python","link":"/categories/编程语言/python/"},{"name":"深度学习","slug":"深度学习","link":"/categories/深度学习/"}]}